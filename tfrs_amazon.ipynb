{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4205e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 20:32:42.132855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 20:32:42.366680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-28 20:32:42.366712: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(str(datetime.now()))\n",
    "import numpy as np\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] =\"3\"\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcc3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bebfdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_218653/1916213802.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 20:32:44.522006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-28 20:32:44.522031: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-28 20:32:44.522051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bioss-System-Product-Name): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "gpu_available = tf.test.is_gpu_available()\n",
    "gpu_available\n",
    "req_cols = ['ITEM_ID', 'USER_ID', 'CABIN_TYPE', 'USER_RESIDENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b86d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_df_updated = pd.read_csv(\"dataset/interaction_demo.csv\")\n",
    "test_df = pd.read_csv(\"dataset/interaction_test_demo.csv\")\n",
    "data_set_df_updated.loc[data_set_df_updated.USER_RESIDENCE.isnull(),\"USER_RESIDENCE\"] = 'None'\n",
    "test_df.loc[test_df.USER_RESIDENCE.isnull(),\"USER_RESIDENCE\"] = 'None'\n",
    "train_df = pd.concat([data_set_df_updated, test_df], ignore_index=True)\n",
    "train_df.sort_values(\"TIMESTAMP\", ascending= False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd24e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_item_count = train_df.groupby([\"ITEM_ID\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_item_count[\"probability\"]= train_df_item_count[\"counts\"] / train_df_item_count[\"counts\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff5752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(train_df_item_count[[\"ITEM_ID\",\"probability\"]], how='left', on='ITEM_ID',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf387015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df = train_df[[\"ITEM_ID\"]].drop_duplicates(\"ITEM_ID\")\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(item_df.to_dict(\"list\")).batch(32)\n",
    "item_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6083b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols = req_cols+[\"probability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3e53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =  tf.data.Dataset.from_tensor_slices(train_df[req_cols].to_dict(\"list\")).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b21ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"USER_ID\"]))))\n",
    "\n",
    "CABIN_TYPE_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"CABIN_TYPE\"]))))\n",
    "\n",
    "USER_RESIDENCE_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"USER_RESIDENCE\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fb359ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_unique =  np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"ITEM_ID\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7712418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rankL(np_rank):\n",
    "#     r = int(np_rank[-1])\n",
    "#     _l = 0\n",
    "#     for k in range(1, r+1):\n",
    "#         _l += 1./k\n",
    "#     return np.float32(_l)\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# labels are assumed to be 1 hot encoded\n",
    "# \"\"\"\n",
    "# def warp_loss(labels, logits):\n",
    "#     # for easy broadcasting\n",
    "#     labels, logits = tf.transpose(labels, [1, 0]), tf.transpose(logits, [1, 0])\n",
    "#     f_y = tf.reduce_sum(logits*labels, axis=0)\n",
    "#     rank = tf.reduce_sum(tf.maximum(tf.sign(1+logits-f_y), 0), axis=0)\n",
    "#     diff = tf.reduce_sum(tf.maximum(1+logits-f_y, 0), axis=0)\n",
    "#     with tf.control_dependencies([tf.assert_greater(rank, tf.zeros_like(rank))]):\n",
    "#         return tf.py_func(rankL, [rank], tf.float32) * diff/rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "876e1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        emb_dim = 8    \n",
    "        self.user_id_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=USER_ID_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(USER_ID_unique) + 1, 16),\n",
    "        ])\n",
    "            \n",
    "        self.cabin_type_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary= CABIN_TYPE_unique, mask_token=None),  \n",
    "            tf.keras.layers.Embedding(len(CABIN_TYPE_unique) + 1, emb_dim),\n",
    "        ])\n",
    "\n",
    "        self.user_residence_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=USER_RESIDENCE_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(USER_RESIDENCE_unique) + 1, emb_dim),\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def call(self, user_interation_data):\n",
    "        return tf.concat([                          \n",
    "            self.user_id_embedding(user_interation_data[\"USER_ID\"]), \n",
    "            self.cabin_type_embedding(user_interation_data[\"CABIN_TYPE\"]), \n",
    "            self.user_residence_embedding(user_interation_data[\"USER_RESIDENCE\"]),\n",
    "        ], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "915250ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=item_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(item_unique) + 1, 32),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, user_interation_data):\n",
    "\n",
    "        return tf.concat([\n",
    "            self.item_embedding(user_interation_data[\"ITEM_ID\"])\n",
    "            \n",
    "            ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5793fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRFSRetrievalModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, UserModel,ItemModel, item_ds ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.query_model = tf.keras.Sequential([#,UserModel()\n",
    "          UserModel(),\n",
    "#           tf.keras.layers.Dense(32 , kernel_initializer= tf.keras.initializers.RandomNormal(seed=99)),  \n",
    "#           tf.keras.layers.Dropout(0.2),\n",
    "        ])\n",
    "        \n",
    "\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "          ItemModel(),\n",
    "#           tf.keras.layers.Dense(32, kernel_initializer= tf.keras.initializers.RandomNormal(seed=1)),\n",
    "#           tf.keras.layers.Dropout(0.2),\n",
    "        ]) \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         metrics = [\n",
    "#           tf.keras.metrics.TopKCategoricalAccuracy(\n",
    "#               k=x, name=f\"factorized_top_k/top_{x}_categorical_accuracy\")\n",
    "#           for x in [3,5,10,15, 25]\n",
    "#         ]  \n",
    "        \n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "#             loss=warp_loss,\n",
    "            num_hard_negatives=100,\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "            item_ds.map(self.candidate_model),\n",
    "                ks= (3, 5, 10,15, 25)),\n",
    "                          \n",
    "\n",
    "        )\n",
    "        \n",
    "#         self.task = tfrs.tasks.Retrieval(\n",
    "#             metrics=tfrs.metrics.FactorizedTopK(\n",
    "#                 candidates=item_ds.map(self.candidate_model),\n",
    "#                 metrics = metrics,\n",
    "#                 k = 100\n",
    "#             ),\n",
    "#             # temperature = 0.5,\n",
    "#             num_hard_negatives = 5\n",
    "#         )\n",
    "\n",
    "    def compute_loss(self, features, training= True):\n",
    "\n",
    "        item_features = {\"ITEM_ID\":features.pop(\"ITEM_ID\") }\n",
    "        query_embeddings = self.query_model(features)\n",
    "        item_embeddings = self.candidate_model(item_features)\n",
    "        candidate_sampling_probability = features.pop(\"probability\")\n",
    "        return self.task(query_embeddings, \n",
    "        item_embeddings, \n",
    "        compute_metrics=True,\n",
    "        candidate_sampling_probability = candidate_sampling_probability\n",
    "        )\n",
    "\n",
    "    def call(self, test):\n",
    "        features= test.copy()\n",
    "        item_features = {\"ITEM_ID\":features.pop(\"ITEM_ID\") }\n",
    "        query_embeddings = self.query_model(features)\n",
    "        item_embeddings = self.candidate_model(item_features)\n",
    "\n",
    "        return query_embeddings, item_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f5d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max_index = math.floor(train_df.shape[0]*0.1)\n",
    "train_split_len = train_df.shape[0] - test_max_index\n",
    "data_set_tf = tf.data.Dataset.from_tensor_slices(train_df[req_cols].to_dict(\"list\"))\n",
    "test = data_set_tf.take(test_max_index)\n",
    "train = data_set_tf.skip(test_max_index).take(train_split_len)\n",
    "shuffled = train.shuffle(train_split_len, seed=42, reshuffle_each_iteration=True)\n",
    "cached_train = shuffled.batch(512).prefetch(4096)#train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(512).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74fcf471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34853, 3485)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0], test_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92aff5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_check_points(fpath= 'new_amazon_check_points/*'):\n",
    "    files = glob.glob(fpath)\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2625b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_call_back_fun(K):\n",
    "    delete_all_check_points()\n",
    "    model_path = f\"new_amazon_check_points/best_check_point_{K}k\"\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_weights_only=True,\n",
    "        monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    early_stoping = tf.keras.callbacks.EarlyStopping(monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy',\n",
    "                                                     mode='min',\n",
    "                                                     patience=5)\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy', \n",
    "                                                     factor=0.6,\n",
    "                                                     #mode='min',\n",
    "                                                     patience=9, \n",
    "                                                     min_lr=1e-6\n",
    "    )\n",
    "    return model_path, model_checkpoint_callback, early_stoping, reduce_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf39bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path, model_checkpoint_callback, early_stoping, reduce_lr = get_call_back_fun(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a45c02e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "model = TRFSRetrievalModel(UserModel, ItemModel, item_ds)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f49834c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'USER_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'CABIN_TYPE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'USER_RESIDENCE': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'probability': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'USER_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'CABIN_TYPE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'USER_RESIDENCE': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'probability': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "61/62 [============================>.] - ETA: 0s - factorized_top_k/top_3_categorical_accuracy: 0.0406 - factorized_top_k/top_5_categorical_accuracy: 0.0765 - factorized_top_k/top_10_categorical_accuracy: 0.1271 - factorized_top_k/top_15_categorical_accuracy: 0.1777 - factorized_top_k/top_25_categorical_accuracy: 0.2766 - loss: 2956.0573 - regularization_loss: 0.0000e+00 - total_loss: 2956.0573WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'USER_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'CABIN_TYPE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'USER_RESIDENCE': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'probability': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "62/62 [==============================] - 6s 51ms/step - factorized_top_k/top_3_categorical_accuracy: 0.0409 - factorized_top_k/top_5_categorical_accuracy: 0.0767 - factorized_top_k/top_10_categorical_accuracy: 0.1273 - factorized_top_k/top_15_categorical_accuracy: 0.1778 - factorized_top_k/top_25_categorical_accuracy: 0.2770 - loss: 2882.3604 - regularization_loss: 0.0000e+00 - total_loss: 2882.3604 - val_factorized_top_k/top_3_categorical_accuracy: 0.1486 - val_factorized_top_k/top_5_categorical_accuracy: 0.2207 - val_factorized_top_k/top_10_categorical_accuracy: 0.3131 - val_factorized_top_k/top_15_categorical_accuracy: 0.3917 - val_factorized_top_k/top_25_categorical_accuracy: 0.5197 - val_loss: 1942.3702 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1942.3702 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1791 - factorized_top_k/top_5_categorical_accuracy: 0.2450 - factorized_top_k/top_10_categorical_accuracy: 0.3513 - factorized_top_k/top_15_categorical_accuracy: 0.4240 - factorized_top_k/top_25_categorical_accuracy: 0.5511 - loss: 2273.5412 - regularization_loss: 0.0000e+00 - total_loss: 2273.5412 - val_factorized_top_k/top_3_categorical_accuracy: 0.2029 - val_factorized_top_k/top_5_categorical_accuracy: 0.2571 - val_factorized_top_k/top_10_categorical_accuracy: 0.3532 - val_factorized_top_k/top_15_categorical_accuracy: 0.4304 - val_factorized_top_k/top_25_categorical_accuracy: 0.5977 - val_loss: 1928.4976 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1928.4976 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5759 - factorized_top_k/top_5_categorical_accuracy: 0.6542 - factorized_top_k/top_10_categorical_accuracy: 0.7338 - factorized_top_k/top_15_categorical_accuracy: 0.7724 - factorized_top_k/top_25_categorical_accuracy: 0.8197 - loss: 1899.1077 - regularization_loss: 0.0000e+00 - total_loss: 1899.1077 - val_factorized_top_k/top_3_categorical_accuracy: 0.2393 - val_factorized_top_k/top_5_categorical_accuracy: 0.3182 - val_factorized_top_k/top_10_categorical_accuracy: 0.4511 - val_factorized_top_k/top_15_categorical_accuracy: 0.5377 - val_factorized_top_k/top_25_categorical_accuracy: 0.6410 - val_loss: 2032.3743 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2032.3743 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.7556 - factorized_top_k/top_5_categorical_accuracy: 0.8147 - factorized_top_k/top_10_categorical_accuracy: 0.8633 - factorized_top_k/top_15_categorical_accuracy: 0.8854 - factorized_top_k/top_25_categorical_accuracy: 0.9116 - loss: 1467.1767 - regularization_loss: 0.0000e+00 - total_loss: 1467.1767 - val_factorized_top_k/top_3_categorical_accuracy: 0.2422 - val_factorized_top_k/top_5_categorical_accuracy: 0.3208 - val_factorized_top_k/top_10_categorical_accuracy: 0.4313 - val_factorized_top_k/top_15_categorical_accuracy: 0.5185 - val_factorized_top_k/top_25_categorical_accuracy: 0.6227 - val_loss: 2167.6853 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2167.6853 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8089 - factorized_top_k/top_5_categorical_accuracy: 0.8662 - factorized_top_k/top_10_categorical_accuracy: 0.9076 - factorized_top_k/top_15_categorical_accuracy: 0.9246 - factorized_top_k/top_25_categorical_accuracy: 0.9453 - loss: 1265.2455 - regularization_loss: 0.0000e+00 - total_loss: 1265.2455 - val_factorized_top_k/top_3_categorical_accuracy: 0.2284 - val_factorized_top_k/top_5_categorical_accuracy: 0.2924 - val_factorized_top_k/top_10_categorical_accuracy: 0.4092 - val_factorized_top_k/top_15_categorical_accuracy: 0.4944 - val_factorized_top_k/top_25_categorical_accuracy: 0.6109 - val_loss: 2246.8018 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2246.8018 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8334 - factorized_top_k/top_5_categorical_accuracy: 0.8881 - factorized_top_k/top_10_categorical_accuracy: 0.9260 - factorized_top_k/top_15_categorical_accuracy: 0.9411 - factorized_top_k/top_25_categorical_accuracy: 0.9586 - loss: 1189.8990 - regularization_loss: 0.0000e+00 - total_loss: 1189.8990 - val_factorized_top_k/top_3_categorical_accuracy: 0.2327 - val_factorized_top_k/top_5_categorical_accuracy: 0.2895 - val_factorized_top_k/top_10_categorical_accuracy: 0.3928 - val_factorized_top_k/top_15_categorical_accuracy: 0.4887 - val_factorized_top_k/top_25_categorical_accuracy: 0.6138 - val_loss: 2294.7529 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2294.7529 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8439 - factorized_top_k/top_5_categorical_accuracy: 0.9006 - factorized_top_k/top_10_categorical_accuracy: 0.9367 - factorized_top_k/top_15_categorical_accuracy: 0.9502 - factorized_top_k/top_25_categorical_accuracy: 0.9651 - loss: 1153.4491 - regularization_loss: 0.0000e+00 - total_loss: 1153.4491 - val_factorized_top_k/top_3_categorical_accuracy: 0.2330 - val_factorized_top_k/top_5_categorical_accuracy: 0.2924 - val_factorized_top_k/top_10_categorical_accuracy: 0.4017 - val_factorized_top_k/top_15_categorical_accuracy: 0.4844 - val_factorized_top_k/top_25_categorical_accuracy: 0.6069 - val_loss: 2329.1218 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2329.1218 - lr: 0.0100\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8494 - factorized_top_k/top_5_categorical_accuracy: 0.9079 - factorized_top_k/top_10_categorical_accuracy: 0.9433 - factorized_top_k/top_15_categorical_accuracy: 0.9573 - factorized_top_k/top_25_categorical_accuracy: 0.9707 - loss: 1129.1514 - regularization_loss: 0.0000e+00 - total_loss: 1129.1514 - val_factorized_top_k/top_3_categorical_accuracy: 0.2290 - val_factorized_top_k/top_5_categorical_accuracy: 0.2901 - val_factorized_top_k/top_10_categorical_accuracy: 0.3865 - val_factorized_top_k/top_15_categorical_accuracy: 0.4539 - val_factorized_top_k/top_25_categorical_accuracy: 0.5897 - val_loss: 2350.1934 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2350.1934 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8577 - factorized_top_k/top_5_categorical_accuracy: 0.9131 - factorized_top_k/top_10_categorical_accuracy: 0.9484 - factorized_top_k/top_15_categorical_accuracy: 0.9609 - factorized_top_k/top_25_categorical_accuracy: 0.9734 - loss: 1112.3289 - regularization_loss: 0.0000e+00 - total_loss: 1112.3289 - val_factorized_top_k/top_3_categorical_accuracy: 0.2241 - val_factorized_top_k/top_5_categorical_accuracy: 0.2898 - val_factorized_top_k/top_10_categorical_accuracy: 0.3948 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.6023 - val_loss: 2367.4131 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2367.4131 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8594 - factorized_top_k/top_5_categorical_accuracy: 0.9177 - factorized_top_k/top_10_categorical_accuracy: 0.9520 - factorized_top_k/top_15_categorical_accuracy: 0.9634 - factorized_top_k/top_25_categorical_accuracy: 0.9758 - loss: 1103.3359 - regularization_loss: 0.0000e+00 - total_loss: 1103.3359 - val_factorized_top_k/top_3_categorical_accuracy: 0.2275 - val_factorized_top_k/top_5_categorical_accuracy: 0.2855 - val_factorized_top_k/top_10_categorical_accuracy: 0.3957 - val_factorized_top_k/top_15_categorical_accuracy: 0.4806 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2393.5410 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2393.5410 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8622 - factorized_top_k/top_5_categorical_accuracy: 0.9211 - factorized_top_k/top_10_categorical_accuracy: 0.9546 - factorized_top_k/top_15_categorical_accuracy: 0.9660 - factorized_top_k/top_25_categorical_accuracy: 0.9774 - loss: 1092.3148 - regularization_loss: 0.0000e+00 - total_loss: 1092.3148 - val_factorized_top_k/top_3_categorical_accuracy: 0.2275 - val_factorized_top_k/top_5_categorical_accuracy: 0.2849 - val_factorized_top_k/top_10_categorical_accuracy: 0.3902 - val_factorized_top_k/top_15_categorical_accuracy: 0.4677 - val_factorized_top_k/top_25_categorical_accuracy: 0.5900 - val_loss: 2415.4211 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2415.4211 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8649 - factorized_top_k/top_5_categorical_accuracy: 0.9244 - factorized_top_k/top_10_categorical_accuracy: 0.9562 - factorized_top_k/top_15_categorical_accuracy: 0.9684 - factorized_top_k/top_25_categorical_accuracy: 0.9793 - loss: 1086.9317 - regularization_loss: 0.0000e+00 - total_loss: 1086.9317 - val_factorized_top_k/top_3_categorical_accuracy: 0.2224 - val_factorized_top_k/top_5_categorical_accuracy: 0.2841 - val_factorized_top_k/top_10_categorical_accuracy: 0.3851 - val_factorized_top_k/top_15_categorical_accuracy: 0.4597 - val_factorized_top_k/top_25_categorical_accuracy: 0.5868 - val_loss: 2433.4890 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2433.4890 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8754 - factorized_top_k/top_5_categorical_accuracy: 0.9327 - factorized_top_k/top_10_categorical_accuracy: 0.9631 - factorized_top_k/top_15_categorical_accuracy: 0.9722 - factorized_top_k/top_25_categorical_accuracy: 0.9826 - loss: 1058.8239 - regularization_loss: 0.0000e+00 - total_loss: 1058.8239 - val_factorized_top_k/top_3_categorical_accuracy: 0.2255 - val_factorized_top_k/top_5_categorical_accuracy: 0.2884 - val_factorized_top_k/top_10_categorical_accuracy: 0.3943 - val_factorized_top_k/top_15_categorical_accuracy: 0.4732 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2438.2969 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2438.2969 - lr: 0.0060\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8746 - factorized_top_k/top_5_categorical_accuracy: 0.9341 - factorized_top_k/top_10_categorical_accuracy: 0.9640 - factorized_top_k/top_15_categorical_accuracy: 0.9732 - factorized_top_k/top_25_categorical_accuracy: 0.9828 - loss: 1050.7882 - regularization_loss: 0.0000e+00 - total_loss: 1050.7882 - val_factorized_top_k/top_3_categorical_accuracy: 0.2267 - val_factorized_top_k/top_5_categorical_accuracy: 0.2872 - val_factorized_top_k/top_10_categorical_accuracy: 0.3874 - val_factorized_top_k/top_15_categorical_accuracy: 0.4677 - val_factorized_top_k/top_25_categorical_accuracy: 0.5963 - val_loss: 2456.6541 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2456.6541 - lr: 0.0060\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8757 - factorized_top_k/top_5_categorical_accuracy: 0.9337 - factorized_top_k/top_10_categorical_accuracy: 0.9651 - factorized_top_k/top_15_categorical_accuracy: 0.9740 - factorized_top_k/top_25_categorical_accuracy: 0.9837 - loss: 1047.3605 - regularization_loss: 0.0000e+00 - total_loss: 1047.3605 - val_factorized_top_k/top_3_categorical_accuracy: 0.2232 - val_factorized_top_k/top_5_categorical_accuracy: 0.2887 - val_factorized_top_k/top_10_categorical_accuracy: 0.3943 - val_factorized_top_k/top_15_categorical_accuracy: 0.4714 - val_factorized_top_k/top_25_categorical_accuracy: 0.5931 - val_loss: 2465.7241 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2465.7241 - lr: 0.0060\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8769 - factorized_top_k/top_5_categorical_accuracy: 0.9355 - factorized_top_k/top_10_categorical_accuracy: 0.9651 - factorized_top_k/top_15_categorical_accuracy: 0.9746 - factorized_top_k/top_25_categorical_accuracy: 0.9841 - loss: 1048.0279 - regularization_loss: 0.0000e+00 - total_loss: 1048.0279 - val_factorized_top_k/top_3_categorical_accuracy: 0.2189 - val_factorized_top_k/top_5_categorical_accuracy: 0.2829 - val_factorized_top_k/top_10_categorical_accuracy: 0.3811 - val_factorized_top_k/top_15_categorical_accuracy: 0.4594 - val_factorized_top_k/top_25_categorical_accuracy: 0.5854 - val_loss: 2479.6267 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2479.6267 - lr: 0.0060\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8789 - factorized_top_k/top_5_categorical_accuracy: 0.9363 - factorized_top_k/top_10_categorical_accuracy: 0.9662 - factorized_top_k/top_15_categorical_accuracy: 0.9755 - factorized_top_k/top_25_categorical_accuracy: 0.9848 - loss: 1041.9588 - regularization_loss: 0.0000e+00 - total_loss: 1041.9588 - val_factorized_top_k/top_3_categorical_accuracy: 0.2227 - val_factorized_top_k/top_5_categorical_accuracy: 0.2821 - val_factorized_top_k/top_10_categorical_accuracy: 0.3842 - val_factorized_top_k/top_15_categorical_accuracy: 0.4697 - val_factorized_top_k/top_25_categorical_accuracy: 0.5948 - val_loss: 2496.4587 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2496.4587 - lr: 0.0060\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8787 - factorized_top_k/top_5_categorical_accuracy: 0.9379 - factorized_top_k/top_10_categorical_accuracy: 0.9669 - factorized_top_k/top_15_categorical_accuracy: 0.9763 - factorized_top_k/top_25_categorical_accuracy: 0.9856 - loss: 1042.6156 - regularization_loss: 0.0000e+00 - total_loss: 1042.6156 - val_factorized_top_k/top_3_categorical_accuracy: 0.2161 - val_factorized_top_k/top_5_categorical_accuracy: 0.2824 - val_factorized_top_k/top_10_categorical_accuracy: 0.3802 - val_factorized_top_k/top_15_categorical_accuracy: 0.4585 - val_factorized_top_k/top_25_categorical_accuracy: 0.5877 - val_loss: 2504.9023 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2504.9023 - lr: 0.0060\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8782 - factorized_top_k/top_5_categorical_accuracy: 0.9382 - factorized_top_k/top_10_categorical_accuracy: 0.9681 - factorized_top_k/top_15_categorical_accuracy: 0.9768 - factorized_top_k/top_25_categorical_accuracy: 0.9861 - loss: 1039.8349 - regularization_loss: 0.0000e+00 - total_loss: 1039.8349 - val_factorized_top_k/top_3_categorical_accuracy: 0.2207 - val_factorized_top_k/top_5_categorical_accuracy: 0.2795 - val_factorized_top_k/top_10_categorical_accuracy: 0.3808 - val_factorized_top_k/top_15_categorical_accuracy: 0.4582 - val_factorized_top_k/top_25_categorical_accuracy: 0.5888 - val_loss: 2516.2000 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2516.2000 - lr: 0.0060\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8788 - factorized_top_k/top_5_categorical_accuracy: 0.9385 - factorized_top_k/top_10_categorical_accuracy: 0.9684 - factorized_top_k/top_15_categorical_accuracy: 0.9768 - factorized_top_k/top_25_categorical_accuracy: 0.9862 - loss: 1036.5959 - regularization_loss: 0.0000e+00 - total_loss: 1036.5959 - val_factorized_top_k/top_3_categorical_accuracy: 0.2158 - val_factorized_top_k/top_5_categorical_accuracy: 0.2778 - val_factorized_top_k/top_10_categorical_accuracy: 0.3834 - val_factorized_top_k/top_15_categorical_accuracy: 0.4692 - val_factorized_top_k/top_25_categorical_accuracy: 0.5914 - val_loss: 2529.6050 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2529.6050 - lr: 0.0060\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8786 - factorized_top_k/top_5_categorical_accuracy: 0.9387 - factorized_top_k/top_10_categorical_accuracy: 0.9692 - factorized_top_k/top_15_categorical_accuracy: 0.9776 - factorized_top_k/top_25_categorical_accuracy: 0.9864 - loss: 1034.9675 - regularization_loss: 0.0000e+00 - total_loss: 1034.9675 - val_factorized_top_k/top_3_categorical_accuracy: 0.2172 - val_factorized_top_k/top_5_categorical_accuracy: 0.2803 - val_factorized_top_k/top_10_categorical_accuracy: 0.3877 - val_factorized_top_k/top_15_categorical_accuracy: 0.4620 - val_factorized_top_k/top_25_categorical_accuracy: 0.5931 - val_loss: 2533.0405 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2533.0405 - lr: 0.0060\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8851 - factorized_top_k/top_5_categorical_accuracy: 0.9431 - factorized_top_k/top_10_categorical_accuracy: 0.9710 - factorized_top_k/top_15_categorical_accuracy: 0.9793 - factorized_top_k/top_25_categorical_accuracy: 0.9881 - loss: 1022.0497 - regularization_loss: 0.0000e+00 - total_loss: 1022.0497 - val_factorized_top_k/top_3_categorical_accuracy: 0.2149 - val_factorized_top_k/top_5_categorical_accuracy: 0.2769 - val_factorized_top_k/top_10_categorical_accuracy: 0.3799 - val_factorized_top_k/top_15_categorical_accuracy: 0.4671 - val_factorized_top_k/top_25_categorical_accuracy: 0.5900 - val_loss: 2543.2937 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2543.2937 - lr: 0.0036\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8855 - factorized_top_k/top_5_categorical_accuracy: 0.9433 - factorized_top_k/top_10_categorical_accuracy: 0.9717 - factorized_top_k/top_15_categorical_accuracy: 0.9798 - factorized_top_k/top_25_categorical_accuracy: 0.9881 - loss: 1019.9313 - regularization_loss: 0.0000e+00 - total_loss: 1019.9313 - val_factorized_top_k/top_3_categorical_accuracy: 0.2146 - val_factorized_top_k/top_5_categorical_accuracy: 0.2780 - val_factorized_top_k/top_10_categorical_accuracy: 0.3805 - val_factorized_top_k/top_15_categorical_accuracy: 0.4677 - val_factorized_top_k/top_25_categorical_accuracy: 0.5948 - val_loss: 2551.3306 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2551.3306 - lr: 0.0036\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8849 - factorized_top_k/top_5_categorical_accuracy: 0.9434 - factorized_top_k/top_10_categorical_accuracy: 0.9720 - factorized_top_k/top_15_categorical_accuracy: 0.9801 - factorized_top_k/top_25_categorical_accuracy: 0.9879 - loss: 1018.6036 - regularization_loss: 0.0000e+00 - total_loss: 1018.6036 - val_factorized_top_k/top_3_categorical_accuracy: 0.2166 - val_factorized_top_k/top_5_categorical_accuracy: 0.2763 - val_factorized_top_k/top_10_categorical_accuracy: 0.3768 - val_factorized_top_k/top_15_categorical_accuracy: 0.4591 - val_factorized_top_k/top_25_categorical_accuracy: 0.5888 - val_loss: 2561.1575 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2561.1575 - lr: 0.0036\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8865 - factorized_top_k/top_5_categorical_accuracy: 0.9449 - factorized_top_k/top_10_categorical_accuracy: 0.9725 - factorized_top_k/top_15_categorical_accuracy: 0.9801 - factorized_top_k/top_25_categorical_accuracy: 0.9883 - loss: 1016.9996 - regularization_loss: 0.0000e+00 - total_loss: 1016.9996 - val_factorized_top_k/top_3_categorical_accuracy: 0.2106 - val_factorized_top_k/top_5_categorical_accuracy: 0.2755 - val_factorized_top_k/top_10_categorical_accuracy: 0.3805 - val_factorized_top_k/top_15_categorical_accuracy: 0.4623 - val_factorized_top_k/top_25_categorical_accuracy: 0.5905 - val_loss: 2566.8293 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2566.8293 - lr: 0.0036\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8853 - factorized_top_k/top_5_categorical_accuracy: 0.9436 - factorized_top_k/top_10_categorical_accuracy: 0.9730 - factorized_top_k/top_15_categorical_accuracy: 0.9804 - factorized_top_k/top_25_categorical_accuracy: 0.9884 - loss: 1016.9083 - regularization_loss: 0.0000e+00 - total_loss: 1016.9083 - val_factorized_top_k/top_3_categorical_accuracy: 0.2143 - val_factorized_top_k/top_5_categorical_accuracy: 0.2743 - val_factorized_top_k/top_10_categorical_accuracy: 0.3813 - val_factorized_top_k/top_15_categorical_accuracy: 0.4703 - val_factorized_top_k/top_25_categorical_accuracy: 0.5940 - val_loss: 2575.0769 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2575.0769 - lr: 0.0036\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8846 - factorized_top_k/top_5_categorical_accuracy: 0.9439 - factorized_top_k/top_10_categorical_accuracy: 0.9734 - factorized_top_k/top_15_categorical_accuracy: 0.9806 - factorized_top_k/top_25_categorical_accuracy: 0.9885 - loss: 1014.8591 - regularization_loss: 0.0000e+00 - total_loss: 1014.8591 - val_factorized_top_k/top_3_categorical_accuracy: 0.2164 - val_factorized_top_k/top_5_categorical_accuracy: 0.2740 - val_factorized_top_k/top_10_categorical_accuracy: 0.3791 - val_factorized_top_k/top_15_categorical_accuracy: 0.4692 - val_factorized_top_k/top_25_categorical_accuracy: 0.5957 - val_loss: 2579.3975 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2579.3975 - lr: 0.0036\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8863 - factorized_top_k/top_5_categorical_accuracy: 0.9441 - factorized_top_k/top_10_categorical_accuracy: 0.9732 - factorized_top_k/top_15_categorical_accuracy: 0.9810 - factorized_top_k/top_25_categorical_accuracy: 0.9886 - loss: 1015.2757 - regularization_loss: 0.0000e+00 - total_loss: 1015.2757 - val_factorized_top_k/top_3_categorical_accuracy: 0.2141 - val_factorized_top_k/top_5_categorical_accuracy: 0.2743 - val_factorized_top_k/top_10_categorical_accuracy: 0.3759 - val_factorized_top_k/top_15_categorical_accuracy: 0.4600 - val_factorized_top_k/top_25_categorical_accuracy: 0.5879 - val_loss: 2587.7371 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2587.7371 - lr: 0.0036\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8858 - factorized_top_k/top_5_categorical_accuracy: 0.9439 - factorized_top_k/top_10_categorical_accuracy: 0.9731 - factorized_top_k/top_15_categorical_accuracy: 0.9814 - factorized_top_k/top_25_categorical_accuracy: 0.9888 - loss: 1014.2088 - regularization_loss: 0.0000e+00 - total_loss: 1014.2088 - val_factorized_top_k/top_3_categorical_accuracy: 0.2143 - val_factorized_top_k/top_5_categorical_accuracy: 0.2694 - val_factorized_top_k/top_10_categorical_accuracy: 0.3779 - val_factorized_top_k/top_15_categorical_accuracy: 0.4637 - val_factorized_top_k/top_25_categorical_accuracy: 0.5945 - val_loss: 2595.9543 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2595.9543 - lr: 0.0036\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8855 - factorized_top_k/top_5_categorical_accuracy: 0.9456 - factorized_top_k/top_10_categorical_accuracy: 0.9738 - factorized_top_k/top_15_categorical_accuracy: 0.9813 - factorized_top_k/top_25_categorical_accuracy: 0.9894 - loss: 1013.1078 - regularization_loss: 0.0000e+00 - total_loss: 1013.1078 - val_factorized_top_k/top_3_categorical_accuracy: 0.2100 - val_factorized_top_k/top_5_categorical_accuracy: 0.2735 - val_factorized_top_k/top_10_categorical_accuracy: 0.3788 - val_factorized_top_k/top_15_categorical_accuracy: 0.4692 - val_factorized_top_k/top_25_categorical_accuracy: 0.5971 - val_loss: 2601.2983 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2601.2983 - lr: 0.0036\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8911 - factorized_top_k/top_5_categorical_accuracy: 0.9478 - factorized_top_k/top_10_categorical_accuracy: 0.9748 - factorized_top_k/top_15_categorical_accuracy: 0.9823 - factorized_top_k/top_25_categorical_accuracy: 0.9898 - loss: 1005.0641 - regularization_loss: 0.0000e+00 - total_loss: 1005.0641 - val_factorized_top_k/top_3_categorical_accuracy: 0.2143 - val_factorized_top_k/top_5_categorical_accuracy: 0.2717 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4631 - val_factorized_top_k/top_25_categorical_accuracy: 0.5934 - val_loss: 2605.4092 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2605.4092 - lr: 0.0022\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8906 - factorized_top_k/top_5_categorical_accuracy: 0.9481 - factorized_top_k/top_10_categorical_accuracy: 0.9751 - factorized_top_k/top_15_categorical_accuracy: 0.9826 - factorized_top_k/top_25_categorical_accuracy: 0.9899 - loss: 1005.0428 - regularization_loss: 0.0000e+00 - total_loss: 1005.0428 - val_factorized_top_k/top_3_categorical_accuracy: 0.2098 - val_factorized_top_k/top_5_categorical_accuracy: 0.2686 - val_factorized_top_k/top_10_categorical_accuracy: 0.3770 - val_factorized_top_k/top_15_categorical_accuracy: 0.4674 - val_factorized_top_k/top_25_categorical_accuracy: 0.5945 - val_loss: 2611.1741 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2611.1741 - lr: 0.0022\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8905 - factorized_top_k/top_5_categorical_accuracy: 0.9477 - factorized_top_k/top_10_categorical_accuracy: 0.9755 - factorized_top_k/top_15_categorical_accuracy: 0.9828 - factorized_top_k/top_25_categorical_accuracy: 0.9901 - loss: 1004.6757 - regularization_loss: 0.0000e+00 - total_loss: 1004.6757 - val_factorized_top_k/top_3_categorical_accuracy: 0.2118 - val_factorized_top_k/top_5_categorical_accuracy: 0.2694 - val_factorized_top_k/top_10_categorical_accuracy: 0.3759 - val_factorized_top_k/top_15_categorical_accuracy: 0.4657 - val_factorized_top_k/top_25_categorical_accuracy: 0.5934 - val_loss: 2614.8232 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2614.8232 - lr: 0.0022\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8915 - factorized_top_k/top_5_categorical_accuracy: 0.9479 - factorized_top_k/top_10_categorical_accuracy: 0.9759 - factorized_top_k/top_15_categorical_accuracy: 0.9829 - factorized_top_k/top_25_categorical_accuracy: 0.9900 - loss: 1003.5928 - regularization_loss: 0.0000e+00 - total_loss: 1003.5928 - val_factorized_top_k/top_3_categorical_accuracy: 0.2109 - val_factorized_top_k/top_5_categorical_accuracy: 0.2686 - val_factorized_top_k/top_10_categorical_accuracy: 0.3753 - val_factorized_top_k/top_15_categorical_accuracy: 0.4640 - val_factorized_top_k/top_25_categorical_accuracy: 0.5928 - val_loss: 2620.3103 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2620.3103 - lr: 0.0022\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8913 - factorized_top_k/top_5_categorical_accuracy: 0.9482 - factorized_top_k/top_10_categorical_accuracy: 0.9755 - factorized_top_k/top_15_categorical_accuracy: 0.9827 - factorized_top_k/top_25_categorical_accuracy: 0.9902 - loss: 1001.9692 - regularization_loss: 0.0000e+00 - total_loss: 1001.9692 - val_factorized_top_k/top_3_categorical_accuracy: 0.2103 - val_factorized_top_k/top_5_categorical_accuracy: 0.2700 - val_factorized_top_k/top_10_categorical_accuracy: 0.3791 - val_factorized_top_k/top_15_categorical_accuracy: 0.4666 - val_factorized_top_k/top_25_categorical_accuracy: 0.5974 - val_loss: 2626.5818 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2626.5818 - lr: 0.0022\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8895 - factorized_top_k/top_5_categorical_accuracy: 0.9483 - factorized_top_k/top_10_categorical_accuracy: 0.9759 - factorized_top_k/top_15_categorical_accuracy: 0.9833 - factorized_top_k/top_25_categorical_accuracy: 0.9901 - loss: 1001.6215 - regularization_loss: 0.0000e+00 - total_loss: 1001.6215 - val_factorized_top_k/top_3_categorical_accuracy: 0.2106 - val_factorized_top_k/top_5_categorical_accuracy: 0.2651 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4680 - val_factorized_top_k/top_25_categorical_accuracy: 0.5977 - val_loss: 2632.2646 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2632.2646 - lr: 0.0022\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8909 - factorized_top_k/top_5_categorical_accuracy: 0.9482 - factorized_top_k/top_10_categorical_accuracy: 0.9761 - factorized_top_k/top_15_categorical_accuracy: 0.9829 - factorized_top_k/top_25_categorical_accuracy: 0.9900 - loss: 1001.7659 - regularization_loss: 0.0000e+00 - total_loss: 1001.7659 - val_factorized_top_k/top_3_categorical_accuracy: 0.2100 - val_factorized_top_k/top_5_categorical_accuracy: 0.2697 - val_factorized_top_k/top_10_categorical_accuracy: 0.3805 - val_factorized_top_k/top_15_categorical_accuracy: 0.4703 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2632.6133 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2632.6133 - lr: 0.0022\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8908 - factorized_top_k/top_5_categorical_accuracy: 0.9484 - factorized_top_k/top_10_categorical_accuracy: 0.9761 - factorized_top_k/top_15_categorical_accuracy: 0.9828 - factorized_top_k/top_25_categorical_accuracy: 0.9902 - loss: 1003.8301 - regularization_loss: 0.0000e+00 - total_loss: 1003.8301 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2697 - val_factorized_top_k/top_10_categorical_accuracy: 0.3776 - val_factorized_top_k/top_15_categorical_accuracy: 0.4694 - val_factorized_top_k/top_25_categorical_accuracy: 0.5977 - val_loss: 2639.6003 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2639.6003 - lr: 0.0022\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8907 - factorized_top_k/top_5_categorical_accuracy: 0.9492 - factorized_top_k/top_10_categorical_accuracy: 0.9759 - factorized_top_k/top_15_categorical_accuracy: 0.9832 - factorized_top_k/top_25_categorical_accuracy: 0.9904 - loss: 1002.2346 - regularization_loss: 0.0000e+00 - total_loss: 1002.2346 - val_factorized_top_k/top_3_categorical_accuracy: 0.2109 - val_factorized_top_k/top_5_categorical_accuracy: 0.2680 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4646 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2645.2358 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2645.2358 - lr: 0.0022\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8948 - factorized_top_k/top_5_categorical_accuracy: 0.9505 - factorized_top_k/top_10_categorical_accuracy: 0.9768 - factorized_top_k/top_15_categorical_accuracy: 0.9838 - factorized_top_k/top_25_categorical_accuracy: 0.9905 - loss: 997.0601 - regularization_loss: 0.0000e+00 - total_loss: 997.0601 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2692 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4683 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2647.7805 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2647.7805 - lr: 0.0013\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8951 - factorized_top_k/top_5_categorical_accuracy: 0.9506 - factorized_top_k/top_10_categorical_accuracy: 0.9768 - factorized_top_k/top_15_categorical_accuracy: 0.9838 - factorized_top_k/top_25_categorical_accuracy: 0.9905 - loss: 997.3189 - regularization_loss: 0.0000e+00 - total_loss: 997.3189 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4692 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2650.6941 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2650.6941 - lr: 0.0013\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8949 - factorized_top_k/top_5_categorical_accuracy: 0.9501 - factorized_top_k/top_10_categorical_accuracy: 0.9770 - factorized_top_k/top_15_categorical_accuracy: 0.9836 - factorized_top_k/top_25_categorical_accuracy: 0.9910 - loss: 997.3706 - regularization_loss: 0.0000e+00 - total_loss: 997.3706 - val_factorized_top_k/top_3_categorical_accuracy: 0.2092 - val_factorized_top_k/top_5_categorical_accuracy: 0.2674 - val_factorized_top_k/top_10_categorical_accuracy: 0.3776 - val_factorized_top_k/top_15_categorical_accuracy: 0.4700 - val_factorized_top_k/top_25_categorical_accuracy: 0.6017 - val_loss: 2651.5610 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2651.5610 - lr: 0.0013\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8946 - factorized_top_k/top_5_categorical_accuracy: 0.9509 - factorized_top_k/top_10_categorical_accuracy: 0.9770 - factorized_top_k/top_15_categorical_accuracy: 0.9837 - factorized_top_k/top_25_categorical_accuracy: 0.9909 - loss: 994.6639 - regularization_loss: 0.0000e+00 - total_loss: 994.6639 - val_factorized_top_k/top_3_categorical_accuracy: 0.2100 - val_factorized_top_k/top_5_categorical_accuracy: 0.2669 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4714 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2654.1555 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2654.1555 - lr: 0.0013\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8953 - factorized_top_k/top_5_categorical_accuracy: 0.9508 - factorized_top_k/top_10_categorical_accuracy: 0.9770 - factorized_top_k/top_15_categorical_accuracy: 0.9840 - factorized_top_k/top_25_categorical_accuracy: 0.9909 - loss: 997.6251 - regularization_loss: 0.0000e+00 - total_loss: 997.6251 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2657 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4689 - val_factorized_top_k/top_25_categorical_accuracy: 0.5980 - val_loss: 2655.8403 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2655.8403 - lr: 0.0013\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8955 - factorized_top_k/top_5_categorical_accuracy: 0.9511 - factorized_top_k/top_10_categorical_accuracy: 0.9771 - factorized_top_k/top_15_categorical_accuracy: 0.9839 - factorized_top_k/top_25_categorical_accuracy: 0.9909 - loss: 994.4328 - regularization_loss: 0.0000e+00 - total_loss: 994.4328 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2689 - val_factorized_top_k/top_10_categorical_accuracy: 0.3768 - val_factorized_top_k/top_15_categorical_accuracy: 0.4714 - val_factorized_top_k/top_25_categorical_accuracy: 0.5980 - val_loss: 2658.6899 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2658.6899 - lr: 0.0013\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8950 - factorized_top_k/top_5_categorical_accuracy: 0.9501 - factorized_top_k/top_10_categorical_accuracy: 0.9769 - factorized_top_k/top_15_categorical_accuracy: 0.9841 - factorized_top_k/top_25_categorical_accuracy: 0.9910 - loss: 997.5681 - regularization_loss: 0.0000e+00 - total_loss: 997.5681 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2686 - val_factorized_top_k/top_10_categorical_accuracy: 0.3770 - val_factorized_top_k/top_15_categorical_accuracy: 0.4717 - val_factorized_top_k/top_25_categorical_accuracy: 0.5977 - val_loss: 2661.5642 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2661.5642 - lr: 0.0013\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8952 - factorized_top_k/top_5_categorical_accuracy: 0.9508 - factorized_top_k/top_10_categorical_accuracy: 0.9771 - factorized_top_k/top_15_categorical_accuracy: 0.9839 - factorized_top_k/top_25_categorical_accuracy: 0.9909 - loss: 994.8752 - regularization_loss: 0.0000e+00 - total_loss: 994.8752 - val_factorized_top_k/top_3_categorical_accuracy: 0.2092 - val_factorized_top_k/top_5_categorical_accuracy: 0.2663 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4680 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2663.5935 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2663.5935 - lr: 0.0013\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8944 - factorized_top_k/top_5_categorical_accuracy: 0.9513 - factorized_top_k/top_10_categorical_accuracy: 0.9771 - factorized_top_k/top_15_categorical_accuracy: 0.9838 - factorized_top_k/top_25_categorical_accuracy: 0.9910 - loss: 993.6212 - regularization_loss: 0.0000e+00 - total_loss: 993.6212 - val_factorized_top_k/top_3_categorical_accuracy: 0.2121 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3762 - val_factorized_top_k/top_15_categorical_accuracy: 0.4723 - val_factorized_top_k/top_25_categorical_accuracy: 0.6009 - val_loss: 2665.8618 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2665.8618 - lr: 0.0013\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8976 - factorized_top_k/top_5_categorical_accuracy: 0.9521 - factorized_top_k/top_10_categorical_accuracy: 0.9773 - factorized_top_k/top_15_categorical_accuracy: 0.9843 - factorized_top_k/top_25_categorical_accuracy: 0.9911 - loss: 991.2785 - regularization_loss: 0.0000e+00 - total_loss: 991.2785 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2671 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4726 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2667.6306 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2667.6306 - lr: 7.7760e-04\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8976 - factorized_top_k/top_5_categorical_accuracy: 0.9517 - factorized_top_k/top_10_categorical_accuracy: 0.9776 - factorized_top_k/top_15_categorical_accuracy: 0.9843 - factorized_top_k/top_25_categorical_accuracy: 0.9912 - loss: 992.5338 - regularization_loss: 0.0000e+00 - total_loss: 992.5338 - val_factorized_top_k/top_3_categorical_accuracy: 0.2095 - val_factorized_top_k/top_5_categorical_accuracy: 0.2657 - val_factorized_top_k/top_10_categorical_accuracy: 0.3707 - val_factorized_top_k/top_15_categorical_accuracy: 0.4700 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2670.3169 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2670.3169 - lr: 7.7760e-04\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8979 - factorized_top_k/top_5_categorical_accuracy: 0.9524 - factorized_top_k/top_10_categorical_accuracy: 0.9778 - factorized_top_k/top_15_categorical_accuracy: 0.9842 - factorized_top_k/top_25_categorical_accuracy: 0.9913 - loss: 992.2543 - regularization_loss: 0.0000e+00 - total_loss: 992.2543 - val_factorized_top_k/top_3_categorical_accuracy: 0.2098 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3702 - val_factorized_top_k/top_15_categorical_accuracy: 0.4717 - val_factorized_top_k/top_25_categorical_accuracy: 0.6014 - val_loss: 2671.9392 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2671.9392 - lr: 7.7760e-04\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8978 - factorized_top_k/top_5_categorical_accuracy: 0.9523 - factorized_top_k/top_10_categorical_accuracy: 0.9781 - factorized_top_k/top_15_categorical_accuracy: 0.9844 - factorized_top_k/top_25_categorical_accuracy: 0.9911 - loss: 993.4644 - regularization_loss: 0.0000e+00 - total_loss: 993.4644 - val_factorized_top_k/top_3_categorical_accuracy: 0.2103 - val_factorized_top_k/top_5_categorical_accuracy: 0.2663 - val_factorized_top_k/top_10_categorical_accuracy: 0.3716 - val_factorized_top_k/top_15_categorical_accuracy: 0.4714 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2673.3730 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2673.3730 - lr: 7.7760e-04\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8977 - factorized_top_k/top_5_categorical_accuracy: 0.9526 - factorized_top_k/top_10_categorical_accuracy: 0.9777 - factorized_top_k/top_15_categorical_accuracy: 0.9844 - factorized_top_k/top_25_categorical_accuracy: 0.9911 - loss: 990.9107 - regularization_loss: 0.0000e+00 - total_loss: 990.9107 - val_factorized_top_k/top_3_categorical_accuracy: 0.2103 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3713 - val_factorized_top_k/top_15_categorical_accuracy: 0.4717 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2675.2798 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2675.2798 - lr: 7.7760e-04\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8982 - factorized_top_k/top_5_categorical_accuracy: 0.9523 - factorized_top_k/top_10_categorical_accuracy: 0.9780 - factorized_top_k/top_15_categorical_accuracy: 0.9845 - factorized_top_k/top_25_categorical_accuracy: 0.9912 - loss: 992.0680 - regularization_loss: 0.0000e+00 - total_loss: 992.0680 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4700 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2677.6167 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2677.6167 - lr: 7.7760e-04\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8987 - factorized_top_k/top_5_categorical_accuracy: 0.9522 - factorized_top_k/top_10_categorical_accuracy: 0.9779 - factorized_top_k/top_15_categorical_accuracy: 0.9845 - factorized_top_k/top_25_categorical_accuracy: 0.9912 - loss: 989.4356 - regularization_loss: 0.0000e+00 - total_loss: 989.4356 - val_factorized_top_k/top_3_categorical_accuracy: 0.2115 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4709 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2680.5051 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2680.5051 - lr: 7.7760e-04\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8979 - factorized_top_k/top_5_categorical_accuracy: 0.9531 - factorized_top_k/top_10_categorical_accuracy: 0.9779 - factorized_top_k/top_15_categorical_accuracy: 0.9847 - factorized_top_k/top_25_categorical_accuracy: 0.9913 - loss: 990.7486 - regularization_loss: 0.0000e+00 - total_loss: 990.7486 - val_factorized_top_k/top_3_categorical_accuracy: 0.2095 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3704 - val_factorized_top_k/top_15_categorical_accuracy: 0.4692 - val_factorized_top_k/top_25_categorical_accuracy: 0.5971 - val_loss: 2681.3813 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2681.3813 - lr: 7.7760e-04\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8977 - factorized_top_k/top_5_categorical_accuracy: 0.9524 - factorized_top_k/top_10_categorical_accuracy: 0.9781 - factorized_top_k/top_15_categorical_accuracy: 0.9847 - factorized_top_k/top_25_categorical_accuracy: 0.9911 - loss: 991.3185 - regularization_loss: 0.0000e+00 - total_loss: 991.3185 - val_factorized_top_k/top_3_categorical_accuracy: 0.2103 - val_factorized_top_k/top_5_categorical_accuracy: 0.2657 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4709 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2683.1814 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2683.1814 - lr: 7.7760e-04\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8989 - factorized_top_k/top_5_categorical_accuracy: 0.9528 - factorized_top_k/top_10_categorical_accuracy: 0.9782 - factorized_top_k/top_15_categorical_accuracy: 0.9848 - factorized_top_k/top_25_categorical_accuracy: 0.9914 - loss: 990.7162 - regularization_loss: 0.0000e+00 - total_loss: 990.7162 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4709 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2684.2500 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2684.2500 - lr: 4.6656e-04\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9009 - factorized_top_k/top_5_categorical_accuracy: 0.9533 - factorized_top_k/top_10_categorical_accuracy: 0.9785 - factorized_top_k/top_15_categorical_accuracy: 0.9848 - factorized_top_k/top_25_categorical_accuracy: 0.9914 - loss: 988.3403 - regularization_loss: 0.0000e+00 - total_loss: 988.3403 - val_factorized_top_k/top_3_categorical_accuracy: 0.2086 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4703 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2685.2705 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2685.2705 - lr: 4.6656e-04\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8994 - factorized_top_k/top_5_categorical_accuracy: 0.9525 - factorized_top_k/top_10_categorical_accuracy: 0.9783 - factorized_top_k/top_15_categorical_accuracy: 0.9847 - factorized_top_k/top_25_categorical_accuracy: 0.9915 - loss: 988.6900 - regularization_loss: 0.0000e+00 - total_loss: 988.6900 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2680 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4712 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2686.3689 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2686.3689 - lr: 4.6656e-04\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9005 - factorized_top_k/top_5_categorical_accuracy: 0.9525 - factorized_top_k/top_10_categorical_accuracy: 0.9784 - factorized_top_k/top_15_categorical_accuracy: 0.9848 - factorized_top_k/top_25_categorical_accuracy: 0.9915 - loss: 986.7282 - regularization_loss: 0.0000e+00 - total_loss: 986.7282 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2686 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4729 - val_factorized_top_k/top_25_categorical_accuracy: 0.5977 - val_loss: 2688.2065 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2688.2065 - lr: 4.6656e-04\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8992 - factorized_top_k/top_5_categorical_accuracy: 0.9528 - factorized_top_k/top_10_categorical_accuracy: 0.9785 - factorized_top_k/top_15_categorical_accuracy: 0.9846 - factorized_top_k/top_25_categorical_accuracy: 0.9915 - loss: 988.7402 - regularization_loss: 0.0000e+00 - total_loss: 988.7402 - val_factorized_top_k/top_3_categorical_accuracy: 0.2095 - val_factorized_top_k/top_5_categorical_accuracy: 0.2651 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4717 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2689.2314 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2689.2314 - lr: 4.6656e-04\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8996 - factorized_top_k/top_5_categorical_accuracy: 0.9531 - factorized_top_k/top_10_categorical_accuracy: 0.9783 - factorized_top_k/top_15_categorical_accuracy: 0.9848 - factorized_top_k/top_25_categorical_accuracy: 0.9915 - loss: 989.0007 - regularization_loss: 0.0000e+00 - total_loss: 989.0007 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4717 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2690.2417 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2690.2417 - lr: 4.6656e-04\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9002 - factorized_top_k/top_5_categorical_accuracy: 0.9535 - factorized_top_k/top_10_categorical_accuracy: 0.9784 - factorized_top_k/top_15_categorical_accuracy: 0.9848 - factorized_top_k/top_25_categorical_accuracy: 0.9916 - loss: 988.8952 - regularization_loss: 0.0000e+00 - total_loss: 988.8952 - val_factorized_top_k/top_3_categorical_accuracy: 0.2092 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4735 - val_factorized_top_k/top_25_categorical_accuracy: 0.5968 - val_loss: 2691.4910 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2691.4910 - lr: 4.6656e-04\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8998 - factorized_top_k/top_5_categorical_accuracy: 0.9534 - factorized_top_k/top_10_categorical_accuracy: 0.9784 - factorized_top_k/top_15_categorical_accuracy: 0.9848 - factorized_top_k/top_25_categorical_accuracy: 0.9916 - loss: 988.4294 - regularization_loss: 0.0000e+00 - total_loss: 988.4294 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4726 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2692.8491 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2692.8491 - lr: 4.6656e-04\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.8996 - factorized_top_k/top_5_categorical_accuracy: 0.9527 - factorized_top_k/top_10_categorical_accuracy: 0.9786 - factorized_top_k/top_15_categorical_accuracy: 0.9848 - factorized_top_k/top_25_categorical_accuracy: 0.9916 - loss: 987.0177 - regularization_loss: 0.0000e+00 - total_loss: 987.0177 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3759 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2693.9563 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2693.9563 - lr: 4.6656e-04\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9013 - factorized_top_k/top_5_categorical_accuracy: 0.9536 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9850 - factorized_top_k/top_25_categorical_accuracy: 0.9916 - loss: 986.9726 - regularization_loss: 0.0000e+00 - total_loss: 986.9726 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2623 - val_factorized_top_k/top_10_categorical_accuracy: 0.3745 - val_factorized_top_k/top_15_categorical_accuracy: 0.4726 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2694.5989 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2694.5989 - lr: 2.7994e-04\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9005 - factorized_top_k/top_5_categorical_accuracy: 0.9534 - factorized_top_k/top_10_categorical_accuracy: 0.9786 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 988.4488 - regularization_loss: 0.0000e+00 - total_loss: 988.4488 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2651 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2695.6914 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2695.6914 - lr: 2.7994e-04\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9013 - factorized_top_k/top_5_categorical_accuracy: 0.9530 - factorized_top_k/top_10_categorical_accuracy: 0.9787 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 987.1535 - regularization_loss: 0.0000e+00 - total_loss: 987.1535 - val_factorized_top_k/top_3_categorical_accuracy: 0.2046 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4729 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2696.3560 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2696.3560 - lr: 2.7994e-04\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9014 - factorized_top_k/top_5_categorical_accuracy: 0.9535 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 987.2800 - regularization_loss: 0.0000e+00 - total_loss: 987.2800 - val_factorized_top_k/top_3_categorical_accuracy: 0.2083 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4726 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2696.9719 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2696.9719 - lr: 2.7994e-04\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9012 - factorized_top_k/top_5_categorical_accuracy: 0.9538 - factorized_top_k/top_10_categorical_accuracy: 0.9787 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 987.4454 - regularization_loss: 0.0000e+00 - total_loss: 987.4454 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3745 - val_factorized_top_k/top_15_categorical_accuracy: 0.4735 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2697.7349 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2697.7349 - lr: 2.7994e-04\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9015 - factorized_top_k/top_5_categorical_accuracy: 0.9538 - factorized_top_k/top_10_categorical_accuracy: 0.9787 - factorized_top_k/top_15_categorical_accuracy: 0.9850 - factorized_top_k/top_25_categorical_accuracy: 0.9916 - loss: 986.0854 - regularization_loss: 0.0000e+00 - total_loss: 986.0854 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2626 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4726 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2698.9343 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2698.9343 - lr: 2.7994e-04\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9015 - factorized_top_k/top_5_categorical_accuracy: 0.9538 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9850 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.6612 - regularization_loss: 0.0000e+00 - total_loss: 985.6612 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2623 - val_factorized_top_k/top_10_categorical_accuracy: 0.3750 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2699.3567 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2699.3567 - lr: 2.7994e-04\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9009 - factorized_top_k/top_5_categorical_accuracy: 0.9535 - factorized_top_k/top_10_categorical_accuracy: 0.9788 - factorized_top_k/top_15_categorical_accuracy: 0.9850 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 988.0554 - regularization_loss: 0.0000e+00 - total_loss: 988.0554 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3713 - val_factorized_top_k/top_15_categorical_accuracy: 0.4778 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2699.7434 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2699.7434 - lr: 2.7994e-04\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9012 - factorized_top_k/top_5_categorical_accuracy: 0.9538 - factorized_top_k/top_10_categorical_accuracy: 0.9788 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 986.6029 - regularization_loss: 0.0000e+00 - total_loss: 986.6029 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3750 - val_factorized_top_k/top_15_categorical_accuracy: 0.4746 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2700.5630 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2700.5630 - lr: 2.7994e-04\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9023 - factorized_top_k/top_5_categorical_accuracy: 0.9542 - factorized_top_k/top_10_categorical_accuracy: 0.9788 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 987.6956 - regularization_loss: 0.0000e+00 - total_loss: 987.6956 - val_factorized_top_k/top_3_categorical_accuracy: 0.2046 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4746 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2701.1079 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2701.1079 - lr: 1.6796e-04\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9021 - factorized_top_k/top_5_categorical_accuracy: 0.9534 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9850 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.6969 - regularization_loss: 0.0000e+00 - total_loss: 984.6969 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4763 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2701.7842 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2701.7842 - lr: 1.6796e-04\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9023 - factorized_top_k/top_5_categorical_accuracy: 0.9538 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 984.4776 - regularization_loss: 0.0000e+00 - total_loss: 984.4776 - val_factorized_top_k/top_3_categorical_accuracy: 0.2083 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2702.2153 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2702.2153 - lr: 1.6796e-04\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9017 - factorized_top_k/top_5_categorical_accuracy: 0.9539 - factorized_top_k/top_10_categorical_accuracy: 0.9788 - factorized_top_k/top_15_categorical_accuracy: 0.9850 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.0154 - regularization_loss: 0.0000e+00 - total_loss: 985.0154 - val_factorized_top_k/top_3_categorical_accuracy: 0.2052 - val_factorized_top_k/top_5_categorical_accuracy: 0.2626 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2702.9021 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2702.9021 - lr: 1.6796e-04\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9023 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 986.7707 - regularization_loss: 0.0000e+00 - total_loss: 986.7707 - val_factorized_top_k/top_3_categorical_accuracy: 0.2052 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4746 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2703.4814 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2703.4814 - lr: 1.6796e-04\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9019 - factorized_top_k/top_5_categorical_accuracy: 0.9537 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 985.7481 - regularization_loss: 0.0000e+00 - total_loss: 985.7481 - val_factorized_top_k/top_3_categorical_accuracy: 0.2083 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4763 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2703.9546 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2703.9546 - lr: 1.6796e-04\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9023 - factorized_top_k/top_5_categorical_accuracy: 0.9537 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.6480 - regularization_loss: 0.0000e+00 - total_loss: 985.6480 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2666 - val_factorized_top_k/top_10_categorical_accuracy: 0.3759 - val_factorized_top_k/top_15_categorical_accuracy: 0.4763 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2704.6340 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2704.6340 - lr: 1.6796e-04\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9026 - factorized_top_k/top_5_categorical_accuracy: 0.9539 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9852 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 986.7758 - regularization_loss: 0.0000e+00 - total_loss: 986.7758 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2669 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2705.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2705.0359 - lr: 1.6796e-04\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9013 - factorized_top_k/top_5_categorical_accuracy: 0.9535 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9850 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.5378 - regularization_loss: 0.0000e+00 - total_loss: 986.5378 - val_factorized_top_k/top_3_categorical_accuracy: 0.2040 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4763 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2705.6160 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2705.6160 - lr: 1.6796e-04\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9025 - factorized_top_k/top_5_categorical_accuracy: 0.9536 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9852 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.0006 - regularization_loss: 0.0000e+00 - total_loss: 986.0006 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3759 - val_factorized_top_k/top_15_categorical_accuracy: 0.4740 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2705.9116 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2705.9116 - lr: 1.0078e-04\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9028 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.9395 - regularization_loss: 0.0000e+00 - total_loss: 985.9395 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3753 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2706.2737 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2706.2737 - lr: 1.0078e-04\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9025 - factorized_top_k/top_5_categorical_accuracy: 0.9539 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9917 - loss: 985.4228 - regularization_loss: 0.0000e+00 - total_loss: 985.4228 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2706.4304 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2706.4304 - lr: 1.0078e-04\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9031 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9851 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.8605 - regularization_loss: 0.0000e+00 - total_loss: 983.8605 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.6009 - val_loss: 2706.7878 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2706.7878 - lr: 1.0078e-04\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9029 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9852 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.9628 - regularization_loss: 0.0000e+00 - total_loss: 984.9628 - val_factorized_top_k/top_3_categorical_accuracy: 0.2086 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3745 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.6020 - val_loss: 2707.1902 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2707.1902 - lr: 1.0078e-04\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9028 - factorized_top_k/top_5_categorical_accuracy: 0.9539 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9852 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 986.0757 - regularization_loss: 0.0000e+00 - total_loss: 986.0757 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2707.4297 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2707.4297 - lr: 1.0078e-04\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9026 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 986.4453 - regularization_loss: 0.0000e+00 - total_loss: 986.4453 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2707.8191 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2707.8191 - lr: 1.0078e-04\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9024 - factorized_top_k/top_5_categorical_accuracy: 0.9535 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.8088 - regularization_loss: 0.0000e+00 - total_loss: 984.8088 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2708.2190 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2708.2190 - lr: 1.0078e-04\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9025 - factorized_top_k/top_5_categorical_accuracy: 0.9537 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.5715 - regularization_loss: 0.0000e+00 - total_loss: 984.5715 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3719 - val_factorized_top_k/top_15_categorical_accuracy: 0.4723 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2708.5444 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2708.5444 - lr: 1.0078e-04\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9026 - factorized_top_k/top_5_categorical_accuracy: 0.9539 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9852 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.8453 - regularization_loss: 0.0000e+00 - total_loss: 984.8453 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2620 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2708.7368 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2708.7368 - lr: 6.0466e-05\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9034 - factorized_top_k/top_5_categorical_accuracy: 0.9537 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.8640 - regularization_loss: 0.0000e+00 - total_loss: 983.8640 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2657 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2709.0588 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2709.0588 - lr: 6.0466e-05\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9034 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 986.0468 - regularization_loss: 0.0000e+00 - total_loss: 986.0468 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2709.3645 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2709.3645 - lr: 6.0466e-05\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9029 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 986.1674 - regularization_loss: 0.0000e+00 - total_loss: 986.1674 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4726 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2709.5808 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2709.5808 - lr: 6.0466e-05\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9031 - factorized_top_k/top_5_categorical_accuracy: 0.9541 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 986.1511 - regularization_loss: 0.0000e+00 - total_loss: 986.1511 - val_factorized_top_k/top_3_categorical_accuracy: 0.2098 - val_factorized_top_k/top_5_categorical_accuracy: 0.2631 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4737 - val_factorized_top_k/top_25_categorical_accuracy: 0.5974 - val_loss: 2709.7810 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2709.7810 - lr: 6.0466e-05\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9024 - factorized_top_k/top_5_categorical_accuracy: 0.9539 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.7449 - regularization_loss: 0.0000e+00 - total_loss: 985.7449 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3716 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2710.0005 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2710.0005 - lr: 6.0466e-05\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9026 - factorized_top_k/top_5_categorical_accuracy: 0.9541 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.7021 - regularization_loss: 0.0000e+00 - total_loss: 983.7021 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2663 - val_factorized_top_k/top_10_categorical_accuracy: 0.3753 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2710.2144 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2710.2144 - lr: 6.0466e-05\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9038 - factorized_top_k/top_5_categorical_accuracy: 0.9541 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.6589 - regularization_loss: 0.0000e+00 - total_loss: 984.6589 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2710.5034 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2710.5034 - lr: 6.0466e-05\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9035 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.2503 - regularization_loss: 0.0000e+00 - total_loss: 984.2503 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2710.7585 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2710.7585 - lr: 6.0466e-05\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9030 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.8981 - regularization_loss: 0.0000e+00 - total_loss: 983.8981 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2710.9148 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2710.9148 - lr: 3.6280e-05\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9034 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.4151 - regularization_loss: 0.0000e+00 - total_loss: 984.4151 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2711.0552 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2711.0552 - lr: 3.6280e-05\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9032 - factorized_top_k/top_5_categorical_accuracy: 0.9537 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.9500 - regularization_loss: 0.0000e+00 - total_loss: 983.9500 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2711.1846 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2711.1846 - lr: 3.6280e-05\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9032 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.9982 - regularization_loss: 0.0000e+00 - total_loss: 985.9982 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2711.2822 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2711.2822 - lr: 3.6280e-05\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9033 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.8507 - regularization_loss: 0.0000e+00 - total_loss: 983.8507 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2669 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2711.3750 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2711.3750 - lr: 3.6280e-05\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9036 - factorized_top_k/top_5_categorical_accuracy: 0.9539 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 986.2687 - regularization_loss: 0.0000e+00 - total_loss: 986.2687 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3745 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2711.5342 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2711.5342 - lr: 3.6280e-05\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9033 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.6132 - regularization_loss: 0.0000e+00 - total_loss: 983.6132 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.5980 - val_loss: 2711.7434 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2711.7434 - lr: 3.6280e-05\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9029 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.6568 - regularization_loss: 0.0000e+00 - total_loss: 985.6568 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2711.9016 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2711.9016 - lr: 3.6280e-05\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9031 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.1627 - regularization_loss: 0.0000e+00 - total_loss: 985.1627 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2712.1021 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.1021 - lr: 3.6280e-05\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9030 - factorized_top_k/top_5_categorical_accuracy: 0.9542 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.8831 - regularization_loss: 0.0000e+00 - total_loss: 984.8831 - val_factorized_top_k/top_3_categorical_accuracy: 0.2092 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2712.2065 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.2065 - lr: 2.1768e-05\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9027 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.1074 - regularization_loss: 0.0000e+00 - total_loss: 984.1074 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4775 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2712.2832 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.2832 - lr: 2.1768e-05\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9031 - factorized_top_k/top_5_categorical_accuracy: 0.9547 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.2009 - regularization_loss: 0.0000e+00 - total_loss: 984.2009 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3750 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2712.3975 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.3975 - lr: 2.1768e-05\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9039 - factorized_top_k/top_5_categorical_accuracy: 0.9540 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.7893 - regularization_loss: 0.0000e+00 - total_loss: 984.7893 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2669 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2712.4856 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.4856 - lr: 2.1768e-05\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9036 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.6863 - regularization_loss: 0.0000e+00 - total_loss: 983.6863 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2712.6150 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.6150 - lr: 2.1768e-05\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9039 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.4182 - regularization_loss: 0.0000e+00 - total_loss: 986.4182 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2631 - val_factorized_top_k/top_10_categorical_accuracy: 0.3719 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2712.7122 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.7122 - lr: 2.1768e-05\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9029 - factorized_top_k/top_5_categorical_accuracy: 0.9544 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.2086 - regularization_loss: 0.0000e+00 - total_loss: 986.2086 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3745 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2712.7803 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.7803 - lr: 2.1768e-05\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9031 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.8630 - regularization_loss: 0.0000e+00 - total_loss: 984.8630 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2660 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2712.9058 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2712.9058 - lr: 2.1768e-05\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9034 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.4453 - regularization_loss: 0.0000e+00 - total_loss: 984.4453 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2713.0454 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.0454 - lr: 2.1768e-05\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9029 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.3969 - regularization_loss: 0.0000e+00 - total_loss: 985.3969 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2651 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2713.1023 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.1023 - lr: 1.3061e-05\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9035 - factorized_top_k/top_5_categorical_accuracy: 0.9544 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.1092 - regularization_loss: 0.0000e+00 - total_loss: 984.1092 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2663 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2713.1692 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.1692 - lr: 1.3061e-05\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9032 - factorized_top_k/top_5_categorical_accuracy: 0.9541 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.6179 - regularization_loss: 0.0000e+00 - total_loss: 983.6179 - val_factorized_top_k/top_3_categorical_accuracy: 0.2083 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4763 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2713.2454 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.2454 - lr: 1.3061e-05\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9037 - factorized_top_k/top_5_categorical_accuracy: 0.9542 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 982.4758 - regularization_loss: 0.0000e+00 - total_loss: 982.4758 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3713 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5977 - val_loss: 2713.3135 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.3135 - lr: 1.3061e-05\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9040 - factorized_top_k/top_5_categorical_accuracy: 0.9542 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.9886 - regularization_loss: 0.0000e+00 - total_loss: 983.9886 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2713.3877 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.3877 - lr: 1.3061e-05\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9044 - factorized_top_k/top_5_categorical_accuracy: 0.9544 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 980.4950 - regularization_loss: 0.0000e+00 - total_loss: 980.4950 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2626 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2713.4595 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.4595 - lr: 1.3061e-05\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9036 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.3798 - regularization_loss: 0.0000e+00 - total_loss: 984.3798 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2657 - val_factorized_top_k/top_10_categorical_accuracy: 0.3719 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2713.5320 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.5320 - lr: 1.3061e-05\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9041 - factorized_top_k/top_5_categorical_accuracy: 0.9542 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.3667 - regularization_loss: 0.0000e+00 - total_loss: 984.3667 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2713.6057 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.6057 - lr: 1.3061e-05\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9039 - factorized_top_k/top_5_categorical_accuracy: 0.9546 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.0051 - regularization_loss: 0.0000e+00 - total_loss: 985.0051 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2713.6538 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.6538 - lr: 1.3061e-05\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9046 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 986.8768 - regularization_loss: 0.0000e+00 - total_loss: 986.8768 - val_factorized_top_k/top_3_categorical_accuracy: 0.2046 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2713.7080 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.7080 - lr: 7.8364e-06\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9039 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.2253 - regularization_loss: 0.0000e+00 - total_loss: 984.2253 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2713.7549 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.7549 - lr: 7.8364e-06\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9034 - factorized_top_k/top_5_categorical_accuracy: 0.9544 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.9257 - regularization_loss: 0.0000e+00 - total_loss: 983.9257 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2631 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2713.8076 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.8076 - lr: 7.8364e-06\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9038 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.7590 - regularization_loss: 0.0000e+00 - total_loss: 984.7590 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2713.8655 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.8655 - lr: 7.8364e-06\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9043 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.9569 - regularization_loss: 0.0000e+00 - total_loss: 985.9569 - val_factorized_top_k/top_3_categorical_accuracy: 0.2092 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4735 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2713.9136 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.9136 - lr: 7.8364e-06\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9042 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.2742 - regularization_loss: 0.0000e+00 - total_loss: 986.2742 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2713.9622 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2713.9622 - lr: 7.8364e-06\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9041 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.2381 - regularization_loss: 0.0000e+00 - total_loss: 985.2381 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4737 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.0000 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.0000 - lr: 7.8364e-06\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9042 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.3158 - regularization_loss: 0.0000e+00 - total_loss: 984.3158 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2620 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.0466 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.0466 - lr: 7.8364e-06\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9040 - factorized_top_k/top_5_categorical_accuracy: 0.9546 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.8871 - regularization_loss: 0.0000e+00 - total_loss: 984.8871 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2620 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5974 - val_loss: 2714.1011 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.1011 - lr: 7.8364e-06\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9048 - factorized_top_k/top_5_categorical_accuracy: 0.9547 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.5722 - regularization_loss: 0.0000e+00 - total_loss: 986.5722 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4778 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.1262 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.1262 - lr: 4.7018e-06\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9044 - factorized_top_k/top_5_categorical_accuracy: 0.9550 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.0220 - regularization_loss: 0.0000e+00 - total_loss: 985.0220 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4778 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.1570 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.1570 - lr: 4.7018e-06\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9045 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.7548 - regularization_loss: 0.0000e+00 - total_loss: 983.7548 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2611 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4763 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.1904 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.1904 - lr: 4.7018e-06\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9034 - factorized_top_k/top_5_categorical_accuracy: 0.9547 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.7508 - regularization_loss: 0.0000e+00 - total_loss: 983.7508 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2626 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.2192 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.2192 - lr: 4.7018e-06\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9045 - factorized_top_k/top_5_categorical_accuracy: 0.9543 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 982.4679 - regularization_loss: 0.0000e+00 - total_loss: 982.4679 - val_factorized_top_k/top_3_categorical_accuracy: 0.2043 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.2449 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.2449 - lr: 4.7018e-06\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9039 - factorized_top_k/top_5_categorical_accuracy: 0.9544 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.8447 - regularization_loss: 0.0000e+00 - total_loss: 983.8447 - val_factorized_top_k/top_3_categorical_accuracy: 0.2086 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3745 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.2759 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.2759 - lr: 4.7018e-06\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9048 - factorized_top_k/top_5_categorical_accuracy: 0.9547 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.2263 - regularization_loss: 0.0000e+00 - total_loss: 984.2263 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2623 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2714.3103 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.3103 - lr: 4.7018e-06\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9041 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.4651 - regularization_loss: 0.0000e+00 - total_loss: 985.4651 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2714.3364 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.3364 - lr: 4.7018e-06\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9047 - factorized_top_k/top_5_categorical_accuracy: 0.9544 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.4852 - regularization_loss: 0.0000e+00 - total_loss: 984.4852 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.3716 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.3716 - lr: 4.7018e-06\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9041 - factorized_top_k/top_5_categorical_accuracy: 0.9546 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.3221 - regularization_loss: 0.0000e+00 - total_loss: 985.3221 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2714.3950 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.3950 - lr: 2.8211e-06\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9045 - factorized_top_k/top_5_categorical_accuracy: 0.9547 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.2886 - regularization_loss: 0.0000e+00 - total_loss: 985.2886 - val_factorized_top_k/top_3_categorical_accuracy: 0.2086 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4775 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2714.4163 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.4163 - lr: 2.8211e-06\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9046 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.5796 - regularization_loss: 0.0000e+00 - total_loss: 985.5796 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2626 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.4360 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.4360 - lr: 2.8211e-06\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9042 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.8275 - regularization_loss: 0.0000e+00 - total_loss: 983.8275 - val_factorized_top_k/top_3_categorical_accuracy: 0.2083 - val_factorized_top_k/top_5_categorical_accuracy: 0.2631 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4772 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.4556 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.4556 - lr: 2.8211e-06\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9048 - factorized_top_k/top_5_categorical_accuracy: 0.9550 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.6579 - regularization_loss: 0.0000e+00 - total_loss: 985.6579 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.6011 - val_loss: 2714.4727 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.4727 - lr: 2.8211e-06\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9047 - factorized_top_k/top_5_categorical_accuracy: 0.9545 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.8733 - regularization_loss: 0.0000e+00 - total_loss: 983.8733 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2714.4932 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.4932 - lr: 2.8211e-06\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9037 - factorized_top_k/top_5_categorical_accuracy: 0.9546 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.5566 - regularization_loss: 0.0000e+00 - total_loss: 983.5566 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4732 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2714.5090 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.5090 - lr: 2.8211e-06\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9047 - factorized_top_k/top_5_categorical_accuracy: 0.9548 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.9915 - regularization_loss: 0.0000e+00 - total_loss: 983.9915 - val_factorized_top_k/top_3_categorical_accuracy: 0.2052 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4775 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.5332 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.5332 - lr: 2.8211e-06\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9056 - factorized_top_k/top_5_categorical_accuracy: 0.9550 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.5816 - regularization_loss: 0.0000e+00 - total_loss: 984.5816 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2714.5510 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.5510 - lr: 2.8211e-06\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9063 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 985.2228 - regularization_loss: 0.0000e+00 - total_loss: 985.2228 - val_factorized_top_k/top_3_categorical_accuracy: 0.2083 - val_factorized_top_k/top_5_categorical_accuracy: 0.2626 - val_factorized_top_k/top_10_categorical_accuracy: 0.3745 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.5620 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.5620 - lr: 1.6927e-06\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9064 - factorized_top_k/top_5_categorical_accuracy: 0.9548 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.8420 - regularization_loss: 0.0000e+00 - total_loss: 986.8420 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3716 - val_factorized_top_k/top_15_categorical_accuracy: 0.4772 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2714.5718 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.5718 - lr: 1.6927e-06\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9060 - factorized_top_k/top_5_categorical_accuracy: 0.9549 - factorized_top_k/top_10_categorical_accuracy: 0.9789 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.1050 - regularization_loss: 0.0000e+00 - total_loss: 984.1050 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2617 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4772 - val_factorized_top_k/top_25_categorical_accuracy: 0.5983 - val_loss: 2714.5845 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.5845 - lr: 1.6927e-06\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9061 - factorized_top_k/top_5_categorical_accuracy: 0.9547 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9856 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.7578 - regularization_loss: 0.0000e+00 - total_loss: 984.7578 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3747 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.5967 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.5967 - lr: 1.6927e-06\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9058 - factorized_top_k/top_5_categorical_accuracy: 0.9549 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 982.2307 - regularization_loss: 0.0000e+00 - total_loss: 982.2307 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2631 - val_factorized_top_k/top_10_categorical_accuracy: 0.3722 - val_factorized_top_k/top_15_categorical_accuracy: 0.4763 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.6096 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6096 - lr: 1.6927e-06\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9059 - factorized_top_k/top_5_categorical_accuracy: 0.9549 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.4716 - regularization_loss: 0.0000e+00 - total_loss: 986.4716 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4780 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.6174 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6174 - lr: 1.6927e-06\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9062 - factorized_top_k/top_5_categorical_accuracy: 0.9550 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 984.3539 - regularization_loss: 0.0000e+00 - total_loss: 984.3539 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.5974 - val_loss: 2714.6357 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6357 - lr: 1.6927e-06\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9059 - factorized_top_k/top_5_categorical_accuracy: 0.9547 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.5951 - regularization_loss: 0.0000e+00 - total_loss: 984.5951 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.6475 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6475 - lr: 1.6927e-06\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9060 - factorized_top_k/top_5_categorical_accuracy: 0.9548 - factorized_top_k/top_10_categorical_accuracy: 0.9794 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.1232 - regularization_loss: 0.0000e+00 - total_loss: 984.1232 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2617 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4746 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.6587 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6587 - lr: 1.6927e-06\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9081 - factorized_top_k/top_5_categorical_accuracy: 0.9553 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.3460 - regularization_loss: 0.0000e+00 - total_loss: 983.3460 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.6670 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6670 - lr: 1.0156e-06\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9069 - factorized_top_k/top_5_categorical_accuracy: 0.9551 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.4064 - regularization_loss: 0.0000e+00 - total_loss: 984.4064 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.6760 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6760 - lr: 1.0156e-06\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9076 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 985.0475 - regularization_loss: 0.0000e+00 - total_loss: 985.0475 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2714.6831 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6831 - lr: 1.0156e-06\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9071 - factorized_top_k/top_5_categorical_accuracy: 0.9555 - factorized_top_k/top_10_categorical_accuracy: 0.9794 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.4119 - regularization_loss: 0.0000e+00 - total_loss: 984.4119 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.6921 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.6921 - lr: 1.0156e-06\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9086 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9856 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.9468 - regularization_loss: 0.0000e+00 - total_loss: 983.9468 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3756 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.7007 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7007 - lr: 1.0156e-06\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9078 - factorized_top_k/top_5_categorical_accuracy: 0.9554 - factorized_top_k/top_10_categorical_accuracy: 0.9794 - factorized_top_k/top_15_categorical_accuracy: 0.9856 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.7266 - regularization_loss: 0.0000e+00 - total_loss: 984.7266 - val_factorized_top_k/top_3_categorical_accuracy: 0.2075 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2714.7080 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7080 - lr: 1.0156e-06\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9076 - factorized_top_k/top_5_categorical_accuracy: 0.9554 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 985.3382 - regularization_loss: 0.0000e+00 - total_loss: 985.3382 - val_factorized_top_k/top_3_categorical_accuracy: 0.2040 - val_factorized_top_k/top_5_categorical_accuracy: 0.2654 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4772 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2714.7151 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7151 - lr: 1.0156e-06\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9071 - factorized_top_k/top_5_categorical_accuracy: 0.9551 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.5377 - regularization_loss: 0.0000e+00 - total_loss: 984.5377 - val_factorized_top_k/top_3_categorical_accuracy: 0.2063 - val_factorized_top_k/top_5_categorical_accuracy: 0.2620 - val_factorized_top_k/top_10_categorical_accuracy: 0.3719 - val_factorized_top_k/top_15_categorical_accuracy: 0.4758 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.7224 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7224 - lr: 1.0156e-06\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9554 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.2693 - regularization_loss: 0.0000e+00 - total_loss: 984.2693 - val_factorized_top_k/top_3_categorical_accuracy: 0.2077 - val_factorized_top_k/top_5_categorical_accuracy: 0.2611 - val_factorized_top_k/top_10_categorical_accuracy: 0.3719 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.7305 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7305 - lr: 1.0156e-06\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9066 - factorized_top_k/top_5_categorical_accuracy: 0.9554 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.5056 - regularization_loss: 0.0000e+00 - total_loss: 984.5056 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4772 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2714.7378 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7378 - lr: 1.0000e-06\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.9486 - regularization_loss: 0.0000e+00 - total_loss: 985.9486 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2626 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2714.7444 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7444 - lr: 1.0000e-06\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9079 - factorized_top_k/top_5_categorical_accuracy: 0.9555 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 983.3605 - regularization_loss: 0.0000e+00 - total_loss: 983.3605 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2651 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.7534 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7534 - lr: 1.0000e-06\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9072 - factorized_top_k/top_5_categorical_accuracy: 0.9555 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.5351 - regularization_loss: 0.0000e+00 - total_loss: 983.5351 - val_factorized_top_k/top_3_categorical_accuracy: 0.2089 - val_factorized_top_k/top_5_categorical_accuracy: 0.2640 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2714.7607 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7607 - lr: 1.0000e-06\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9074 - factorized_top_k/top_5_categorical_accuracy: 0.9553 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.1340 - regularization_loss: 0.0000e+00 - total_loss: 984.1340 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.7686 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7686 - lr: 1.0000e-06\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9073 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.5433 - regularization_loss: 0.0000e+00 - total_loss: 984.5433 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2643 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.7761 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7761 - lr: 1.0000e-06\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9553 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.6832 - regularization_loss: 0.0000e+00 - total_loss: 984.6832 - val_factorized_top_k/top_3_categorical_accuracy: 0.2052 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4740 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.7854 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7854 - lr: 1.0000e-06\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9080 - factorized_top_k/top_5_categorical_accuracy: 0.9556 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9853 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 984.7239 - regularization_loss: 0.0000e+00 - total_loss: 984.7239 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4743 - val_factorized_top_k/top_25_categorical_accuracy: 0.6003 - val_loss: 2714.7932 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.7932 - lr: 1.0000e-06\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9071 - factorized_top_k/top_5_categorical_accuracy: 0.9557 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.1359 - regularization_loss: 0.0000e+00 - total_loss: 983.1359 - val_factorized_top_k/top_3_categorical_accuracy: 0.2046 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.5989 - val_loss: 2714.8015 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8015 - lr: 1.0000e-06\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9074 - factorized_top_k/top_5_categorical_accuracy: 0.9551 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9856 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 985.7652 - regularization_loss: 0.0000e+00 - total_loss: 985.7652 - val_factorized_top_k/top_3_categorical_accuracy: 0.2060 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.8091 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8091 - lr: 1.0000e-06\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9080 - factorized_top_k/top_5_categorical_accuracy: 0.9550 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9856 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 984.5401 - regularization_loss: 0.0000e+00 - total_loss: 984.5401 - val_factorized_top_k/top_3_categorical_accuracy: 0.2052 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3733 - val_factorized_top_k/top_15_categorical_accuracy: 0.4746 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.8174 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8174 - lr: 1.0000e-06\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9074 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.0397 - regularization_loss: 0.0000e+00 - total_loss: 984.0397 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.8254 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8254 - lr: 1.0000e-06\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9076 - factorized_top_k/top_5_categorical_accuracy: 0.9551 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.8221 - regularization_loss: 0.0000e+00 - total_loss: 983.8221 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3719 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.5986 - val_loss: 2714.8313 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8313 - lr: 1.0000e-06\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9553 - factorized_top_k/top_10_categorical_accuracy: 0.9794 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.4791 - regularization_loss: 0.0000e+00 - total_loss: 986.4791 - val_factorized_top_k/top_3_categorical_accuracy: 0.2052 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3713 - val_factorized_top_k/top_15_categorical_accuracy: 0.4749 - val_factorized_top_k/top_25_categorical_accuracy: 0.6009 - val_loss: 2714.8389 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8389 - lr: 1.0000e-06\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9082 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9920 - loss: 984.6123 - regularization_loss: 0.0000e+00 - total_loss: 984.6123 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4766 - val_factorized_top_k/top_25_categorical_accuracy: 0.6006 - val_loss: 2714.8481 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8481 - lr: 1.0000e-06\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9071 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9793 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.9949 - regularization_loss: 0.0000e+00 - total_loss: 985.9949 - val_factorized_top_k/top_3_categorical_accuracy: 0.2066 - val_factorized_top_k/top_5_categorical_accuracy: 0.2651 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4740 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.8572 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8572 - lr: 1.0000e-06\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9554 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.1338 - regularization_loss: 0.0000e+00 - total_loss: 985.1338 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2628 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.8665 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8665 - lr: 1.0000e-06\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9084 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 985.6823 - regularization_loss: 0.0000e+00 - total_loss: 985.6823 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2631 - val_factorized_top_k/top_10_categorical_accuracy: 0.3736 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.5980 - val_loss: 2714.8748 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8748 - lr: 1.0000e-06\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9550 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.2752 - regularization_loss: 0.0000e+00 - total_loss: 986.2752 - val_factorized_top_k/top_3_categorical_accuracy: 0.2055 - val_factorized_top_k/top_5_categorical_accuracy: 0.2620 - val_factorized_top_k/top_10_categorical_accuracy: 0.3742 - val_factorized_top_k/top_15_categorical_accuracy: 0.4775 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.8843 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8843 - lr: 1.0000e-06\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9070 - factorized_top_k/top_5_categorical_accuracy: 0.9553 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.0097 - regularization_loss: 0.0000e+00 - total_loss: 984.0097 - val_factorized_top_k/top_3_categorical_accuracy: 0.2052 - val_factorized_top_k/top_5_categorical_accuracy: 0.2646 - val_factorized_top_k/top_10_categorical_accuracy: 0.3725 - val_factorized_top_k/top_15_categorical_accuracy: 0.4737 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.8916 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8916 - lr: 1.0000e-06\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9080 - factorized_top_k/top_5_categorical_accuracy: 0.9550 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 986.1615 - regularization_loss: 0.0000e+00 - total_loss: 986.1615 - val_factorized_top_k/top_3_categorical_accuracy: 0.2049 - val_factorized_top_k/top_5_categorical_accuracy: 0.2648 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.5991 - val_loss: 2714.8999 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.8999 - lr: 1.0000e-06\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9068 - factorized_top_k/top_5_categorical_accuracy: 0.9553 - factorized_top_k/top_10_categorical_accuracy: 0.9791 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.1754 - regularization_loss: 0.0000e+00 - total_loss: 984.1754 - val_factorized_top_k/top_3_categorical_accuracy: 0.2057 - val_factorized_top_k/top_5_categorical_accuracy: 0.2634 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4752 - val_factorized_top_k/top_25_categorical_accuracy: 0.6000 - val_loss: 2714.9082 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.9082 - lr: 1.0000e-06\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9557 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.8413 - regularization_loss: 0.0000e+00 - total_loss: 984.8413 - val_factorized_top_k/top_3_categorical_accuracy: 0.2083 - val_factorized_top_k/top_5_categorical_accuracy: 0.2637 - val_factorized_top_k/top_10_categorical_accuracy: 0.3727 - val_factorized_top_k/top_15_categorical_accuracy: 0.4746 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.9163 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.9163 - lr: 1.0000e-06\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9556 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9855 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 983.6920 - regularization_loss: 0.0000e+00 - total_loss: 983.6920 - val_factorized_top_k/top_3_categorical_accuracy: 0.2072 - val_factorized_top_k/top_5_categorical_accuracy: 0.2603 - val_factorized_top_k/top_10_categorical_accuracy: 0.3713 - val_factorized_top_k/top_15_categorical_accuracy: 0.4755 - val_factorized_top_k/top_25_categorical_accuracy: 0.5980 - val_loss: 2714.9231 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.9231 - lr: 1.0000e-06\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9075 - factorized_top_k/top_5_categorical_accuracy: 0.9549 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9918 - loss: 983.9826 - regularization_loss: 0.0000e+00 - total_loss: 983.9826 - val_factorized_top_k/top_3_categorical_accuracy: 0.2069 - val_factorized_top_k/top_5_categorical_accuracy: 0.2651 - val_factorized_top_k/top_10_categorical_accuracy: 0.3739 - val_factorized_top_k/top_15_categorical_accuracy: 0.4760 - val_factorized_top_k/top_25_categorical_accuracy: 0.5994 - val_loss: 2714.9314 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.9314 - lr: 1.0000e-06\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.9076 - factorized_top_k/top_5_categorical_accuracy: 0.9552 - factorized_top_k/top_10_categorical_accuracy: 0.9792 - factorized_top_k/top_15_categorical_accuracy: 0.9854 - factorized_top_k/top_25_categorical_accuracy: 0.9919 - loss: 984.5531 - regularization_loss: 0.0000e+00 - total_loss: 984.5531 - val_factorized_top_k/top_3_categorical_accuracy: 0.2080 - val_factorized_top_k/top_5_categorical_accuracy: 0.2623 - val_factorized_top_k/top_10_categorical_accuracy: 0.3730 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.5997 - val_loss: 2714.9407 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2714.9407 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "data = model.fit(cached_train,\n",
    "          validation_data=cached_test,\n",
    "          epochs=200,\n",
    "          verbose=1, \n",
    "          workers=3,\n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[model_checkpoint_callback, \n",
    "                     reduce_lr]\n",
    "\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c91798a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1f3c117d90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"new_amazon_check_points/best_check_point_25k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40d04cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 39ms/step - factorized_top_k/top_3_categorical_accuracy: 0.2393 - factorized_top_k/top_5_categorical_accuracy: 0.3182 - factorized_top_k/top_10_categorical_accuracy: 0.4511 - factorized_top_k/top_15_categorical_accuracy: 0.5377 - factorized_top_k/top_25_categorical_accuracy: 0.6410 - loss: 2447.4448 - regularization_loss: 0.0000e+00 - total_loss: 2447.4448\n"
     ]
    }
   ],
   "source": [
    "result_summary = model.evaluate(cached_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "215d3fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.2393113374710083,\n",
       " 5: 0.31822094321250916,\n",
       " 10: 0.45107603073120117,\n",
       " 15: 0.5377331376075745,\n",
       " 25: 0.6410329937934875}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{val:result_summary[idx] for idx, val in enumerate([3, 5, 10,15, 25]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ee8552d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_3_categorical_accuracy': [0.040933433920145035,\n",
       "  0.17909972369670868,\n",
       "  0.5759053826332092,\n",
       "  0.7556427121162415,\n",
       "  0.8088816404342651,\n",
       "  0.8333970904350281,\n",
       "  0.8439173698425293,\n",
       "  0.8494006395339966,\n",
       "  0.8576574921607971,\n",
       "  0.8594108819961548,\n",
       "  0.8621525168418884,\n",
       "  0.8648622632026672,\n",
       "  0.8753825426101685,\n",
       "  0.8746174573898315,\n",
       "  0.8757332563400269,\n",
       "  0.8769127726554871,\n",
       "  0.8788893222808838,\n",
       "  0.8787299394607544,\n",
       "  0.8781560659408569,\n",
       "  0.8788255453109741,\n",
       "  0.8786342740058899,\n",
       "  0.8851058483123779,\n",
       "  0.8854883909225464,\n",
       "  0.884850800037384,\n",
       "  0.886540412902832,\n",
       "  0.8852971196174622,\n",
       "  0.8845957517623901,\n",
       "  0.8862853646278381,\n",
       "  0.8857753276824951,\n",
       "  0.8855202794075012,\n",
       "  0.891099214553833,\n",
       "  0.8905572295188904,\n",
       "  0.8904935121536255,\n",
       "  0.8914817571640015,\n",
       "  0.8913223743438721,\n",
       "  0.8895370960235596,\n",
       "  0.890876054763794,\n",
       "  0.8908122777938843,\n",
       "  0.8907485604286194,\n",
       "  0.8947653770446777,\n",
       "  0.8951479196548462,\n",
       "  0.8948609828948975,\n",
       "  0.8946059942245483,\n",
       "  0.8953391909599304,\n",
       "  0.8954985737800598,\n",
       "  0.8949885368347168,\n",
       "  0.8952435851097107,\n",
       "  0.8943509459495544,\n",
       "  0.8976345062255859,\n",
       "  0.8976026773452759,\n",
       "  0.8978895545005798,\n",
       "  0.8977620601654053,\n",
       "  0.8976663947105408,\n",
       "  0.8982083797454834,\n",
       "  0.8986546993255615,\n",
       "  0.8978895545005798,\n",
       "  0.8977301716804504,\n",
       "  0.8989096879959106,\n",
       "  0.9008543491363525,\n",
       "  0.8993560075759888,\n",
       "  0.9004718065261841,\n",
       "  0.8991966247558594,\n",
       "  0.8996110558509827,\n",
       "  0.900248646736145,\n",
       "  0.8997704386711121,\n",
       "  0.8996110558509827,\n",
       "  0.9013325572013855,\n",
       "  0.9005355834960938,\n",
       "  0.9013006687164307,\n",
       "  0.9013644456863403,\n",
       "  0.9011731743812561,\n",
       "  0.9015238285064697,\n",
       "  0.9015238285064697,\n",
       "  0.9008862376213074,\n",
       "  0.9012369513511658,\n",
       "  0.9023208618164062,\n",
       "  0.9020658135414124,\n",
       "  0.9022889733314514,\n",
       "  0.9017469882965088,\n",
       "  0.9023208618164062,\n",
       "  0.901938259601593,\n",
       "  0.9022889733314514,\n",
       "  0.9025758504867554,\n",
       "  0.9013006687164307,\n",
       "  0.9025121331214905,\n",
       "  0.9027671217918396,\n",
       "  0.9024802446365356,\n",
       "  0.903117835521698,\n",
       "  0.9029265642166138,\n",
       "  0.9027990102767944,\n",
       "  0.9026077389717102,\n",
       "  0.9023526906967163,\n",
       "  0.9024802446365356,\n",
       "  0.9025758504867554,\n",
       "  0.9034366011619568,\n",
       "  0.9034366011619568,\n",
       "  0.9028946757316589,\n",
       "  0.9030540585517883,\n",
       "  0.9023845791816711,\n",
       "  0.9026077389717102,\n",
       "  0.9037873148918152,\n",
       "  0.9035322666168213,\n",
       "  0.9029584527015686,\n",
       "  0.9034047722816467,\n",
       "  0.9032134413719177,\n",
       "  0.9032453298568726,\n",
       "  0.9033409953117371,\n",
       "  0.9035641551017761,\n",
       "  0.9033091068267822,\n",
       "  0.9028946757316589,\n",
       "  0.9030540585517883,\n",
       "  0.9029902815818787,\n",
       "  0.9027352929115295,\n",
       "  0.9030540585517883,\n",
       "  0.9039148092269897,\n",
       "  0.9035641551017761,\n",
       "  0.9039148092269897,\n",
       "  0.9029265642166138,\n",
       "  0.9031497240066528,\n",
       "  0.9034047722816467,\n",
       "  0.9029265642166138,\n",
       "  0.9035003781318665,\n",
       "  0.9032453298568726,\n",
       "  0.9036916494369507,\n",
       "  0.9040423631668091,\n",
       "  0.9043611288070679,\n",
       "  0.903627872467041,\n",
       "  0.904106080532074,\n",
       "  0.9038510322570801,\n",
       "  0.9045842885971069,\n",
       "  0.9038510322570801,\n",
       "  0.9034047722816467,\n",
       "  0.9037873148918152,\n",
       "  0.9042655229568481,\n",
       "  0.9041698575019836,\n",
       "  0.904106080532074,\n",
       "  0.9041698575019836,\n",
       "  0.9039785861968994,\n",
       "  0.9047755599021912,\n",
       "  0.9044249057769775,\n",
       "  0.9045205116271973,\n",
       "  0.9034047722816467,\n",
       "  0.9044567942619324,\n",
       "  0.9039148092269897,\n",
       "  0.9048393368721008,\n",
       "  0.904106080532074,\n",
       "  0.9047117829322815,\n",
       "  0.9040741920471191,\n",
       "  0.9045205116271973,\n",
       "  0.9045842885971069,\n",
       "  0.9042017459869385,\n",
       "  0.9048393368721008,\n",
       "  0.9047436714172363,\n",
       "  0.9036597609519958,\n",
       "  0.9046799540519714,\n",
       "  0.9056363105773926,\n",
       "  0.9062739014625549,\n",
       "  0.9064014554023743,\n",
       "  0.906018853187561,\n",
       "  0.9061145186424255,\n",
       "  0.9057638645172119,\n",
       "  0.9058913588523865,\n",
       "  0.9061782956123352,\n",
       "  0.9058594703674316,\n",
       "  0.9059551358222961,\n",
       "  0.9080591797828674,\n",
       "  0.9069114923477173,\n",
       "  0.9076447486877441,\n",
       "  0.9071346521377563,\n",
       "  0.9085692167282104,\n",
       "  0.9078360199928284,\n",
       "  0.9076128602027893,\n",
       "  0.9071346521377563,\n",
       "  0.90748530626297,\n",
       "  0.9066246151924133,\n",
       "  0.9075490832328796,\n",
       "  0.9079316258430481,\n",
       "  0.907198429107666,\n",
       "  0.9073578119277954,\n",
       "  0.9072940349578857,\n",
       "  0.9074534773826599,\n",
       "  0.9079635143280029,\n",
       "  0.9070708751678467,\n",
       "  0.9073578119277954,\n",
       "  0.9080272912979126,\n",
       "  0.9073578119277954,\n",
       "  0.9076447486877441,\n",
       "  0.9074534773826599,\n",
       "  0.908186674118042,\n",
       "  0.9070708751678467,\n",
       "  0.90748530626297,\n",
       "  0.9084417223930359,\n",
       "  0.9074534773826599,\n",
       "  0.9070071578025818,\n",
       "  0.9079954028129578,\n",
       "  0.9068158864974976,\n",
       "  0.9075171947479248,\n",
       "  0.9075171947479248,\n",
       "  0.9075490832328796,\n",
       "  0.9075809717178345],\n",
       " 'factorized_top_k/top_5_categorical_accuracy': [0.07670237123966217,\n",
       "  0.24502678215503693,\n",
       "  0.6542017459869385,\n",
       "  0.8147475123405457,\n",
       "  0.8662012219429016,\n",
       "  0.8881025314331055,\n",
       "  0.9006311893463135,\n",
       "  0.9078679084777832,\n",
       "  0.9130642414093018,\n",
       "  0.9176868200302124,\n",
       "  0.9211298227310181,\n",
       "  0.9243815541267395,\n",
       "  0.9326702356338501,\n",
       "  0.934136688709259,\n",
       "  0.9337222576141357,\n",
       "  0.9355394244194031,\n",
       "  0.9362726211547852,\n",
       "  0.9378666281700134,\n",
       "  0.9381853938102722,\n",
       "  0.938472330570221,\n",
       "  0.9387273788452148,\n",
       "  0.9430948495864868,\n",
       "  0.9433180093765259,\n",
       "  0.9433817863464355,\n",
       "  0.9448801279067993,\n",
       "  0.9436368346214294,\n",
       "  0.9438599944114685,\n",
       "  0.9440512657165527,\n",
       "  0.9439237713813782,\n",
       "  0.9456133842468262,\n",
       "  0.9478130340576172,\n",
       "  0.9480680823326111,\n",
       "  0.9477174282073975,\n",
       "  0.9479086995124817,\n",
       "  0.9481637477874756,\n",
       "  0.9482912421226501,\n",
       "  0.9481956362724304,\n",
       "  0.9484187960624695,\n",
       "  0.9492476582527161,\n",
       "  0.9505228400230408,\n",
       "  0.9505547285079956,\n",
       "  0.9501084089279175,\n",
       "  0.9508734941482544,\n",
       "  0.9507778882980347,\n",
       "  0.9510647654533386,\n",
       "  0.9500765204429626,\n",
       "  0.9507778882980347,\n",
       "  0.9512879252433777,\n",
       "  0.9520530700683594,\n",
       "  0.9517342448234558,\n",
       "  0.9523718357086182,\n",
       "  0.9523080587387085,\n",
       "  0.9525631070137024,\n",
       "  0.9523399472236633,\n",
       "  0.9522443413734436,\n",
       "  0.953105092048645,\n",
       "  0.9523718357086182,\n",
       "  0.9527543783187866,\n",
       "  0.9532644748687744,\n",
       "  0.9524675011634827,\n",
       "  0.9524675011634827,\n",
       "  0.9528181552886963,\n",
       "  0.9531369805335999,\n",
       "  0.9535195231437683,\n",
       "  0.9534238576889038,\n",
       "  0.9526587724685669,\n",
       "  0.9535832405090332,\n",
       "  0.9534238576889038,\n",
       "  0.9529775381088257,\n",
       "  0.9535195231437683,\n",
       "  0.9537745714187622,\n",
       "  0.9538064002990723,\n",
       "  0.9538064002990723,\n",
       "  0.9534557461738586,\n",
       "  0.9538064002990723,\n",
       "  0.9541571140289307,\n",
       "  0.9534238576889038,\n",
       "  0.9538382887840271,\n",
       "  0.9539020657539368,\n",
       "  0.9540295600891113,\n",
       "  0.9536789059638977,\n",
       "  0.9536789059638977,\n",
       "  0.9539339542388916,\n",
       "  0.9535195231437683,\n",
       "  0.953615128993988,\n",
       "  0.9539977312088013,\n",
       "  0.9539020657539368,\n",
       "  0.9539977312088013,\n",
       "  0.9542846083641052,\n",
       "  0.9539339542388916,\n",
       "  0.9539658427238464,\n",
       "  0.9535195231437683,\n",
       "  0.9537426829338074,\n",
       "  0.9539339542388916,\n",
       "  0.9537107944488525,\n",
       "  0.9539658427238464,\n",
       "  0.9539658427238464,\n",
       "  0.9540614485740662,\n",
       "  0.9539020657539368,\n",
       "  0.954093337059021,\n",
       "  0.954093337059021,\n",
       "  0.9545077681541443,\n",
       "  0.9539658427238464,\n",
       "  0.9543483853340149,\n",
       "  0.9537426829338074,\n",
       "  0.9542846083641052,\n",
       "  0.9542846083641052,\n",
       "  0.9538701772689819,\n",
       "  0.9540295600891113,\n",
       "  0.9540295600891113,\n",
       "  0.9543483853340149,\n",
       "  0.9541571140289307,\n",
       "  0.9540295600891113,\n",
       "  0.9547309279441833,\n",
       "  0.9539977312088013,\n",
       "  0.9542846083641052,\n",
       "  0.9545396566390991,\n",
       "  0.9544121623039246,\n",
       "  0.9543483853340149,\n",
       "  0.9543483853340149,\n",
       "  0.9545077681541443,\n",
       "  0.9544439911842346,\n",
       "  0.9541252255439758,\n",
       "  0.9542208909988403,\n",
       "  0.9541890025138855,\n",
       "  0.9543802738189697,\n",
       "  0.9543483853340149,\n",
       "  0.9541890025138855,\n",
       "  0.9546034336090088,\n",
       "  0.9543483853340149,\n",
       "  0.9543483853340149,\n",
       "  0.9543802738189697,\n",
       "  0.9543164968490601,\n",
       "  0.9544758796691895,\n",
       "  0.9543164968490601,\n",
       "  0.9545077681541443,\n",
       "  0.9544758796691895,\n",
       "  0.954571545124054,\n",
       "  0.9547309279441833,\n",
       "  0.9550178647041321,\n",
       "  0.9543483853340149,\n",
       "  0.9546671509742737,\n",
       "  0.9543164968490601,\n",
       "  0.9544439911842346,\n",
       "  0.9546671509742737,\n",
       "  0.9544758796691895,\n",
       "  0.9544121623039246,\n",
       "  0.9546034336090088,\n",
       "  0.9546990394592285,\n",
       "  0.9544758796691895,\n",
       "  0.9544758796691895,\n",
       "  0.9550178647041321,\n",
       "  0.9545396566390991,\n",
       "  0.9546353220939636,\n",
       "  0.9548265933990479,\n",
       "  0.9549859762191772,\n",
       "  0.9551772475242615,\n",
       "  0.9547628164291382,\n",
       "  0.9549221992492676,\n",
       "  0.9547309279441833,\n",
       "  0.9549221992492676,\n",
       "  0.9549221992492676,\n",
       "  0.9549859762191772,\n",
       "  0.9547309279441833,\n",
       "  0.9548265933990479,\n",
       "  0.955272912979126,\n",
       "  0.9551134705543518,\n",
       "  0.9552091360092163,\n",
       "  0.9554641842842102,\n",
       "  0.9552410244941711,\n",
       "  0.9553685188293457,\n",
       "  0.9553685188293457,\n",
       "  0.9551453590393066,\n",
       "  0.9554004073143005,\n",
       "  0.9554004073143005,\n",
       "  0.9552091360092163,\n",
       "  0.9554641842842102,\n",
       "  0.9554641842842102,\n",
       "  0.955272912979126,\n",
       "  0.9552091360092163,\n",
       "  0.955272912979126,\n",
       "  0.9555916786193848,\n",
       "  0.9556554555892944,\n",
       "  0.955081582069397,\n",
       "  0.9549540877342224,\n",
       "  0.9552410244941711,\n",
       "  0.9551453590393066,\n",
       "  0.955272912979126,\n",
       "  0.9551772475242615,\n",
       "  0.9552091360092163,\n",
       "  0.9554004073143005,\n",
       "  0.9552410244941711,\n",
       "  0.9549540877342224,\n",
       "  0.955272912979126,\n",
       "  0.9550178647041321,\n",
       "  0.9553366303443909,\n",
       "  0.9557192325592041,\n",
       "  0.9555916786193848,\n",
       "  0.9549221992492676,\n",
       "  0.9552410244941711],\n",
       " 'factorized_top_k/top_10_categorical_accuracy': [0.12732721865177155,\n",
       "  0.35134533047676086,\n",
       "  0.7338051795959473,\n",
       "  0.8633002042770386,\n",
       "  0.9075809717178345,\n",
       "  0.9260392785072327,\n",
       "  0.9366551637649536,\n",
       "  0.943254292011261,\n",
       "  0.9483869075775146,\n",
       "  0.9519892930984497,\n",
       "  0.9546034336090088,\n",
       "  0.9562292695045471,\n",
       "  0.9631471633911133,\n",
       "  0.9640398025512695,\n",
       "  0.9650918245315552,\n",
       "  0.9650918245315552,\n",
       "  0.9662076234817505,\n",
       "  0.9669089317321777,\n",
       "  0.9680566191673279,\n",
       "  0.9684072732925415,\n",
       "  0.969204306602478,\n",
       "  0.9709576368331909,\n",
       "  0.9716590046882629,\n",
       "  0.9720415472984314,\n",
       "  0.9724878668785095,\n",
       "  0.9730298519134521,\n",
       "  0.9734442830085754,\n",
       "  0.9732211232185364,\n",
       "  0.973093569278717,\n",
       "  0.9738268256187439,\n",
       "  0.9748469591140747,\n",
       "  0.9750701189041138,\n",
       "  0.9754845499992371,\n",
       "  0.9758671522140503,\n",
       "  0.9755483269691467,\n",
       "  0.9758989810943604,\n",
       "  0.9760903120040894,\n",
       "  0.9760584235191345,\n",
       "  0.9759308695793152,\n",
       "  0.9767597317695618,\n",
       "  0.9767597317695618,\n",
       "  0.9769828915596008,\n",
       "  0.9770147800445557,\n",
       "  0.9769510626792908,\n",
       "  0.9770785570144653,\n",
       "  0.9768872857093811,\n",
       "  0.9771104454994202,\n",
       "  0.9770785570144653,\n",
       "  0.9773017168045044,\n",
       "  0.9776204824447632,\n",
       "  0.9778436422348022,\n",
       "  0.9780668020248413,\n",
       "  0.9777480363845825,\n",
       "  0.9779711961746216,\n",
       "  0.9778755307197571,\n",
       "  0.9778755307197571,\n",
       "  0.978130578994751,\n",
       "  0.9781943559646606,\n",
       "  0.9785131216049194,\n",
       "  0.9782899618148804,\n",
       "  0.9784175157546997,\n",
       "  0.9785131216049194,\n",
       "  0.9783218502998352,\n",
       "  0.97835373878479,\n",
       "  0.9784494042396545,\n",
       "  0.9786406755447388,\n",
       "  0.9788956642150879,\n",
       "  0.9786406755447388,\n",
       "  0.9787362813949585,\n",
       "  0.9789275527000427,\n",
       "  0.9786725044250488,\n",
       "  0.9786725044250488,\n",
       "  0.9789594411849976,\n",
       "  0.9788000583648682,\n",
       "  0.9787681698799133,\n",
       "  0.978831946849823,\n",
       "  0.9788956642150879,\n",
       "  0.9789275527000427,\n",
       "  0.9787681698799133,\n",
       "  0.9788956642150879,\n",
       "  0.9789275527000427,\n",
       "  0.9789594411849976,\n",
       "  0.9789275527000427,\n",
       "  0.9790232181549072,\n",
       "  0.9788638353347778,\n",
       "  0.9789594411849976,\n",
       "  0.9790869951248169,\n",
       "  0.9790232181549072,\n",
       "  0.9790869951248169,\n",
       "  0.9791507124900818,\n",
       "  0.9792144894599915,\n",
       "  0.9789275527000427,\n",
       "  0.9790551066398621,\n",
       "  0.9790232181549072,\n",
       "  0.979118824005127,\n",
       "  0.9790232181549072,\n",
       "  0.9790232181549072,\n",
       "  0.9789594411849976,\n",
       "  0.9791507124900818,\n",
       "  0.979118824005127,\n",
       "  0.9790551066398621,\n",
       "  0.9789913296699524,\n",
       "  0.9790232181549072,\n",
       "  0.9791507124900818,\n",
       "  0.9790551066398621,\n",
       "  0.9790232181549072,\n",
       "  0.9789594411849976,\n",
       "  0.9789913296699524,\n",
       "  0.9789275527000427,\n",
       "  0.9790869951248169,\n",
       "  0.9790869951248169,\n",
       "  0.9792782664299011,\n",
       "  0.9790232181549072,\n",
       "  0.9789913296699524,\n",
       "  0.9789913296699524,\n",
       "  0.9790232181549072,\n",
       "  0.9790232181549072,\n",
       "  0.9790232181549072,\n",
       "  0.9790232181549072,\n",
       "  0.9791507124900818,\n",
       "  0.9790232181549072,\n",
       "  0.9792144894599915,\n",
       "  0.979118824005127,\n",
       "  0.9790551066398621,\n",
       "  0.9790869951248169,\n",
       "  0.9789913296699524,\n",
       "  0.9789594411849976,\n",
       "  0.9789913296699524,\n",
       "  0.9790869951248169,\n",
       "  0.9790869951248169,\n",
       "  0.9792144894599915,\n",
       "  0.9789913296699524,\n",
       "  0.979118824005127,\n",
       "  0.9790551066398621,\n",
       "  0.9790869951248169,\n",
       "  0.9789913296699524,\n",
       "  0.9791507124900818,\n",
       "  0.9790232181549072,\n",
       "  0.9791507124900818,\n",
       "  0.9790869951248169,\n",
       "  0.9792144894599915,\n",
       "  0.9791507124900818,\n",
       "  0.9790869951248169,\n",
       "  0.9792463779449463,\n",
       "  0.9790551066398621,\n",
       "  0.9791826009750366,\n",
       "  0.9790551066398621,\n",
       "  0.9792144894599915,\n",
       "  0.9791507124900818,\n",
       "  0.9790869951248169,\n",
       "  0.9790869951248169,\n",
       "  0.9792144894599915,\n",
       "  0.9791826009750366,\n",
       "  0.9790551066398621,\n",
       "  0.9791507124900818,\n",
       "  0.9790869951248169,\n",
       "  0.9792144894599915,\n",
       "  0.9792782664299011,\n",
       "  0.9789275527000427,\n",
       "  0.9791507124900818,\n",
       "  0.9792463779449463,\n",
       "  0.9792782664299011,\n",
       "  0.9790232181549072,\n",
       "  0.9791826009750366,\n",
       "  0.9794057607650757,\n",
       "  0.9792463779449463,\n",
       "  0.9791507124900818,\n",
       "  0.9792144894599915,\n",
       "  0.9793738722801208,\n",
       "  0.9792782664299011,\n",
       "  0.9794376492500305,\n",
       "  0.9792144894599915,\n",
       "  0.9792463779449463,\n",
       "  0.9792782664299011,\n",
       "  0.9792144894599915,\n",
       "  0.9792782664299011,\n",
       "  0.9791507124900818,\n",
       "  0.9791826009750366,\n",
       "  0.9792144894599915,\n",
       "  0.9793100953102112,\n",
       "  0.9792144894599915,\n",
       "  0.9792463779449463,\n",
       "  0.9791826009750366,\n",
       "  0.9792144894599915,\n",
       "  0.9790869951248169,\n",
       "  0.9792782664299011,\n",
       "  0.9790232181549072,\n",
       "  0.9793738722801208,\n",
       "  0.9792144894599915,\n",
       "  0.9792782664299011,\n",
       "  0.9790869951248169,\n",
       "  0.9792463779449463,\n",
       "  0.9791507124900818,\n",
       "  0.979118824005127,\n",
       "  0.979118824005127,\n",
       "  0.9790869951248169,\n",
       "  0.9791826009750366,\n",
       "  0.9792144894599915,\n",
       "  0.9792463779449463,\n",
       "  0.9791826009750366],\n",
       " 'factorized_top_k/top_15_categorical_accuracy': [0.17782454192638397,\n",
       "  0.4239670932292938,\n",
       "  0.7724113464355469,\n",
       "  0.8853608965873718,\n",
       "  0.9245728254318237,\n",
       "  0.9411183595657349,\n",
       "  0.9501721262931824,\n",
       "  0.9573450684547424,\n",
       "  0.9609474539756775,\n",
       "  0.963434100151062,\n",
       "  0.9660162925720215,\n",
       "  0.9683753848075867,\n",
       "  0.9722009897232056,\n",
       "  0.9731573462486267,\n",
       "  0.9740180969238281,\n",
       "  0.9745919704437256,\n",
       "  0.9754845499992371,\n",
       "  0.9763453006744385,\n",
       "  0.9767916202545166,\n",
       "  0.9767916202545166,\n",
       "  0.9775567650794983,\n",
       "  0.9793100953102112,\n",
       "  0.9797883033752441,\n",
       "  0.9801390171051025,\n",
       "  0.9801390171051025,\n",
       "  0.9803940057754517,\n",
       "  0.9805534482002258,\n",
       "  0.980999767780304,\n",
       "  0.9814460873603821,\n",
       "  0.9812866449356079,\n",
       "  0.9823386669158936,\n",
       "  0.9825618267059326,\n",
       "  0.9828487634658813,\n",
       "  0.9828806519508362,\n",
       "  0.9826574921607971,\n",
       "  0.9832631945610046,\n",
       "  0.9829444289207458,\n",
       "  0.9828487634658813,\n",
       "  0.9832313060760498,\n",
       "  0.9838370084762573,\n",
       "  0.9838370084762573,\n",
       "  0.9835820198059082,\n",
       "  0.9837095141410828,\n",
       "  0.9839645624160767,\n",
       "  0.983900785446167,\n",
       "  0.9840920567512512,\n",
       "  0.9838688969612122,\n",
       "  0.9838370084762573,\n",
       "  0.9842514395713806,\n",
       "  0.9842514395713806,\n",
       "  0.9842196106910706,\n",
       "  0.9844108819961548,\n",
       "  0.9843789935112,\n",
       "  0.9845383763313293,\n",
       "  0.9844745993614197,\n",
       "  0.9846977591514587,\n",
       "  0.9846659302711487,\n",
       "  0.9848253130912781,\n",
       "  0.9847615361213684,\n",
       "  0.9846977591514587,\n",
       "  0.9847934246063232,\n",
       "  0.9846340417861938,\n",
       "  0.9847615361213684,\n",
       "  0.9847934246063232,\n",
       "  0.9847615361213684,\n",
       "  0.9848253130912781,\n",
       "  0.9849528074264526,\n",
       "  0.985112190246582,\n",
       "  0.985112190246582,\n",
       "  0.985112190246582,\n",
       "  0.9851440787315369,\n",
       "  0.9850165843963623,\n",
       "  0.9850484728813171,\n",
       "  0.9850484728813171,\n",
       "  0.985080361366272,\n",
       "  0.985303521156311,\n",
       "  0.9850484728813171,\n",
       "  0.985112190246582,\n",
       "  0.9850484728813171,\n",
       "  0.985080361366272,\n",
       "  0.9851440787315369,\n",
       "  0.9851440787315369,\n",
       "  0.9852078557014465,\n",
       "  0.9850484728813171,\n",
       "  0.9851759672164917,\n",
       "  0.9851440787315369,\n",
       "  0.9852716326713562,\n",
       "  0.9851440787315369,\n",
       "  0.9852078557014465,\n",
       "  0.9852397441864014,\n",
       "  0.9853353500366211,\n",
       "  0.985303521156311,\n",
       "  0.985303521156311,\n",
       "  0.9852397441864014,\n",
       "  0.985303521156311,\n",
       "  0.9853672385215759,\n",
       "  0.9853672385215759,\n",
       "  0.9855266809463501,\n",
       "  0.9853672385215759,\n",
       "  0.985303521156311,\n",
       "  0.9854310154914856,\n",
       "  0.9854310154914856,\n",
       "  0.9854629039764404,\n",
       "  0.9853991270065308,\n",
       "  0.9853991270065308,\n",
       "  0.9853672385215759,\n",
       "  0.985303521156311,\n",
       "  0.9853353500366211,\n",
       "  0.9853991270065308,\n",
       "  0.9853672385215759,\n",
       "  0.9854629039764404,\n",
       "  0.9853672385215759,\n",
       "  0.9853672385215759,\n",
       "  0.985303521156311,\n",
       "  0.985303521156311,\n",
       "  0.9853353500366211,\n",
       "  0.9853353500366211,\n",
       "  0.9853991270065308,\n",
       "  0.9852716326713562,\n",
       "  0.9854310154914856,\n",
       "  0.9853991270065308,\n",
       "  0.985303521156311,\n",
       "  0.9853991270065308,\n",
       "  0.9853353500366211,\n",
       "  0.9853353500366211,\n",
       "  0.9854310154914856,\n",
       "  0.9854629039764404,\n",
       "  0.9853672385215759,\n",
       "  0.9854310154914856,\n",
       "  0.9853991270065308,\n",
       "  0.9853353500366211,\n",
       "  0.9853672385215759,\n",
       "  0.9853991270065308,\n",
       "  0.9854629039764404,\n",
       "  0.985303521156311,\n",
       "  0.9853353500366211,\n",
       "  0.9854629039764404,\n",
       "  0.9853353500366211,\n",
       "  0.9855266809463501,\n",
       "  0.9853991270065308,\n",
       "  0.9854310154914856,\n",
       "  0.9853991270065308,\n",
       "  0.985303521156311,\n",
       "  0.9854310154914856,\n",
       "  0.9854629039764404,\n",
       "  0.9853672385215759,\n",
       "  0.9854947924613953,\n",
       "  0.9853991270065308,\n",
       "  0.9854629039764404,\n",
       "  0.9854310154914856,\n",
       "  0.9853672385215759,\n",
       "  0.9853991270065308,\n",
       "  0.9854629039764404,\n",
       "  0.9853672385215759,\n",
       "  0.9854629039764404,\n",
       "  0.9853991270065308,\n",
       "  0.9853353500366211,\n",
       "  0.9853672385215759,\n",
       "  0.9853353500366211,\n",
       "  0.985590398311615,\n",
       "  0.9854310154914856,\n",
       "  0.9853672385215759,\n",
       "  0.9853353500366211,\n",
       "  0.9854947924613953,\n",
       "  0.9854310154914856,\n",
       "  0.9853672385215759,\n",
       "  0.9854629039764404,\n",
       "  0.9854310154914856,\n",
       "  0.9853672385215759,\n",
       "  0.985590398311615,\n",
       "  0.9855585098266602,\n",
       "  0.985303521156311,\n",
       "  0.9853991270065308,\n",
       "  0.9854310154914856,\n",
       "  0.9854947924613953,\n",
       "  0.9854629039764404,\n",
       "  0.985303521156311,\n",
       "  0.9853672385215759,\n",
       "  0.9853672385215759,\n",
       "  0.985303521156311,\n",
       "  0.9855266809463501,\n",
       "  0.9853353500366211,\n",
       "  0.9854310154914856,\n",
       "  0.9855585098266602,\n",
       "  0.9855585098266602,\n",
       "  0.9853991270065308,\n",
       "  0.9853672385215759,\n",
       "  0.9854629039764404,\n",
       "  0.9854629039764404,\n",
       "  0.9853991270065308,\n",
       "  0.9854310154914856,\n",
       "  0.9853991270065308,\n",
       "  0.9853991270065308,\n",
       "  0.9853991270065308,\n",
       "  0.9853991270065308,\n",
       "  0.9854310154914856,\n",
       "  0.9854629039764404,\n",
       "  0.9854947924613953,\n",
       "  0.9854310154914856,\n",
       "  0.9854310154914856],\n",
       " 'factorized_top_k/top_25_categorical_accuracy': [0.27697014808654785,\n",
       "  0.5511030554771423,\n",
       "  0.8196888566017151,\n",
       "  0.9116296768188477,\n",
       "  0.9452945590019226,\n",
       "  0.9585883617401123,\n",
       "  0.9650599360466003,\n",
       "  0.970670759677887,\n",
       "  0.9733805060386658,\n",
       "  0.9758352637290955,\n",
       "  0.9773973226547241,\n",
       "  0.9793100953102112,\n",
       "  0.9825937151908875,\n",
       "  0.9828168749809265,\n",
       "  0.9837414026260376,\n",
       "  0.984123945236206,\n",
       "  0.9847934246063232,\n",
       "  0.9856222867965698,\n",
       "  0.986068606376648,\n",
       "  0.9861961007118225,\n",
       "  0.9863555431365967,\n",
       "  0.9880770444869995,\n",
       "  0.9880770444869995,\n",
       "  0.9879494905471802,\n",
       "  0.9883320331573486,\n",
       "  0.9883958101272583,\n",
       "  0.9884914755821228,\n",
       "  0.9886189699172974,\n",
       "  0.9888102412223816,\n",
       "  0.9894159436225891,\n",
       "  0.9897666573524475,\n",
       "  0.9899260401725769,\n",
       "  0.990149199962616,\n",
       "  0.9899579286575317,\n",
       "  0.9902129769325256,\n",
       "  0.9900535345077515,\n",
       "  0.9899579286575317,\n",
       "  0.9902448058128357,\n",
       "  0.9904042482376099,\n",
       "  0.9905317425727844,\n",
       "  0.9904998540878296,\n",
       "  0.9909780621528625,\n",
       "  0.9908824563026428,\n",
       "  0.9909142851829529,\n",
       "  0.9909461736679077,\n",
       "  0.9909780621528625,\n",
       "  0.9909142851829529,\n",
       "  0.9910099506378174,\n",
       "  0.9911055564880371,\n",
       "  0.9911693334579468,\n",
       "  0.9912968873977661,\n",
       "  0.9911055564880371,\n",
       "  0.9911374449729919,\n",
       "  0.9911693334579468,\n",
       "  0.9911693334579468,\n",
       "  0.9912968873977661,\n",
       "  0.9911374449729919,\n",
       "  0.9914243817329407,\n",
       "  0.9913924932479858,\n",
       "  0.9915200471878052,\n",
       "  0.9914881587028503,\n",
       "  0.9914881587028503,\n",
       "  0.9914562702178955,\n",
       "  0.9915837645530701,\n",
       "  0.9915837645530701,\n",
       "  0.9916156530380249,\n",
       "  0.9915518760681152,\n",
       "  0.9917432069778442,\n",
       "  0.9918069243431091,\n",
       "  0.9916794300079346,\n",
       "  0.9917113184928894,\n",
       "  0.9916475415229797,\n",
       "  0.9917750358581543,\n",
       "  0.9917750358581543,\n",
       "  0.9916794300079346,\n",
       "  0.9917432069778442,\n",
       "  0.9917750358581543,\n",
       "  0.9917432069778442,\n",
       "  0.991838812828064,\n",
       "  0.9917432069778442,\n",
       "  0.9917432069778442,\n",
       "  0.9918707013130188,\n",
       "  0.9917750358581543,\n",
       "  0.9918707013130188,\n",
       "  0.9918707013130188,\n",
       "  0.9917750358581543,\n",
       "  0.9917432069778442,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.9918069243431091,\n",
       "  0.9919025897979736,\n",
       "  0.9918069243431091,\n",
       "  0.9919025897979736,\n",
       "  0.9918069243431091,\n",
       "  0.9918069243431091,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.9919025897979736,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.9918069243431091,\n",
       "  0.9918707013130188,\n",
       "  0.9918069243431091,\n",
       "  0.9918707013130188,\n",
       "  0.9919025897979736,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.9919025897979736,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.9918707013130188,\n",
       "  0.9919025897979736,\n",
       "  0.9918707013130188,\n",
       "  0.9918707013130188,\n",
       "  0.9919025897979736,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.9919663071632385,\n",
       "  0.991838812828064,\n",
       "  0.9919025897979736,\n",
       "  0.9919025897979736,\n",
       "  0.9918707013130188,\n",
       "  0.9919025897979736,\n",
       "  0.9918707013130188,\n",
       "  0.9919344782829285,\n",
       "  0.9919025897979736,\n",
       "  0.9919344782829285,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.9919344782829285,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.9919025897979736,\n",
       "  0.991838812828064,\n",
       "  0.991838812828064,\n",
       "  0.9919344782829285,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.9919025897979736,\n",
       "  0.9919025897979736,\n",
       "  0.9918707013130188,\n",
       "  0.9919344782829285,\n",
       "  0.991838812828064,\n",
       "  0.9919344782829285,\n",
       "  0.9918707013130188,\n",
       "  0.9919344782829285,\n",
       "  0.9919344782829285,\n",
       "  0.9919344782829285,\n",
       "  0.9919663071632385,\n",
       "  0.9919344782829285,\n",
       "  0.9919344782829285,\n",
       "  0.991838812828064,\n",
       "  0.9919025897979736,\n",
       "  0.9919663071632385,\n",
       "  0.9919025897979736,\n",
       "  0.991838812828064,\n",
       "  0.9919344782829285,\n",
       "  0.9920300841331482,\n",
       "  0.9919344782829285,\n",
       "  0.9918707013130188,\n",
       "  0.9919344782829285,\n",
       "  0.9919025897979736,\n",
       "  0.9919981956481934,\n",
       "  0.9919344782829285,\n",
       "  0.9919344782829285,\n",
       "  0.9919025897979736,\n",
       "  0.9918707013130188,\n",
       "  0.991838812828064,\n",
       "  0.9919344782829285,\n",
       "  0.9919663071632385,\n",
       "  0.9919663071632385,\n",
       "  0.9919344782829285,\n",
       "  0.9919025897979736,\n",
       "  0.9919025897979736,\n",
       "  0.9919663071632385,\n",
       "  0.9919025897979736,\n",
       "  0.9919344782829285,\n",
       "  0.9918707013130188,\n",
       "  0.9919025897979736,\n",
       "  0.9918707013130188,\n",
       "  0.9919025897979736,\n",
       "  0.9919344782829285,\n",
       "  0.9918707013130188,\n",
       "  0.9919025897979736,\n",
       "  0.991838812828064,\n",
       "  0.9918707013130188],\n",
       " 'loss': [634.60400390625,\n",
       "  573.1990356445312,\n",
       "  397.32366943359375,\n",
       "  278.01751708984375,\n",
       "  221.23529052734375,\n",
       "  224.8983154296875,\n",
       "  170.9429931640625,\n",
       "  178.31280517578125,\n",
       "  168.8962860107422,\n",
       "  172.96957397460938,\n",
       "  182.13067626953125,\n",
       "  172.24008178710938,\n",
       "  156.60743713378906,\n",
       "  148.0763397216797,\n",
       "  140.19757080078125,\n",
       "  162.4940185546875,\n",
       "  170.35008239746094,\n",
       "  160.91409301757812,\n",
       "  183.0614013671875,\n",
       "  154.17291259765625,\n",
       "  175.1697998046875,\n",
       "  166.94729614257812,\n",
       "  146.94906616210938,\n",
       "  158.19512939453125,\n",
       "  133.12557983398438,\n",
       "  166.48654174804688,\n",
       "  149.39004516601562,\n",
       "  155.11358642578125,\n",
       "  158.887939453125,\n",
       "  139.2950439453125,\n",
       "  146.6750030517578,\n",
       "  140.03890991210938,\n",
       "  157.0683135986328,\n",
       "  129.6365509033203,\n",
       "  143.2218780517578,\n",
       "  131.543212890625,\n",
       "  146.3482666015625,\n",
       "  139.69003295898438,\n",
       "  162.30593872070312,\n",
       "  143.07640075683594,\n",
       "  156.3245086669922,\n",
       "  146.93873596191406,\n",
       "  146.68101501464844,\n",
       "  145.2906036376953,\n",
       "  145.13967895507812,\n",
       "  147.9573211669922,\n",
       "  148.7924346923828,\n",
       "  171.99826049804688,\n",
       "  149.5874481201172,\n",
       "  140.3052215576172,\n",
       "  120.76651000976562,\n",
       "  150.92408752441406,\n",
       "  129.25059509277344,\n",
       "  158.2508544921875,\n",
       "  139.16961669921875,\n",
       "  136.72970581054688,\n",
       "  128.63465881347656,\n",
       "  124.21401977539062,\n",
       "  139.75201416015625,\n",
       "  148.8472137451172,\n",
       "  133.51043701171875,\n",
       "  133.02264404296875,\n",
       "  136.4429168701172,\n",
       "  158.04388427734375,\n",
       "  129.0746307373047,\n",
       "  128.48443603515625,\n",
       "  137.7486572265625,\n",
       "  157.42922973632812,\n",
       "  151.40130615234375,\n",
       "  128.87940979003906,\n",
       "  135.5500946044922,\n",
       "  111.9652099609375,\n",
       "  132.58999633789062,\n",
       "  164.1654052734375,\n",
       "  143.88226318359375,\n",
       "  128.36642456054688,\n",
       "  142.08285522460938,\n",
       "  135.38743591308594,\n",
       "  137.65130615234375,\n",
       "  150.04049682617188,\n",
       "  141.51498413085938,\n",
       "  152.68031311035156,\n",
       "  143.26657104492188,\n",
       "  152.86923217773438,\n",
       "  144.07601928710938,\n",
       "  129.28184509277344,\n",
       "  148.51332092285156,\n",
       "  150.8062744140625,\n",
       "  129.2950897216797,\n",
       "  140.9497833251953,\n",
       "  137.4861297607422,\n",
       "  128.04116821289062,\n",
       "  143.37924194335938,\n",
       "  127.49354553222656,\n",
       "  126.070068359375,\n",
       "  150.39596557617188,\n",
       "  146.6011962890625,\n",
       "  152.92831420898438,\n",
       "  138.92864990234375,\n",
       "  119.82970428466797,\n",
       "  148.26544189453125,\n",
       "  155.2546844482422,\n",
       "  145.39300537109375,\n",
       "  145.75341796875,\n",
       "  133.2825164794922,\n",
       "  132.7777557373047,\n",
       "  142.9291229248047,\n",
       "  145.90826416015625,\n",
       "  144.262939453125,\n",
       "  130.40786743164062,\n",
       "  137.18919372558594,\n",
       "  151.56201171875,\n",
       "  150.35968017578125,\n",
       "  119.57196807861328,\n",
       "  138.04605102539062,\n",
       "  140.47613525390625,\n",
       "  140.8092041015625,\n",
       "  146.20068359375,\n",
       "  161.10467529296875,\n",
       "  118.751953125,\n",
       "  125.91107177734375,\n",
       "  138.47238159179688,\n",
       "  144.1440887451172,\n",
       "  130.18252563476562,\n",
       "  139.91595458984375,\n",
       "  134.22760009765625,\n",
       "  123.37998962402344,\n",
       "  140.28750610351562,\n",
       "  126.69438171386719,\n",
       "  132.0308074951172,\n",
       "  145.62998962402344,\n",
       "  123.2796630859375,\n",
       "  143.97203063964844,\n",
       "  134.2412567138672,\n",
       "  143.48001098632812,\n",
       "  159.9872589111328,\n",
       "  150.22129821777344,\n",
       "  134.35366821289062,\n",
       "  134.48867797851562,\n",
       "  129.3508758544922,\n",
       "  141.42588806152344,\n",
       "  123.24275207519531,\n",
       "  124.13908386230469,\n",
       "  150.423095703125,\n",
       "  132.83203125,\n",
       "  127.44087982177734,\n",
       "  142.48590087890625,\n",
       "  153.11904907226562,\n",
       "  141.31402587890625,\n",
       "  142.23553466796875,\n",
       "  140.81735229492188,\n",
       "  131.0801239013672,\n",
       "  135.26792907714844,\n",
       "  140.693115234375,\n",
       "  150.7504119873047,\n",
       "  127.62554931640625,\n",
       "  153.29835510253906,\n",
       "  158.0375213623047,\n",
       "  135.88397216796875,\n",
       "  151.00729370117188,\n",
       "  131.4517822265625,\n",
       "  150.37240600585938,\n",
       "  108.99275207519531,\n",
       "  155.09010314941406,\n",
       "  151.42913818359375,\n",
       "  143.51992797851562,\n",
       "  151.48049926757812,\n",
       "  135.18545532226562,\n",
       "  143.29803466796875,\n",
       "  139.53244018554688,\n",
       "  121.67706298828125,\n",
       "  143.3465576171875,\n",
       "  127.80257415771484,\n",
       "  134.81887817382812,\n",
       "  156.328369140625,\n",
       "  129.61734008789062,\n",
       "  130.20587158203125,\n",
       "  124.17616271972656,\n",
       "  123.18170166015625,\n",
       "  131.6801300048828,\n",
       "  117.89550018310547,\n",
       "  137.73751831054688,\n",
       "  143.0139923095703,\n",
       "  144.76634216308594,\n",
       "  137.53179931640625,\n",
       "  100.92115020751953,\n",
       "  148.0736541748047,\n",
       "  140.56353759765625,\n",
       "  142.01979064941406,\n",
       "  142.98223876953125,\n",
       "  132.58851623535156,\n",
       "  154.9962615966797,\n",
       "  118.20818328857422,\n",
       "  129.51478576660156,\n",
       "  148.62852478027344,\n",
       "  138.96630859375,\n",
       "  142.45974731445312,\n",
       "  139.5318603515625,\n",
       "  146.73883056640625,\n",
       "  162.079345703125],\n",
       " 'regularization_loss': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'total_loss': [634.60400390625,\n",
       "  573.1990356445312,\n",
       "  397.32366943359375,\n",
       "  278.01751708984375,\n",
       "  221.23529052734375,\n",
       "  224.8983154296875,\n",
       "  170.9429931640625,\n",
       "  178.31280517578125,\n",
       "  168.8962860107422,\n",
       "  172.96957397460938,\n",
       "  182.13067626953125,\n",
       "  172.24008178710938,\n",
       "  156.60743713378906,\n",
       "  148.0763397216797,\n",
       "  140.19757080078125,\n",
       "  162.4940185546875,\n",
       "  170.35008239746094,\n",
       "  160.91409301757812,\n",
       "  183.0614013671875,\n",
       "  154.17291259765625,\n",
       "  175.1697998046875,\n",
       "  166.94729614257812,\n",
       "  146.94906616210938,\n",
       "  158.19512939453125,\n",
       "  133.12557983398438,\n",
       "  166.48654174804688,\n",
       "  149.39004516601562,\n",
       "  155.11358642578125,\n",
       "  158.887939453125,\n",
       "  139.2950439453125,\n",
       "  146.6750030517578,\n",
       "  140.03890991210938,\n",
       "  157.0683135986328,\n",
       "  129.6365509033203,\n",
       "  143.2218780517578,\n",
       "  131.543212890625,\n",
       "  146.3482666015625,\n",
       "  139.69003295898438,\n",
       "  162.30593872070312,\n",
       "  143.07640075683594,\n",
       "  156.3245086669922,\n",
       "  146.93873596191406,\n",
       "  146.68101501464844,\n",
       "  145.2906036376953,\n",
       "  145.13967895507812,\n",
       "  147.9573211669922,\n",
       "  148.7924346923828,\n",
       "  171.99826049804688,\n",
       "  149.5874481201172,\n",
       "  140.3052215576172,\n",
       "  120.76651000976562,\n",
       "  150.92408752441406,\n",
       "  129.25059509277344,\n",
       "  158.2508544921875,\n",
       "  139.16961669921875,\n",
       "  136.72970581054688,\n",
       "  128.63465881347656,\n",
       "  124.21401977539062,\n",
       "  139.75201416015625,\n",
       "  148.8472137451172,\n",
       "  133.51043701171875,\n",
       "  133.02264404296875,\n",
       "  136.4429168701172,\n",
       "  158.04388427734375,\n",
       "  129.0746307373047,\n",
       "  128.48443603515625,\n",
       "  137.7486572265625,\n",
       "  157.42922973632812,\n",
       "  151.40130615234375,\n",
       "  128.87940979003906,\n",
       "  135.5500946044922,\n",
       "  111.9652099609375,\n",
       "  132.58999633789062,\n",
       "  164.1654052734375,\n",
       "  143.88226318359375,\n",
       "  128.36642456054688,\n",
       "  142.08285522460938,\n",
       "  135.38743591308594,\n",
       "  137.65130615234375,\n",
       "  150.04049682617188,\n",
       "  141.51498413085938,\n",
       "  152.68031311035156,\n",
       "  143.26657104492188,\n",
       "  152.86923217773438,\n",
       "  144.07601928710938,\n",
       "  129.28184509277344,\n",
       "  148.51332092285156,\n",
       "  150.8062744140625,\n",
       "  129.2950897216797,\n",
       "  140.9497833251953,\n",
       "  137.4861297607422,\n",
       "  128.04116821289062,\n",
       "  143.37924194335938,\n",
       "  127.49354553222656,\n",
       "  126.070068359375,\n",
       "  150.39596557617188,\n",
       "  146.6011962890625,\n",
       "  152.92831420898438,\n",
       "  138.92864990234375,\n",
       "  119.82970428466797,\n",
       "  148.26544189453125,\n",
       "  155.2546844482422,\n",
       "  145.39300537109375,\n",
       "  145.75341796875,\n",
       "  133.2825164794922,\n",
       "  132.7777557373047,\n",
       "  142.9291229248047,\n",
       "  145.90826416015625,\n",
       "  144.262939453125,\n",
       "  130.40786743164062,\n",
       "  137.18919372558594,\n",
       "  151.56201171875,\n",
       "  150.35968017578125,\n",
       "  119.57196807861328,\n",
       "  138.04605102539062,\n",
       "  140.47613525390625,\n",
       "  140.8092041015625,\n",
       "  146.20068359375,\n",
       "  161.10467529296875,\n",
       "  118.751953125,\n",
       "  125.91107177734375,\n",
       "  138.47238159179688,\n",
       "  144.1440887451172,\n",
       "  130.18252563476562,\n",
       "  139.91595458984375,\n",
       "  134.22760009765625,\n",
       "  123.37998962402344,\n",
       "  140.28750610351562,\n",
       "  126.69438171386719,\n",
       "  132.0308074951172,\n",
       "  145.62998962402344,\n",
       "  123.2796630859375,\n",
       "  143.97203063964844,\n",
       "  134.2412567138672,\n",
       "  143.48001098632812,\n",
       "  159.9872589111328,\n",
       "  150.22129821777344,\n",
       "  134.35366821289062,\n",
       "  134.48867797851562,\n",
       "  129.3508758544922,\n",
       "  141.42588806152344,\n",
       "  123.24275207519531,\n",
       "  124.13908386230469,\n",
       "  150.423095703125,\n",
       "  132.83203125,\n",
       "  127.44087982177734,\n",
       "  142.48590087890625,\n",
       "  153.11904907226562,\n",
       "  141.31402587890625,\n",
       "  142.23553466796875,\n",
       "  140.81735229492188,\n",
       "  131.0801239013672,\n",
       "  135.26792907714844,\n",
       "  140.693115234375,\n",
       "  150.7504119873047,\n",
       "  127.62554931640625,\n",
       "  153.29835510253906,\n",
       "  158.0375213623047,\n",
       "  135.88397216796875,\n",
       "  151.00729370117188,\n",
       "  131.4517822265625,\n",
       "  150.37240600585938,\n",
       "  108.99275207519531,\n",
       "  155.09010314941406,\n",
       "  151.42913818359375,\n",
       "  143.51992797851562,\n",
       "  151.48049926757812,\n",
       "  135.18545532226562,\n",
       "  143.29803466796875,\n",
       "  139.53244018554688,\n",
       "  121.67706298828125,\n",
       "  143.3465576171875,\n",
       "  127.80257415771484,\n",
       "  134.81887817382812,\n",
       "  156.328369140625,\n",
       "  129.61734008789062,\n",
       "  130.20587158203125,\n",
       "  124.17616271972656,\n",
       "  123.18170166015625,\n",
       "  131.6801300048828,\n",
       "  117.89550018310547,\n",
       "  137.73751831054688,\n",
       "  143.0139923095703,\n",
       "  144.76634216308594,\n",
       "  137.53179931640625,\n",
       "  100.92115020751953,\n",
       "  148.0736541748047,\n",
       "  140.56353759765625,\n",
       "  142.01979064941406,\n",
       "  142.98223876953125,\n",
       "  132.58851623535156,\n",
       "  154.9962615966797,\n",
       "  118.20818328857422,\n",
       "  129.51478576660156,\n",
       "  148.62852478027344,\n",
       "  138.96630859375,\n",
       "  142.45974731445312,\n",
       "  139.5318603515625,\n",
       "  146.73883056640625,\n",
       "  162.079345703125],\n",
       " 'val_factorized_top_k/top_3_categorical_accuracy': [0.14863701164722443,\n",
       "  0.2028694450855255,\n",
       "  0.2393113374710083,\n",
       "  0.24218077957630157,\n",
       "  0.22840745747089386,\n",
       "  0.23271162807941437,\n",
       "  0.2329985648393631,\n",
       "  0.22898134589195251,\n",
       "  0.22410330176353455,\n",
       "  0.22754663228988647,\n",
       "  0.22754663228988647,\n",
       "  0.22238163650035858,\n",
       "  0.22553801536560059,\n",
       "  0.2266857922077179,\n",
       "  0.22324246168136597,\n",
       "  0.21893830597400665,\n",
       "  0.2226685732603073,\n",
       "  0.21606886386871338,\n",
       "  0.22065997123718262,\n",
       "  0.21578192710876465,\n",
       "  0.2172166407108307,\n",
       "  0.21492108702659607,\n",
       "  0.21463415026664734,\n",
       "  0.21664275228977203,\n",
       "  0.21061693131923676,\n",
       "  0.21434719860553741,\n",
       "  0.2163558155298233,\n",
       "  0.21406026184558868,\n",
       "  0.21434719860553741,\n",
       "  0.2100430428981781,\n",
       "  0.21434719860553741,\n",
       "  0.20975609123706818,\n",
       "  0.21176470816135406,\n",
       "  0.21090386807918549,\n",
       "  0.21032997965812683,\n",
       "  0.21061693131923676,\n",
       "  0.2100430428981781,\n",
       "  0.2057388871908188,\n",
       "  0.21090386807918549,\n",
       "  0.2088952660560608,\n",
       "  0.20746055245399475,\n",
       "  0.20918220281600952,\n",
       "  0.2100430428981781,\n",
       "  0.2080344259738922,\n",
       "  0.20746055245399475,\n",
       "  0.2068866640329361,\n",
       "  0.20918220281600952,\n",
       "  0.2120516449213028,\n",
       "  0.2088952660560608,\n",
       "  0.20946915447711945,\n",
       "  0.20975609123706818,\n",
       "  0.21032997965812683,\n",
       "  0.21032997965812683,\n",
       "  0.2088952660560608,\n",
       "  0.21147775650024414,\n",
       "  0.20946915447711945,\n",
       "  0.21032997965812683,\n",
       "  0.20602582395076752,\n",
       "  0.20860831439495087,\n",
       "  0.20746055245399475,\n",
       "  0.2080344259738922,\n",
       "  0.20946915447711945,\n",
       "  0.20631277561187744,\n",
       "  0.20918220281600952,\n",
       "  0.20746055245399475,\n",
       "  0.20545193552970886,\n",
       "  0.20659971237182617,\n",
       "  0.2068866640329361,\n",
       "  0.20459111034870148,\n",
       "  0.20832137763500214,\n",
       "  0.20602582395076752,\n",
       "  0.20717360079288483,\n",
       "  0.20774748921394348,\n",
       "  0.20659971237182617,\n",
       "  0.20602582395076752,\n",
       "  0.20459111034870148,\n",
       "  0.2080344259738922,\n",
       "  0.20832137763500214,\n",
       "  0.20516499876976013,\n",
       "  0.20516499876976013,\n",
       "  0.20832137763500214,\n",
       "  0.2088952660560608,\n",
       "  0.2080344259738922,\n",
       "  0.20401722192764282,\n",
       "  0.2068866640329361,\n",
       "  0.20746055245399475,\n",
       "  0.20746055245399475,\n",
       "  0.2088952660560608,\n",
       "  0.20860831439495087,\n",
       "  0.20659971237182617,\n",
       "  0.20659971237182617,\n",
       "  0.2068866640329361,\n",
       "  0.20631277561187744,\n",
       "  0.20659971237182617,\n",
       "  0.2057388871908188,\n",
       "  0.20746055245399475,\n",
       "  0.2068866640329361,\n",
       "  0.20975609123706818,\n",
       "  0.2068866640329361,\n",
       "  0.20717360079288483,\n",
       "  0.20602582395076752,\n",
       "  0.20717360079288483,\n",
       "  0.20602582395076752,\n",
       "  0.20602582395076752,\n",
       "  0.20774748921394348,\n",
       "  0.20717360079288483,\n",
       "  0.20746055245399475,\n",
       "  0.2068866640329361,\n",
       "  0.20631277561187744,\n",
       "  0.2068866640329361,\n",
       "  0.20774748921394348,\n",
       "  0.20918220281600952,\n",
       "  0.20746055245399475,\n",
       "  0.20774748921394348,\n",
       "  0.20602582395076752,\n",
       "  0.20774748921394348,\n",
       "  0.20631277561187744,\n",
       "  0.20631277561187744,\n",
       "  0.20746055245399475,\n",
       "  0.20746055245399475,\n",
       "  0.2080344259738922,\n",
       "  0.20717360079288483,\n",
       "  0.20832137763500214,\n",
       "  0.20631277561187744,\n",
       "  0.20746055245399475,\n",
       "  0.20602582395076752,\n",
       "  0.20774748921394348,\n",
       "  0.2080344259738922,\n",
       "  0.2068866640329361,\n",
       "  0.20459111034870148,\n",
       "  0.20774748921394348,\n",
       "  0.2068866640329361,\n",
       "  0.20545193552970886,\n",
       "  0.20918220281600952,\n",
       "  0.2057388871908188,\n",
       "  0.20746055245399475,\n",
       "  0.20545193552970886,\n",
       "  0.20659971237182617,\n",
       "  0.20659971237182617,\n",
       "  0.20717360079288483,\n",
       "  0.20717360079288483,\n",
       "  0.20717360079288483,\n",
       "  0.20430415868759155,\n",
       "  0.20860831439495087,\n",
       "  0.2068866640329361,\n",
       "  0.20631277561187744,\n",
       "  0.2080344259738922,\n",
       "  0.20717360079288483,\n",
       "  0.20860831439495087,\n",
       "  0.2057388871908188,\n",
       "  0.20832137763500214,\n",
       "  0.2057388871908188,\n",
       "  0.20631277561187744,\n",
       "  0.20717360079288483,\n",
       "  0.20516499876976013,\n",
       "  0.2080344259738922,\n",
       "  0.20832137763500214,\n",
       "  0.2068866640329361,\n",
       "  0.20602582395076752,\n",
       "  0.20659971237182617,\n",
       "  0.2057388871908188,\n",
       "  0.20659971237182617,\n",
       "  0.20545193552970886,\n",
       "  0.2068866640329361,\n",
       "  0.2088952660560608,\n",
       "  0.2088952660560608,\n",
       "  0.20717360079288483,\n",
       "  0.20659971237182617,\n",
       "  0.20545193552970886,\n",
       "  0.20659971237182617,\n",
       "  0.20746055245399475,\n",
       "  0.20401722192764282,\n",
       "  0.20631277561187744,\n",
       "  0.20774748921394348,\n",
       "  0.20717360079288483,\n",
       "  0.20659971237182617,\n",
       "  0.20545193552970886,\n",
       "  0.2088952660560608,\n",
       "  0.20659971237182617,\n",
       "  0.2080344259738922,\n",
       "  0.20516499876976013,\n",
       "  0.20717360079288483,\n",
       "  0.20459111034870148,\n",
       "  0.20602582395076752,\n",
       "  0.20516499876976013,\n",
       "  0.2068866640329361,\n",
       "  0.2057388871908188,\n",
       "  0.20516499876976013,\n",
       "  0.20717360079288483,\n",
       "  0.20659971237182617,\n",
       "  0.2057388871908188,\n",
       "  0.20545193552970886,\n",
       "  0.20545193552970886,\n",
       "  0.20516499876976013,\n",
       "  0.2048780471086502,\n",
       "  0.2057388871908188,\n",
       "  0.20832137763500214,\n",
       "  0.20717360079288483,\n",
       "  0.2068866640329361,\n",
       "  0.2080344259738922],\n",
       " 'val_factorized_top_k/top_5_categorical_accuracy': [0.22065997123718262,\n",
       "  0.2571018636226654,\n",
       "  0.31822094321250916,\n",
       "  0.3208034336566925,\n",
       "  0.2923959791660309,\n",
       "  0.2895265519618988,\n",
       "  0.2923959791660309,\n",
       "  0.29010042548179626,\n",
       "  0.28981348872184753,\n",
       "  0.285509318113327,\n",
       "  0.28493544459342957,\n",
       "  0.284074604511261,\n",
       "  0.2883787751197815,\n",
       "  0.2872309982776642,\n",
       "  0.2886657118797302,\n",
       "  0.2829268276691437,\n",
       "  0.2820659875869751,\n",
       "  0.2823529541492462,\n",
       "  0.27948349714279175,\n",
       "  0.277761846780777,\n",
       "  0.2803443372249603,\n",
       "  0.2769010066986084,\n",
       "  0.2780487835407257,\n",
       "  0.27632710337638855,\n",
       "  0.27546629309654236,\n",
       "  0.27431851625442505,\n",
       "  0.27403154969215393,\n",
       "  0.27431851625442505,\n",
       "  0.2694404721260071,\n",
       "  0.27345767617225647,\n",
       "  0.2717360258102417,\n",
       "  0.2685796320438385,\n",
       "  0.2694404721260071,\n",
       "  0.2685796320438385,\n",
       "  0.27001434564590454,\n",
       "  0.2651363015174866,\n",
       "  0.2697274088859558,\n",
       "  0.2697274088859558,\n",
       "  0.26800572872161865,\n",
       "  0.26915350556373596,\n",
       "  0.2645623981952667,\n",
       "  0.2674318552017212,\n",
       "  0.26685795187950134,\n",
       "  0.26571017503738403,\n",
       "  0.26886656880378723,\n",
       "  0.2685796320438385,\n",
       "  0.2662840783596039,\n",
       "  0.2645623981952667,\n",
       "  0.26714491844177246,\n",
       "  0.26571017503738403,\n",
       "  0.26599714159965515,\n",
       "  0.2662840783596039,\n",
       "  0.264275461435318,\n",
       "  0.26484936475753784,\n",
       "  0.2634146213531494,\n",
       "  0.26370158791542053,\n",
       "  0.26571017503738403,\n",
       "  0.2654232382774353,\n",
       "  0.2654232382774353,\n",
       "  0.26800572872161865,\n",
       "  0.2685796320438385,\n",
       "  0.2651363015174866,\n",
       "  0.26370158791542053,\n",
       "  0.26484936475753784,\n",
       "  0.2654232382774353,\n",
       "  0.26484936475753784,\n",
       "  0.2622668445110321,\n",
       "  0.2651363015174866,\n",
       "  0.26599714159965515,\n",
       "  0.2645623981952667,\n",
       "  0.26484936475753784,\n",
       "  0.2625538110733032,\n",
       "  0.2622668445110321,\n",
       "  0.26398852467536926,\n",
       "  0.264275461435318,\n",
       "  0.26398852467536926,\n",
       "  0.2645623981952667,\n",
       "  0.26484936475753784,\n",
       "  0.2625538110733032,\n",
       "  0.26398852467536926,\n",
       "  0.26484936475753784,\n",
       "  0.2665710151195526,\n",
       "  0.26685795187950134,\n",
       "  0.26599714159965515,\n",
       "  0.26599714159965515,\n",
       "  0.26599714159965515,\n",
       "  0.264275461435318,\n",
       "  0.26599714159965515,\n",
       "  0.26599714159965515,\n",
       "  0.26484936475753784,\n",
       "  0.26398852467536926,\n",
       "  0.2645623981952667,\n",
       "  0.2654232382774353,\n",
       "  0.2619799077510834,\n",
       "  0.26571017503738403,\n",
       "  0.264275461435318,\n",
       "  0.2645623981952667,\n",
       "  0.2631276845932007,\n",
       "  0.264275461435318,\n",
       "  0.2662840783596039,\n",
       "  0.264275461435318,\n",
       "  0.26484936475753784,\n",
       "  0.2654232382774353,\n",
       "  0.2634146213531494,\n",
       "  0.26398852467536926,\n",
       "  0.26484936475753784,\n",
       "  0.26685795187950134,\n",
       "  0.26398852467536926,\n",
       "  0.2645623981952667,\n",
       "  0.26484936475753784,\n",
       "  0.2634146213531494,\n",
       "  0.26484936475753784,\n",
       "  0.264275461435318,\n",
       "  0.2634146213531494,\n",
       "  0.26685795187950134,\n",
       "  0.264275461435318,\n",
       "  0.2631276845932007,\n",
       "  0.26284074783325195,\n",
       "  0.26599714159965515,\n",
       "  0.26484936475753784,\n",
       "  0.2651363015174866,\n",
       "  0.2662840783596039,\n",
       "  0.26398852467536926,\n",
       "  0.264275461435318,\n",
       "  0.26370158791542053,\n",
       "  0.2625538110733032,\n",
       "  0.26571017503738403,\n",
       "  0.2634146213531494,\n",
       "  0.2645623981952667,\n",
       "  0.26370158791542053,\n",
       "  0.26370158791542053,\n",
       "  0.2631276845932007,\n",
       "  0.26398852467536926,\n",
       "  0.26484936475753784,\n",
       "  0.2645623981952667,\n",
       "  0.26484936475753784,\n",
       "  0.2619799077510834,\n",
       "  0.2619799077510834,\n",
       "  0.26284074783325195,\n",
       "  0.26484936475753784,\n",
       "  0.2611190676689148,\n",
       "  0.2625538110733032,\n",
       "  0.26370158791542053,\n",
       "  0.26398852467536926,\n",
       "  0.2622668445110321,\n",
       "  0.2654232382774353,\n",
       "  0.2654232382774353,\n",
       "  0.2645623981952667,\n",
       "  0.26398852467536926,\n",
       "  0.2625538110733032,\n",
       "  0.2631276845932007,\n",
       "  0.26284074783325195,\n",
       "  0.26398852467536926,\n",
       "  0.26370158791542053,\n",
       "  0.26284074783325195,\n",
       "  0.2634146213531494,\n",
       "  0.2625538110733032,\n",
       "  0.2654232382774353,\n",
       "  0.26169297099113464,\n",
       "  0.26484936475753784,\n",
       "  0.2631276845932007,\n",
       "  0.2654232382774353,\n",
       "  0.264275461435318,\n",
       "  0.2645623981952667,\n",
       "  0.26169297099113464,\n",
       "  0.26398852467536926,\n",
       "  0.26284074783325195,\n",
       "  0.26398852467536926,\n",
       "  0.2634146213531494,\n",
       "  0.264275461435318,\n",
       "  0.26284074783325195,\n",
       "  0.2654232382774353,\n",
       "  0.2619799077510834,\n",
       "  0.2611190676689148,\n",
       "  0.26370158791542053,\n",
       "  0.2625538110733032,\n",
       "  0.2651363015174866,\n",
       "  0.26398852467536926,\n",
       "  0.26484936475753784,\n",
       "  0.264275461435318,\n",
       "  0.2634146213531494,\n",
       "  0.2645623981952667,\n",
       "  0.26284074783325195,\n",
       "  0.26370158791542053,\n",
       "  0.26484936475753784,\n",
       "  0.26370158791542053,\n",
       "  0.2645623981952667,\n",
       "  0.2634146213531494,\n",
       "  0.2634146213531494,\n",
       "  0.2651363015174866,\n",
       "  0.26284074783325195,\n",
       "  0.2631276845932007,\n",
       "  0.2619799077510834,\n",
       "  0.2645623981952667,\n",
       "  0.26484936475753784,\n",
       "  0.2634146213531494,\n",
       "  0.26370158791542053,\n",
       "  0.2602582573890686,\n",
       "  0.2651363015174866,\n",
       "  0.2622668445110321],\n",
       " 'val_factorized_top_k/top_10_categorical_accuracy': [0.31305596232414246,\n",
       "  0.3532281219959259,\n",
       "  0.45107603073120117,\n",
       "  0.4312768876552582,\n",
       "  0.40918222069740295,\n",
       "  0.3928264081478119,\n",
       "  0.40172165632247925,\n",
       "  0.3865136206150055,\n",
       "  0.3948349952697754,\n",
       "  0.39569583535194397,\n",
       "  0.39024388790130615,\n",
       "  0.38507890701293945,\n",
       "  0.39426112174987793,\n",
       "  0.3873744606971741,\n",
       "  0.39426112174987793,\n",
       "  0.38106170296669006,\n",
       "  0.3842180669307709,\n",
       "  0.3802008628845215,\n",
       "  0.38077473640441895,\n",
       "  0.3833572566509247,\n",
       "  0.3876613974571228,\n",
       "  0.37991392612457275,\n",
       "  0.3804877996444702,\n",
       "  0.37675753235816956,\n",
       "  0.3804877996444702,\n",
       "  0.3813486397266388,\n",
       "  0.3790530860424042,\n",
       "  0.375896692276001,\n",
       "  0.37790530920028687,\n",
       "  0.37876614928245544,\n",
       "  0.3741750419139862,\n",
       "  0.3770444691181183,\n",
       "  0.375896692276001,\n",
       "  0.3753228187561035,\n",
       "  0.3790530860424042,\n",
       "  0.3738881051540375,\n",
       "  0.3804877996444702,\n",
       "  0.37761837244033813,\n",
       "  0.37474891543388367,\n",
       "  0.37474891543388367,\n",
       "  0.37474891543388367,\n",
       "  0.37761837244033813,\n",
       "  0.37360113859176636,\n",
       "  0.3721664249897003,\n",
       "  0.37675753235816956,\n",
       "  0.3770444691181183,\n",
       "  0.3733142018318176,\n",
       "  0.3761836588382721,\n",
       "  0.3738881051540375,\n",
       "  0.3707317113876343,\n",
       "  0.37015780806541443,\n",
       "  0.37159255146980286,\n",
       "  0.37130558490753174,\n",
       "  0.37245336174964905,\n",
       "  0.3733142018318176,\n",
       "  0.37044477462768555,\n",
       "  0.3741750419139862,\n",
       "  0.37245336174964905,\n",
       "  0.3733142018318176,\n",
       "  0.3738881051540375,\n",
       "  0.3741750419139862,\n",
       "  0.37245336174964905,\n",
       "  0.3730272650718689,\n",
       "  0.37474891543388367,\n",
       "  0.37245336174964905,\n",
       "  0.375896692276001,\n",
       "  0.37446197867393494,\n",
       "  0.3733142018318176,\n",
       "  0.37474891543388367,\n",
       "  0.3741750419139862,\n",
       "  0.37446197867393494,\n",
       "  0.37360113859176636,\n",
       "  0.3750358819961548,\n",
       "  0.37130558490753174,\n",
       "  0.3750358819961548,\n",
       "  0.3733142018318176,\n",
       "  0.3741750419139862,\n",
       "  0.37274032831192017,\n",
       "  0.37360113859176636,\n",
       "  0.3738881051540375,\n",
       "  0.3741750419139862,\n",
       "  0.375896692276001,\n",
       "  0.3721664249897003,\n",
       "  0.3738881051540375,\n",
       "  0.375896692276001,\n",
       "  0.3753228187561035,\n",
       "  0.37245336174964905,\n",
       "  0.37474891543388367,\n",
       "  0.37446197867393494,\n",
       "  0.37274032831192017,\n",
       "  0.3741750419139862,\n",
       "  0.37274032831192017,\n",
       "  0.3718794882297516,\n",
       "  0.3721664249897003,\n",
       "  0.37360113859176636,\n",
       "  0.3733142018318176,\n",
       "  0.3721664249897003,\n",
       "  0.3730272650718689,\n",
       "  0.37159255146980286,\n",
       "  0.3753228187561035,\n",
       "  0.3738881051540375,\n",
       "  0.3741750419139862,\n",
       "  0.3738881051540375,\n",
       "  0.3730272650718689,\n",
       "  0.3733142018318176,\n",
       "  0.37360113859176636,\n",
       "  0.3733142018318176,\n",
       "  0.37446197867393494,\n",
       "  0.3733142018318176,\n",
       "  0.37360113859176636,\n",
       "  0.37274032831192017,\n",
       "  0.37245336174964905,\n",
       "  0.3741750419139862,\n",
       "  0.3750358819961548,\n",
       "  0.37360113859176636,\n",
       "  0.3738881051540375,\n",
       "  0.3718794882297516,\n",
       "  0.37446197867393494,\n",
       "  0.3741750419139862,\n",
       "  0.37274032831192017,\n",
       "  0.37360113859176636,\n",
       "  0.3733142018318176,\n",
       "  0.3738881051540375,\n",
       "  0.37130558490753174,\n",
       "  0.3730272650718689,\n",
       "  0.3730272650718689,\n",
       "  0.3718794882297516,\n",
       "  0.37360113859176636,\n",
       "  0.3741750419139862,\n",
       "  0.3738881051540375,\n",
       "  0.3738881051540375,\n",
       "  0.37245336174964905,\n",
       "  0.3721664249897003,\n",
       "  0.37274032831192017,\n",
       "  0.3738881051540375,\n",
       "  0.3730272650718689,\n",
       "  0.3730272650718689,\n",
       "  0.3730272650718689,\n",
       "  0.3738881051540375,\n",
       "  0.3733142018318176,\n",
       "  0.37274032831192017,\n",
       "  0.37245336174964905,\n",
       "  0.37245336174964905,\n",
       "  0.37446197867393494,\n",
       "  0.37274032831192017,\n",
       "  0.3721664249897003,\n",
       "  0.37245336174964905,\n",
       "  0.3733142018318176,\n",
       "  0.37474891543388367,\n",
       "  0.3738881051540375,\n",
       "  0.3741750419139862,\n",
       "  0.37274032831192017,\n",
       "  0.37274032831192017,\n",
       "  0.3721664249897003,\n",
       "  0.3730272650718689,\n",
       "  0.3733142018318176,\n",
       "  0.37446197867393494,\n",
       "  0.37159255146980286,\n",
       "  0.3733142018318176,\n",
       "  0.37474891543388367,\n",
       "  0.3721664249897003,\n",
       "  0.37245336174964905,\n",
       "  0.3738881051540375,\n",
       "  0.3738881051540375,\n",
       "  0.3741750419139862,\n",
       "  0.3730272650718689,\n",
       "  0.3730272650718689,\n",
       "  0.3730272650718689,\n",
       "  0.3733142018318176,\n",
       "  0.37560975551605225,\n",
       "  0.37360113859176636,\n",
       "  0.3733142018318176,\n",
       "  0.3718794882297516,\n",
       "  0.3718794882297516,\n",
       "  0.3733142018318176,\n",
       "  0.3733142018318176,\n",
       "  0.3730272650718689,\n",
       "  0.3730272650718689,\n",
       "  0.37245336174964905,\n",
       "  0.37360113859176636,\n",
       "  0.3741750419139862,\n",
       "  0.3730272650718689,\n",
       "  0.3741750419139862,\n",
       "  0.3733142018318176,\n",
       "  0.3733142018318176,\n",
       "  0.37360113859176636,\n",
       "  0.3718794882297516,\n",
       "  0.37130558490753174,\n",
       "  0.37360113859176636,\n",
       "  0.37274032831192017,\n",
       "  0.37360113859176636,\n",
       "  0.37360113859176636,\n",
       "  0.3741750419139862,\n",
       "  0.37245336174964905,\n",
       "  0.3738881051540375,\n",
       "  0.3738881051540375,\n",
       "  0.37274032831192017,\n",
       "  0.37130558490753174,\n",
       "  0.3738881051540375,\n",
       "  0.3730272650718689],\n",
       " 'val_factorized_top_k/top_15_categorical_accuracy': [0.3916786313056946,\n",
       "  0.430416077375412,\n",
       "  0.5377331376075745,\n",
       "  0.5185078978538513,\n",
       "  0.4944045841693878,\n",
       "  0.48866569995880127,\n",
       "  0.48436155915260315,\n",
       "  0.45394548773765564,\n",
       "  0.4754662811756134,\n",
       "  0.4806312620639801,\n",
       "  0.46771878004074097,\n",
       "  0.4596843719482422,\n",
       "  0.4731707274913788,\n",
       "  0.46771878004074097,\n",
       "  0.471449077129364,\n",
       "  0.45939740538597107,\n",
       "  0.46972739696502686,\n",
       "  0.4585365951061249,\n",
       "  0.45824962854385376,\n",
       "  0.4691535234451294,\n",
       "  0.4619799256324768,\n",
       "  0.4671449065208435,\n",
       "  0.46771878004074097,\n",
       "  0.45911046862602234,\n",
       "  0.46226686239242554,\n",
       "  0.4703013002872467,\n",
       "  0.4691535234451294,\n",
       "  0.4599713087081909,\n",
       "  0.4637015759944916,\n",
       "  0.4691535234451294,\n",
       "  0.4631277024745941,\n",
       "  0.46743184328079224,\n",
       "  0.46571019291877747,\n",
       "  0.4639885127544403,\n",
       "  0.46657103300094604,\n",
       "  0.4680057466030121,\n",
       "  0.4703013002872467,\n",
       "  0.4694404602050781,\n",
       "  0.46456241607666016,\n",
       "  0.4682926833629608,\n",
       "  0.4691535234451294,\n",
       "  0.4700143337249756,\n",
       "  0.471449077129364,\n",
       "  0.4688665568828583,\n",
       "  0.471449077129364,\n",
       "  0.47173601388931274,\n",
       "  0.4680057466030121,\n",
       "  0.4723098874092102,\n",
       "  0.4725968539714813,\n",
       "  0.4700143337249756,\n",
       "  0.47173601388931274,\n",
       "  0.471449077129364,\n",
       "  0.47173601388931274,\n",
       "  0.4700143337249756,\n",
       "  0.47087517380714417,\n",
       "  0.4691535234451294,\n",
       "  0.47087517380714417,\n",
       "  0.47087517380714417,\n",
       "  0.4703013002872467,\n",
       "  0.4711621105670929,\n",
       "  0.47288379073143005,\n",
       "  0.47173601388931274,\n",
       "  0.47173601388931274,\n",
       "  0.4734576642513275,\n",
       "  0.4725968539714813,\n",
       "  0.4743185043334961,\n",
       "  0.4725968539714813,\n",
       "  0.4743185043334961,\n",
       "  0.47288379073143005,\n",
       "  0.4725968539714813,\n",
       "  0.4734576642513275,\n",
       "  0.4725968539714813,\n",
       "  0.4751793444156647,\n",
       "  0.477761834859848,\n",
       "  0.4746054410934448,\n",
       "  0.4746054410934448,\n",
       "  0.476327121257782,\n",
       "  0.4754662811756134,\n",
       "  0.4743185043334961,\n",
       "  0.4746054410934448,\n",
       "  0.476327121257782,\n",
       "  0.476327121257782,\n",
       "  0.47604018449783325,\n",
       "  0.476327121257782,\n",
       "  0.47403156757354736,\n",
       "  0.4754662811756134,\n",
       "  0.4751793444156647,\n",
       "  0.47690099477767944,\n",
       "  0.47690099477767944,\n",
       "  0.4751793444156647,\n",
       "  0.47604018449783325,\n",
       "  0.4766140580177307,\n",
       "  0.4723098874092102,\n",
       "  0.47690099477767944,\n",
       "  0.47604018449783325,\n",
       "  0.4754662811756134,\n",
       "  0.4725968539714813,\n",
       "  0.47374463081359863,\n",
       "  0.4751793444156647,\n",
       "  0.4766140580177307,\n",
       "  0.47690099477767944,\n",
       "  0.47489240765571594,\n",
       "  0.4766140580177307,\n",
       "  0.4743185043334961,\n",
       "  0.4751793444156647,\n",
       "  0.47575321793556213,\n",
       "  0.4743185043334961,\n",
       "  0.47690099477767944,\n",
       "  0.47489240765571594,\n",
       "  0.47489240765571594,\n",
       "  0.47604018449783325,\n",
       "  0.4766140580177307,\n",
       "  0.4774748980998993,\n",
       "  0.47489240765571594,\n",
       "  0.47489240765571594,\n",
       "  0.4754662811756134,\n",
       "  0.47604018449783325,\n",
       "  0.4751793444156647,\n",
       "  0.47604018449783325,\n",
       "  0.4766140580177307,\n",
       "  0.47575321793556213,\n",
       "  0.4751793444156647,\n",
       "  0.476327121257782,\n",
       "  0.4754662811756134,\n",
       "  0.47604018449783325,\n",
       "  0.4751793444156647,\n",
       "  0.47575321793556213,\n",
       "  0.47690099477767944,\n",
       "  0.47575321793556213,\n",
       "  0.4754662811756134,\n",
       "  0.47489240765571594,\n",
       "  0.47604018449783325,\n",
       "  0.47604018449783325,\n",
       "  0.4734576642513275,\n",
       "  0.4743185043334961,\n",
       "  0.47374463081359863,\n",
       "  0.4751793444156647,\n",
       "  0.47575321793556213,\n",
       "  0.477761834859848,\n",
       "  0.477761834859848,\n",
       "  0.476327121257782,\n",
       "  0.4766140580177307,\n",
       "  0.4754662811756134,\n",
       "  0.4754662811756134,\n",
       "  0.4754662811756134,\n",
       "  0.4751793444156647,\n",
       "  0.47575321793556213,\n",
       "  0.4766140580177307,\n",
       "  0.4774748980998993,\n",
       "  0.4754662811756134,\n",
       "  0.47718796133995056,\n",
       "  0.47604018449783325,\n",
       "  0.4766140580177307,\n",
       "  0.4731707274913788,\n",
       "  0.4774748980998993,\n",
       "  0.4743185043334961,\n",
       "  0.47575321793556213,\n",
       "  0.47718796133995056,\n",
       "  0.47718796133995056,\n",
       "  0.47604018449783325,\n",
       "  0.476327121257782,\n",
       "  0.47804877161979675,\n",
       "  0.4743185043334961,\n",
       "  0.4751793444156647,\n",
       "  0.4746054410934448,\n",
       "  0.47690099477767944,\n",
       "  0.4754662811756134,\n",
       "  0.47575321793556213,\n",
       "  0.4743185043334961,\n",
       "  0.4754662811756134,\n",
       "  0.47604018449783325,\n",
       "  0.47718796133995056,\n",
       "  0.47575321793556213,\n",
       "  0.47604018449783325,\n",
       "  0.47718796133995056,\n",
       "  0.4751793444156647,\n",
       "  0.4766140580177307,\n",
       "  0.4766140580177307,\n",
       "  0.4766140580177307,\n",
       "  0.4754662811756134,\n",
       "  0.47403156757354736,\n",
       "  0.4743185043334961,\n",
       "  0.4766140580177307,\n",
       "  0.47489240765571594,\n",
       "  0.4746054410934448,\n",
       "  0.47489240765571594,\n",
       "  0.47690099477767944,\n",
       "  0.47489240765571594,\n",
       "  0.4766140580177307,\n",
       "  0.47403156757354736,\n",
       "  0.4754662811756134,\n",
       "  0.4751793444156647,\n",
       "  0.4774748980998993,\n",
       "  0.47374463081359863,\n",
       "  0.47690099477767944,\n",
       "  0.4751793444156647,\n",
       "  0.4746054410934448,\n",
       "  0.4754662811756134,\n",
       "  0.47604018449783325,\n",
       "  0.47690099477767944],\n",
       " 'val_factorized_top_k/top_25_categorical_accuracy': [0.5196556448936462,\n",
       "  0.5977044701576233,\n",
       "  0.6410329937934875,\n",
       "  0.6226685643196106,\n",
       "  0.6109038591384888,\n",
       "  0.6137732863426208,\n",
       "  0.6068866848945618,\n",
       "  0.5896700024604797,\n",
       "  0.6022955775260925,\n",
       "  0.6005738973617554,\n",
       "  0.5899569392204285,\n",
       "  0.5868005752563477,\n",
       "  0.5982783436775208,\n",
       "  0.5962697267532349,\n",
       "  0.593113362789154,\n",
       "  0.5853658318519592,\n",
       "  0.5948349833488464,\n",
       "  0.5876613855361938,\n",
       "  0.5888091921806335,\n",
       "  0.5913916826248169,\n",
       "  0.593113362789154,\n",
       "  0.5899569392204285,\n",
       "  0.5948349833488464,\n",
       "  0.5888091921806335,\n",
       "  0.5905308723449707,\n",
       "  0.5939741730690002,\n",
       "  0.5956958532333374,\n",
       "  0.5879483222961426,\n",
       "  0.5945480465888977,\n",
       "  0.597130537033081,\n",
       "  0.5934002995491028,\n",
       "  0.5945480465888977,\n",
       "  0.5934002995491028,\n",
       "  0.5928264260292053,\n",
       "  0.5974174737930298,\n",
       "  0.5977044701576233,\n",
       "  0.5994260907173157,\n",
       "  0.5977044701576233,\n",
       "  0.6000000238418579,\n",
       "  0.5988522171974182,\n",
       "  0.6000000238418579,\n",
       "  0.6017216444015503,\n",
       "  0.6000000238418579,\n",
       "  0.597991406917572,\n",
       "  0.597991406917572,\n",
       "  0.5977044701576233,\n",
       "  0.5982783436775208,\n",
       "  0.6008608341217041,\n",
       "  0.5985652804374695,\n",
       "  0.5985652804374695,\n",
       "  0.6014347076416016,\n",
       "  0.6005738973617554,\n",
       "  0.6000000238418579,\n",
       "  0.5988522171974182,\n",
       "  0.5985652804374695,\n",
       "  0.597130537033081,\n",
       "  0.5997130274772644,\n",
       "  0.5982783436775208,\n",
       "  0.5997130274772644,\n",
       "  0.6000000238418579,\n",
       "  0.5977044701576233,\n",
       "  0.5982783436775208,\n",
       "  0.5988522171974182,\n",
       "  0.5968436002731323,\n",
       "  0.5991391539573669,\n",
       "  0.6005738973617554,\n",
       "  0.5982783436775208,\n",
       "  0.6002869606018066,\n",
       "  0.5997130274772644,\n",
       "  0.6002869606018066,\n",
       "  0.5994260907173157,\n",
       "  0.6002869606018066,\n",
       "  0.6005738973617554,\n",
       "  0.5997130274772644,\n",
       "  0.5994260907173157,\n",
       "  0.5988522171974182,\n",
       "  0.5991391539573669,\n",
       "  0.6000000238418579,\n",
       "  0.6002869606018066,\n",
       "  0.6005738973617554,\n",
       "  0.5994260907173157,\n",
       "  0.5982783436775208,\n",
       "  0.5988522171974182,\n",
       "  0.5991391539573669,\n",
       "  0.5985652804374695,\n",
       "  0.6000000238418579,\n",
       "  0.5988522171974182,\n",
       "  0.6008608341217041,\n",
       "  0.602008581161499,\n",
       "  0.5994260907173157,\n",
       "  0.6005738973617554,\n",
       "  0.5988522171974182,\n",
       "  0.6000000238418579,\n",
       "  0.5991391539573669,\n",
       "  0.5982783436775208,\n",
       "  0.5991391539573669,\n",
       "  0.5994260907173157,\n",
       "  0.5974174737930298,\n",
       "  0.5997130274772644,\n",
       "  0.5997130274772644,\n",
       "  0.5991391539573669,\n",
       "  0.6002869606018066,\n",
       "  0.5991391539573669,\n",
       "  0.5994260907173157,\n",
       "  0.6000000238418579,\n",
       "  0.5982783436775208,\n",
       "  0.6002869606018066,\n",
       "  0.5994260907173157,\n",
       "  0.597991406917572,\n",
       "  0.5994260907173157,\n",
       "  0.5997130274772644,\n",
       "  0.6002869606018066,\n",
       "  0.5994260907173157,\n",
       "  0.5982783436775208,\n",
       "  0.5985652804374695,\n",
       "  0.5991391539573669,\n",
       "  0.5997130274772644,\n",
       "  0.6002869606018066,\n",
       "  0.5982783436775208,\n",
       "  0.5994260907173157,\n",
       "  0.5994260907173157,\n",
       "  0.5997130274772644,\n",
       "  0.5991391539573669,\n",
       "  0.5977044701576233,\n",
       "  0.5994260907173157,\n",
       "  0.5988522171974182,\n",
       "  0.6002869606018066,\n",
       "  0.6000000238418579,\n",
       "  0.5988522171974182,\n",
       "  0.5997130274772644,\n",
       "  0.5985652804374695,\n",
       "  0.6000000238418579,\n",
       "  0.5994260907173157,\n",
       "  0.5991391539573669,\n",
       "  0.6000000238418579,\n",
       "  0.6000000238418579,\n",
       "  0.6000000238418579,\n",
       "  0.5974174737930298,\n",
       "  0.5997130274772644,\n",
       "  0.5994260907173157,\n",
       "  0.6000000238418579,\n",
       "  0.6000000238418579,\n",
       "  0.6000000238418579,\n",
       "  0.5994260907173157,\n",
       "  0.5985652804374695,\n",
       "  0.5988522171974182,\n",
       "  0.5994260907173157,\n",
       "  0.5982783436775208,\n",
       "  0.5985652804374695,\n",
       "  0.5991391539573669,\n",
       "  0.5994260907173157,\n",
       "  0.6011477708816528,\n",
       "  0.6005738973617554,\n",
       "  0.5988522171974182,\n",
       "  0.5994260907173157,\n",
       "  0.5985652804374695,\n",
       "  0.5997130274772644,\n",
       "  0.5985652804374695,\n",
       "  0.5982783436775208,\n",
       "  0.6000000238418579,\n",
       "  0.5994260907173157,\n",
       "  0.6000000238418579,\n",
       "  0.5974174737930298,\n",
       "  0.5994260907173157,\n",
       "  0.5991391539573669,\n",
       "  0.5991391539573669,\n",
       "  0.5991391539573669,\n",
       "  0.5988522171974182,\n",
       "  0.5991391539573669,\n",
       "  0.5997130274772644,\n",
       "  0.5988522171974182,\n",
       "  0.5988522171974182,\n",
       "  0.5997130274772644,\n",
       "  0.5997130274772644,\n",
       "  0.6005738973617554,\n",
       "  0.5985652804374695,\n",
       "  0.6000000238418579,\n",
       "  0.6002869606018066,\n",
       "  0.6000000238418579,\n",
       "  0.5994260907173157,\n",
       "  0.5991391539573669,\n",
       "  0.6002869606018066,\n",
       "  0.5988522171974182,\n",
       "  0.5991391539573669,\n",
       "  0.6000000238418579,\n",
       "  0.6000000238418579,\n",
       "  0.5985652804374695,\n",
       "  0.6008608341217041,\n",
       "  0.6005738973617554,\n",
       "  0.5991391539573669,\n",
       "  0.5997130274772644,\n",
       "  0.597991406917572,\n",
       "  0.5997130274772644,\n",
       "  0.5994260907173157,\n",
       "  0.5991391539573669,\n",
       "  0.6000000238418579,\n",
       "  0.5994260907173157,\n",
       "  0.597991406917572,\n",
       "  0.5994260907173157,\n",
       "  0.5997130274772644],\n",
       " 'val_loss': [1942.3702392578125,\n",
       "  1928.49755859375,\n",
       "  2032.374267578125,\n",
       "  2167.685302734375,\n",
       "  2246.8017578125,\n",
       "  2294.7529296875,\n",
       "  2329.121826171875,\n",
       "  2350.193359375,\n",
       "  2367.4130859375,\n",
       "  2393.541015625,\n",
       "  2415.421142578125,\n",
       "  2433.489013671875,\n",
       "  2438.296875,\n",
       "  2456.654052734375,\n",
       "  2465.72412109375,\n",
       "  2479.626708984375,\n",
       "  2496.458740234375,\n",
       "  2504.90234375,\n",
       "  2516.199951171875,\n",
       "  2529.60498046875,\n",
       "  2533.04052734375,\n",
       "  2543.293701171875,\n",
       "  2551.33056640625,\n",
       "  2561.157470703125,\n",
       "  2566.829345703125,\n",
       "  2575.076904296875,\n",
       "  2579.3974609375,\n",
       "  2587.737060546875,\n",
       "  2595.954345703125,\n",
       "  2601.29833984375,\n",
       "  2605.4091796875,\n",
       "  2611.174072265625,\n",
       "  2614.8232421875,\n",
       "  2620.310302734375,\n",
       "  2626.581787109375,\n",
       "  2632.2646484375,\n",
       "  2632.61328125,\n",
       "  2639.600341796875,\n",
       "  2645.23583984375,\n",
       "  2647.780517578125,\n",
       "  2650.694091796875,\n",
       "  2651.56103515625,\n",
       "  2654.155517578125,\n",
       "  2655.84033203125,\n",
       "  2658.68994140625,\n",
       "  2661.564208984375,\n",
       "  2663.593505859375,\n",
       "  2665.86181640625,\n",
       "  2667.630615234375,\n",
       "  2670.31689453125,\n",
       "  2671.939208984375,\n",
       "  2673.373046875,\n",
       "  2675.27978515625,\n",
       "  2677.61669921875,\n",
       "  2680.505126953125,\n",
       "  2681.38134765625,\n",
       "  2683.181396484375,\n",
       "  2684.25,\n",
       "  2685.2705078125,\n",
       "  2686.368896484375,\n",
       "  2688.20654296875,\n",
       "  2689.2314453125,\n",
       "  2690.24169921875,\n",
       "  2691.490966796875,\n",
       "  2692.84912109375,\n",
       "  2693.956298828125,\n",
       "  2694.598876953125,\n",
       "  2695.69140625,\n",
       "  2696.35595703125,\n",
       "  2696.971923828125,\n",
       "  2697.73486328125,\n",
       "  2698.934326171875,\n",
       "  2699.356689453125,\n",
       "  2699.743408203125,\n",
       "  2700.56298828125,\n",
       "  2701.10791015625,\n",
       "  2701.7841796875,\n",
       "  2702.21533203125,\n",
       "  2702.902099609375,\n",
       "  2703.4814453125,\n",
       "  2703.95458984375,\n",
       "  2704.634033203125,\n",
       "  2705.035888671875,\n",
       "  2705.615966796875,\n",
       "  2705.91162109375,\n",
       "  2706.273681640625,\n",
       "  2706.430419921875,\n",
       "  2706.787841796875,\n",
       "  2707.190185546875,\n",
       "  2707.4296875,\n",
       "  2707.819091796875,\n",
       "  2708.218994140625,\n",
       "  2708.54443359375,\n",
       "  2708.73681640625,\n",
       "  2709.058837890625,\n",
       "  2709.364501953125,\n",
       "  2709.580810546875,\n",
       "  2709.781005859375,\n",
       "  2710.00048828125,\n",
       "  2710.21435546875,\n",
       "  2710.50341796875,\n",
       "  2710.758544921875,\n",
       "  2710.914794921875,\n",
       "  2711.05517578125,\n",
       "  2711.1845703125,\n",
       "  2711.2822265625,\n",
       "  2711.375,\n",
       "  2711.5341796875,\n",
       "  2711.743408203125,\n",
       "  2711.901611328125,\n",
       "  2712.10205078125,\n",
       "  2712.20654296875,\n",
       "  2712.283203125,\n",
       "  2712.3974609375,\n",
       "  2712.485595703125,\n",
       "  2712.614990234375,\n",
       "  2712.712158203125,\n",
       "  2712.7802734375,\n",
       "  2712.90576171875,\n",
       "  2713.04541015625,\n",
       "  2713.102294921875,\n",
       "  2713.169189453125,\n",
       "  2713.245361328125,\n",
       "  2713.3134765625,\n",
       "  2713.3876953125,\n",
       "  2713.45947265625,\n",
       "  2713.531982421875,\n",
       "  2713.605712890625,\n",
       "  2713.65380859375,\n",
       "  2713.7080078125,\n",
       "  2713.7548828125,\n",
       "  2713.8076171875,\n",
       "  2713.865478515625,\n",
       "  2713.91357421875,\n",
       "  2713.962158203125,\n",
       "  2714.0,\n",
       "  2714.046630859375,\n",
       "  2714.10107421875,\n",
       "  2714.126220703125,\n",
       "  2714.156982421875,\n",
       "  2714.1904296875,\n",
       "  2714.21923828125,\n",
       "  2714.244873046875,\n",
       "  2714.27587890625,\n",
       "  2714.310302734375,\n",
       "  2714.33642578125,\n",
       "  2714.37158203125,\n",
       "  2714.39501953125,\n",
       "  2714.416259765625,\n",
       "  2714.43603515625,\n",
       "  2714.45556640625,\n",
       "  2714.47265625,\n",
       "  2714.4931640625,\n",
       "  2714.509033203125,\n",
       "  2714.533203125,\n",
       "  2714.551025390625,\n",
       "  2714.56201171875,\n",
       "  2714.57177734375,\n",
       "  2714.58447265625,\n",
       "  2714.5966796875,\n",
       "  2714.609619140625,\n",
       "  2714.617431640625,\n",
       "  2714.6357421875,\n",
       "  2714.6474609375,\n",
       "  2714.65869140625,\n",
       "  2714.6669921875,\n",
       "  2714.676025390625,\n",
       "  2714.68310546875,\n",
       "  2714.692138671875,\n",
       "  2714.70068359375,\n",
       "  2714.7080078125,\n",
       "  2714.715087890625,\n",
       "  2714.722412109375,\n",
       "  2714.73046875,\n",
       "  2714.73779296875,\n",
       "  2714.744384765625,\n",
       "  2714.75341796875,\n",
       "  2714.7607421875,\n",
       "  2714.7685546875,\n",
       "  2714.776123046875,\n",
       "  2714.785400390625,\n",
       "  2714.793212890625,\n",
       "  2714.801513671875,\n",
       "  2714.80908203125,\n",
       "  2714.8173828125,\n",
       "  2714.825439453125,\n",
       "  2714.831298828125,\n",
       "  2714.8388671875,\n",
       "  2714.84814453125,\n",
       "  2714.857177734375,\n",
       "  2714.866455078125,\n",
       "  2714.874755859375,\n",
       "  2714.88427734375,\n",
       "  2714.8916015625,\n",
       "  2714.89990234375,\n",
       "  2714.908203125,\n",
       "  2714.916259765625,\n",
       "  2714.923095703125,\n",
       "  2714.931396484375,\n",
       "  2714.940673828125],\n",
       " 'val_regularization_loss': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'val_total_loss': [1942.3702392578125,\n",
       "  1928.49755859375,\n",
       "  2032.374267578125,\n",
       "  2167.685302734375,\n",
       "  2246.8017578125,\n",
       "  2294.7529296875,\n",
       "  2329.121826171875,\n",
       "  2350.193359375,\n",
       "  2367.4130859375,\n",
       "  2393.541015625,\n",
       "  2415.421142578125,\n",
       "  2433.489013671875,\n",
       "  2438.296875,\n",
       "  2456.654052734375,\n",
       "  2465.72412109375,\n",
       "  2479.626708984375,\n",
       "  2496.458740234375,\n",
       "  2504.90234375,\n",
       "  2516.199951171875,\n",
       "  2529.60498046875,\n",
       "  2533.04052734375,\n",
       "  2543.293701171875,\n",
       "  2551.33056640625,\n",
       "  2561.157470703125,\n",
       "  2566.829345703125,\n",
       "  2575.076904296875,\n",
       "  2579.3974609375,\n",
       "  2587.737060546875,\n",
       "  2595.954345703125,\n",
       "  2601.29833984375,\n",
       "  2605.4091796875,\n",
       "  2611.174072265625,\n",
       "  2614.8232421875,\n",
       "  2620.310302734375,\n",
       "  2626.581787109375,\n",
       "  2632.2646484375,\n",
       "  2632.61328125,\n",
       "  2639.600341796875,\n",
       "  2645.23583984375,\n",
       "  2647.780517578125,\n",
       "  2650.694091796875,\n",
       "  2651.56103515625,\n",
       "  2654.155517578125,\n",
       "  2655.84033203125,\n",
       "  2658.68994140625,\n",
       "  2661.564208984375,\n",
       "  2663.593505859375,\n",
       "  2665.86181640625,\n",
       "  2667.630615234375,\n",
       "  2670.31689453125,\n",
       "  2671.939208984375,\n",
       "  2673.373046875,\n",
       "  2675.27978515625,\n",
       "  2677.61669921875,\n",
       "  2680.505126953125,\n",
       "  2681.38134765625,\n",
       "  2683.181396484375,\n",
       "  2684.25,\n",
       "  2685.2705078125,\n",
       "  2686.368896484375,\n",
       "  2688.20654296875,\n",
       "  2689.2314453125,\n",
       "  2690.24169921875,\n",
       "  2691.490966796875,\n",
       "  2692.84912109375,\n",
       "  2693.956298828125,\n",
       "  2694.598876953125,\n",
       "  2695.69140625,\n",
       "  2696.35595703125,\n",
       "  2696.971923828125,\n",
       "  2697.73486328125,\n",
       "  2698.934326171875,\n",
       "  2699.356689453125,\n",
       "  2699.743408203125,\n",
       "  2700.56298828125,\n",
       "  2701.10791015625,\n",
       "  2701.7841796875,\n",
       "  2702.21533203125,\n",
       "  2702.902099609375,\n",
       "  2703.4814453125,\n",
       "  2703.95458984375,\n",
       "  2704.634033203125,\n",
       "  2705.035888671875,\n",
       "  2705.615966796875,\n",
       "  2705.91162109375,\n",
       "  2706.273681640625,\n",
       "  2706.430419921875,\n",
       "  2706.787841796875,\n",
       "  2707.190185546875,\n",
       "  2707.4296875,\n",
       "  2707.819091796875,\n",
       "  2708.218994140625,\n",
       "  2708.54443359375,\n",
       "  2708.73681640625,\n",
       "  2709.058837890625,\n",
       "  2709.364501953125,\n",
       "  2709.580810546875,\n",
       "  2709.781005859375,\n",
       "  2710.00048828125,\n",
       "  2710.21435546875,\n",
       "  2710.50341796875,\n",
       "  2710.758544921875,\n",
       "  2710.914794921875,\n",
       "  2711.05517578125,\n",
       "  2711.1845703125,\n",
       "  2711.2822265625,\n",
       "  2711.375,\n",
       "  2711.5341796875,\n",
       "  2711.743408203125,\n",
       "  2711.901611328125,\n",
       "  2712.10205078125,\n",
       "  2712.20654296875,\n",
       "  2712.283203125,\n",
       "  2712.3974609375,\n",
       "  2712.485595703125,\n",
       "  2712.614990234375,\n",
       "  2712.712158203125,\n",
       "  2712.7802734375,\n",
       "  2712.90576171875,\n",
       "  2713.04541015625,\n",
       "  2713.102294921875,\n",
       "  2713.169189453125,\n",
       "  2713.245361328125,\n",
       "  2713.3134765625,\n",
       "  2713.3876953125,\n",
       "  2713.45947265625,\n",
       "  2713.531982421875,\n",
       "  2713.605712890625,\n",
       "  2713.65380859375,\n",
       "  2713.7080078125,\n",
       "  2713.7548828125,\n",
       "  2713.8076171875,\n",
       "  2713.865478515625,\n",
       "  2713.91357421875,\n",
       "  2713.962158203125,\n",
       "  2714.0,\n",
       "  2714.046630859375,\n",
       "  2714.10107421875,\n",
       "  2714.126220703125,\n",
       "  2714.156982421875,\n",
       "  2714.1904296875,\n",
       "  2714.21923828125,\n",
       "  2714.244873046875,\n",
       "  2714.27587890625,\n",
       "  2714.310302734375,\n",
       "  2714.33642578125,\n",
       "  2714.37158203125,\n",
       "  2714.39501953125,\n",
       "  2714.416259765625,\n",
       "  2714.43603515625,\n",
       "  2714.45556640625,\n",
       "  2714.47265625,\n",
       "  2714.4931640625,\n",
       "  2714.509033203125,\n",
       "  2714.533203125,\n",
       "  2714.551025390625,\n",
       "  2714.56201171875,\n",
       "  2714.57177734375,\n",
       "  2714.58447265625,\n",
       "  2714.5966796875,\n",
       "  2714.609619140625,\n",
       "  2714.617431640625,\n",
       "  2714.6357421875,\n",
       "  2714.6474609375,\n",
       "  2714.65869140625,\n",
       "  2714.6669921875,\n",
       "  2714.676025390625,\n",
       "  2714.68310546875,\n",
       "  2714.692138671875,\n",
       "  2714.70068359375,\n",
       "  2714.7080078125,\n",
       "  2714.715087890625,\n",
       "  2714.722412109375,\n",
       "  2714.73046875,\n",
       "  2714.73779296875,\n",
       "  2714.744384765625,\n",
       "  2714.75341796875,\n",
       "  2714.7607421875,\n",
       "  2714.7685546875,\n",
       "  2714.776123046875,\n",
       "  2714.785400390625,\n",
       "  2714.793212890625,\n",
       "  2714.801513671875,\n",
       "  2714.80908203125,\n",
       "  2714.8173828125,\n",
       "  2714.825439453125,\n",
       "  2714.831298828125,\n",
       "  2714.8388671875,\n",
       "  2714.84814453125,\n",
       "  2714.857177734375,\n",
       "  2714.866455078125,\n",
       "  2714.874755859375,\n",
       "  2714.88427734375,\n",
       "  2714.8916015625,\n",
       "  2714.89990234375,\n",
       "  2714.908203125,\n",
       "  2714.916259765625,\n",
       "  2714.923095703125,\n",
       "  2714.931396484375,\n",
       "  2714.940673828125],\n",
       " 'lr': [0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = iter([key for key in data.history.keys() if key.startswith(\"factorized_top\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe020a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1,201,1)]\n",
    "for key in keys:\n",
    "    plt.plot(x, data.history[key], \"-b\", label=\"Train\")\n",
    "    plt.plot(x, data.history[\"val_\"+key], \"-r\", label=\"Test\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(key.split(\"/\")[1])\n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b85ca7cd17e46580c5781b40041ecb0327ffab993dd3a95c3861a9f1364646"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
