{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(str(datetime.now()))\n",
    "import numpy as np\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] =\"3\"\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = tf.test.is_gpu_available()\n",
    "gpu_available\n",
    "req_cols = ['ITEM_ID', 'USER_ID', 'CABIN_TYPE', 'USER_RESIDENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b86d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_df_updated = pd.read_csv(\"dataset/interaction_demo.csv\")\n",
    "test_df = pd.read_csv(\"dataset/interaction_test_demo.csv\")\n",
    "data_set_df_updated.loc[data_set_df_updated.USER_RESIDENCE.isnull(),\"USER_RESIDENCE\"] = 'None'\n",
    "test_df.loc[test_df.USER_RESIDENCE.isnull(),\"USER_RESIDENCE\"] = 'None'\n",
    "train_df = pd.concat([data_set_df_updated, test_df], ignore_index=True)\n",
    "train_df.sort_values(\"TIMESTAMP\", ascending= False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_item_count = train_df.groupby([\"ITEM_ID\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_item_count[\"probability\"]= train_df_item_count[\"counts\"] / train_df_item_count[\"counts\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff5752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(train_df_item_count[[\"ITEM_ID\",\"probability\"]], how='left', on='ITEM_ID',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf387015",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = train_df[[\"ITEM_ID\"]].drop_duplicates(\"ITEM_ID\")\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(item_df.to_dict(\"list\")).batch(32)\n",
    "item_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6083b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols = req_cols+[\"probability\",\"EVENT_VALUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =  tf.data.Dataset.from_tensor_slices(train_df[req_cols].to_dict(\"list\")).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b21ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"USER_ID\"]))))\n",
    "\n",
    "CABIN_TYPE_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"CABIN_TYPE\"]))))\n",
    "\n",
    "USER_RESIDENCE_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"USER_RESIDENCE\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb359ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_unique =  np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"ITEM_ID\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rankL(np_rank):\n",
    "#     r = int(np_rank[-1])\n",
    "#     _l = 0\n",
    "#     for k in range(1, r+1):\n",
    "#         _l += 1./k\n",
    "#     return np.float32(_l)\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# labels are assumed to be 1 hot encoded\n",
    "# \"\"\"\n",
    "# def warp_loss(labels, logits):\n",
    "#     # for easy broadcasting\n",
    "#     labels, logits = tf.transpose(labels, [1, 0]), tf.transpose(logits, [1, 0])\n",
    "#     f_y = tf.reduce_sum(logits*labels, axis=0)\n",
    "#     rank = tf.reduce_sum(tf.maximum(tf.sign(1+logits-f_y), 0), axis=0)\n",
    "#     diff = tf.reduce_sum(tf.maximum(1+logits-f_y, 0), axis=0)\n",
    "#     with tf.control_dependencies([tf.assert_greater(rank, tf.zeros_like(rank))]):\n",
    "#         return tf.py_func(rankL, [rank], tf.float32) * diff/rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        emb_dim = 8    \n",
    "        self.user_id_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=USER_ID_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(USER_ID_unique) + 1, 16),\n",
    "        ])\n",
    "            \n",
    "        self.cabin_type_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary= CABIN_TYPE_unique, mask_token=None),  \n",
    "            tf.keras.layers.Embedding(len(CABIN_TYPE_unique) + 1, emb_dim),\n",
    "        ])\n",
    "\n",
    "        self.user_residence_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=USER_RESIDENCE_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(USER_RESIDENCE_unique) + 1, emb_dim),\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def call(self, user_interation_data):\n",
    "        return tf.concat([                          \n",
    "            self.user_id_embedding(user_interation_data[\"USER_ID\"]), \n",
    "            self.cabin_type_embedding(user_interation_data[\"CABIN_TYPE\"]), \n",
    "            self.user_residence_embedding(user_interation_data[\"USER_RESIDENCE\"]),\n",
    "        ], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915250ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=item_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(item_unique) + 1, 32),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, user_interation_data):\n",
    "\n",
    "        return tf.concat([\n",
    "            self.item_embedding(user_interation_data[\"ITEM_ID\"])\n",
    "            \n",
    "            ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5793fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRFSRetrievalModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, UserModel,ItemModel, item_ds ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.query_model = tf.keras.Sequential([#,UserModel()\n",
    "          UserModel(),\n",
    "#           tf.keras.layers.Dense(32 , kernel_initializer= tf.keras.initializers.RandomNormal(seed=99)),  \n",
    "#           tf.keras.layers.Dropout(0.2),\n",
    "        ])\n",
    "        \n",
    "\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "          ItemModel(),\n",
    "#           tf.keras.layers.Dense(32, kernel_initializer= tf.keras.initializers.RandomNormal(seed=1)),\n",
    "#           tf.keras.layers.Dropout(0.2),\n",
    "        ]) \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         metrics = [\n",
    "#           tf.keras.metrics.TopKCategoricalAccuracy(\n",
    "#               k=x, name=f\"factorized_top_k/top_{x}_categorical_accuracy\")\n",
    "#           for x in [3,5,10,15, 25]\n",
    "#         ]  \n",
    "        \n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "#             loss=warp_loss,\n",
    "#             num_hard_negatives=100,\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "            item_ds.map(self.candidate_model),\n",
    "                ks= (3, 5, 10,15, 25)),\n",
    "                          \n",
    "\n",
    "        )\n",
    "        \n",
    "#         self.task = tfrs.tasks.Retrieval(\n",
    "#             metrics=tfrs.metrics.FactorizedTopK(\n",
    "#                 candidates=item_ds.map(self.candidate_model),\n",
    "#                 metrics = metrics,\n",
    "#                 k = 100\n",
    "#             ),\n",
    "#             # temperature = 0.5,\n",
    "#             num_hard_negatives = 5\n",
    "#         )\n",
    "\n",
    "    def compute_loss(self, features, training= True):\n",
    "\n",
    "        item_features = {\"ITEM_ID\":features.pop(\"ITEM_ID\") }\n",
    "        candidate_sampling_probability = features.pop(\"probability\")\n",
    "        sample_weight= features.pop(\"EVENT_VALUE\")\n",
    "        query_embeddings = self.query_model(features)\n",
    "        item_embeddings = self.candidate_model(item_features)\n",
    "        return self.task(query_embeddings, \n",
    "        item_embeddings, \n",
    "        compute_metrics=True,\n",
    "#         sample_weight= sample_weight,\n",
    "        candidate_sampling_probability = candidate_sampling_probability\n",
    "        )\n",
    "\n",
    "    def call(self, test):\n",
    "        features= test.copy()\n",
    "        __ = features.pop(\"probability\")\n",
    "        item_features = {\"ITEM_ID\":features.pop(\"ITEM_ID\") }\n",
    "        query_embeddings = self.query_model(features)\n",
    "        item_embeddings = self.candidate_model(item_features)\n",
    "\n",
    "        return query_embeddings, item_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max_index = math.floor(train_df.shape[0]*0.1)\n",
    "train_split_len = train_df.shape[0] - test_max_index\n",
    "data_set_tf = tf.data.Dataset.from_tensor_slices(train_df[req_cols].to_dict(\"list\"))\n",
    "test = data_set_tf.take(test_max_index)\n",
    "train = data_set_tf.skip(test_max_index).take(train_split_len)\n",
    "shuffled = train.shuffle(train_split_len, seed=42, reshuffle_each_iteration=True)\n",
    "cached_train = shuffled.batch(512).prefetch(4096)#train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(512).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fcf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape[0], test_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aff5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_check_points(fpath= 'new_amazon_check_points/*'):\n",
    "    files = glob.glob(fpath)\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2625b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_call_back_fun(K):\n",
    "    delete_all_check_points()\n",
    "    model_path = f\"new_amazon_check_points/best_check_point_{K}k\"\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_weights_only=True,\n",
    "        monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    early_stoping = tf.keras.callbacks.EarlyStopping(monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy',\n",
    "                                                     mode='min',\n",
    "                                                     patience=5)\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy', \n",
    "                                                     factor=0.6,\n",
    "                                                     #mode='min',\n",
    "                                                     patience=9, \n",
    "                                                     min_lr=1e-6\n",
    "    )\n",
    "    return model_path, model_checkpoint_callback, early_stoping, reduce_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path, model_checkpoint_callback, early_stoping, reduce_lr = get_call_back_fun(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TRFSRetrievalModel(UserModel, ItemModel, item_ds)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.fit(cached_train,\n",
    "          validation_data=cached_test,\n",
    "          epochs=1,\n",
    "          verbose=1, \n",
    "          workers=3,\n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[model_checkpoint_callback, \n",
    "                     reduce_lr]\n",
    "\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26726357",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"new_amazon_check_points/best_check_point_25k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"model/candidate\"\n",
    "tf.saved_model.save(model.candidate_model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7094143",
   "metadata": {},
   "outputs": [],
   "source": [
    "qpath = \"model/query\"\n",
    "tf.saved_model.save(model.query_model, qpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.saved_model.load(qpath)\n",
    "candidate_model = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682abcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_test_ds = tf.data.Dataset.from_tensor_slices(item_df.to_dict(\"list\")).batch(5000)\n",
    "for item_name in item_test_ds:\n",
    "    item_names = item_name[\"ITEM_ID\"].numpy()\n",
    "for user in cached_test:\n",
    "    all_features = list(user.keys()) \n",
    "    __ = [user.pop(j) for j in all_features if j not in ['USER_ID', 'CABIN_TYPE', 'USER_RESIDENCE']]\n",
    "    print(\"User keys\",user.keys())\n",
    "    user_vector = user_model(user)\n",
    "    item_vector = item_test_ds.map(candidate_model)\n",
    "    for i in item_vector:\n",
    "        score = tf.matmul(user_vector[0:1], i, transpose_b=True)\n",
    "        break\n",
    "    sorted_index = tf.argsort(score,axis=-1,direction='DESCENDING',stable=False)\n",
    "    print(\"sorted_list\",tf.gather(item_names, sorted_index[0,0:5]), sorted_index.shape )\n",
    "    print(\"shape of score\",tf.gather(tf.reshape(score,(-1)), sorted_index[0,0:5]) )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64981733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model, k=10)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip( (item_test_ds.map(lambda x: x[\"ITEM_ID\"]), item_test_ds.map(model.candidate_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dc142",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test.batch(1):\n",
    "    print(i)\n",
    "    print(index(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d04cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_summary = model.evaluate(cached_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "{val:result_summary[idx] for idx, val in enumerate([3, 5, 10,15, 25]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = iter([key for key in data.history.keys() if key.startswith(\"factorized_top\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe020a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1,201,1)]\n",
    "for key in keys:\n",
    "    plt.plot(x, data.history[key], \"-b\", label=\"Train\")\n",
    "    plt.plot(x, data.history[\"val_\"+key], \"-r\", label=\"Test\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(key.split(\"/\")[1])\n",
    "    break\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b85ca7cd17e46580c5781b40041ecb0327ffab993dd3a95c3861a9f1364646"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
