{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4205e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-03 08:17:04.661608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 08:17:04.884640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-03 08:17:04.884667: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(str(datetime.now()))\n",
    "import numpy as np\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] =\"3\"\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcc3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bebfdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20015/1916213802.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 08:17:07.012672: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-03 08:17:07.012695: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-03 08:17:07.012714: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bioss-System-Product-Name): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "gpu_available = tf.test.is_gpu_available()\n",
    "gpu_available\n",
    "req_cols = ['ITEM_ID', 'USER_ID', 'CABIN_TYPE', 'USER_RESIDENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b86d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_df_updated = pd.read_csv(\"dataset/interaction_demo.csv\")\n",
    "test_df = pd.read_csv(\"dataset/interaction_test_demo.csv\")\n",
    "data_set_df_updated.loc[data_set_df_updated.USER_RESIDENCE.isnull(),\"USER_RESIDENCE\"] = 'None'\n",
    "test_df.loc[test_df.USER_RESIDENCE.isnull(),\"USER_RESIDENCE\"] = 'None'\n",
    "train_df = pd.concat([data_set_df_updated, test_df], ignore_index=True)\n",
    "train_df.sort_values(\"TIMESTAMP\", ascending= False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd24e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_item_count = train_df.groupby([\"ITEM_ID\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_item_count[\"probability\"]= train_df_item_count[\"counts\"] / train_df_item_count[\"counts\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff5752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(train_df_item_count[[\"ITEM_ID\",\"probability\"]], how='left', on='ITEM_ID',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa2bf873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>CABIN_TYPE</th>\n",
       "      <th>EVENT_VALUE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>USER_RESIDENCE</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emirates</td>\n",
       "      <td>BFinn</td>\n",
       "      <td>1438473600</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5</td>\n",
       "      <td>RATING</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.019797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>china-southern-airlines</td>\n",
       "      <td>BrentEvans</td>\n",
       "      <td>1438473600</td>\n",
       "      <td>First Class</td>\n",
       "      <td>10</td>\n",
       "      <td>RATING</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0.011477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garuda-indonesia</td>\n",
       "      <td>MichaelBrien</td>\n",
       "      <td>1438473600</td>\n",
       "      <td>Economy</td>\n",
       "      <td>9</td>\n",
       "      <td>RATING</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.010071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ukraine-international-airlines</td>\n",
       "      <td>SamNaguib</td>\n",
       "      <td>1438473600</td>\n",
       "      <td>Economy</td>\n",
       "      <td>1</td>\n",
       "      <td>RATING</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.002295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spirit-airlines</td>\n",
       "      <td>LRichardson</td>\n",
       "      <td>1438473600</td>\n",
       "      <td>Economy</td>\n",
       "      <td>8</td>\n",
       "      <td>RATING</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.008149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34848</th>\n",
       "      <td>blue-islands</td>\n",
       "      <td>MGroves</td>\n",
       "      <td>1211673600</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5</td>\n",
       "      <td>RATING</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34849</th>\n",
       "      <td>blue-islands</td>\n",
       "      <td>MPreston</td>\n",
       "      <td>1208822400</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5</td>\n",
       "      <td>RATING</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34850</th>\n",
       "      <td>blue-islands</td>\n",
       "      <td>PeterCullen</td>\n",
       "      <td>1199750400</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5</td>\n",
       "      <td>RATING</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34851</th>\n",
       "      <td>volaris</td>\n",
       "      <td>BHübbe</td>\n",
       "      <td>1194566400</td>\n",
       "      <td>Economy</td>\n",
       "      <td>9</td>\n",
       "      <td>RATING</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34852</th>\n",
       "      <td>british-airways</td>\n",
       "      <td>RussKing</td>\n",
       "      <td>0</td>\n",
       "      <td>First Class</td>\n",
       "      <td>4</td>\n",
       "      <td>RATING</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.025651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34853 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ITEM_ID       USER_ID   TIMESTAMP   CABIN_TYPE  \\\n",
       "0                            emirates         BFinn  1438473600      Economy   \n",
       "1             china-southern-airlines    BrentEvans  1438473600  First Class   \n",
       "2                    garuda-indonesia  MichaelBrien  1438473600      Economy   \n",
       "3      ukraine-international-airlines     SamNaguib  1438473600      Economy   \n",
       "4                     spirit-airlines   LRichardson  1438473600      Economy   \n",
       "...                               ...           ...         ...          ...   \n",
       "34848                    blue-islands       MGroves  1211673600      Economy   \n",
       "34849                    blue-islands      MPreston  1208822400      Economy   \n",
       "34850                    blue-islands   PeterCullen  1199750400      Economy   \n",
       "34851                         volaris        BHübbe  1194566400      Economy   \n",
       "34852                 british-airways      RussKing           0  First Class   \n",
       "\n",
       "       EVENT_VALUE EVENT_TYPE  USER_RESIDENCE  probability  \n",
       "0                5     RATING       Australia     0.019797  \n",
       "1               10     RATING     New Zealand     0.011477  \n",
       "2                9     RATING       Australia     0.010071  \n",
       "3                1     RATING   United States     0.002295  \n",
       "4                8     RATING   United States     0.008149  \n",
       "...            ...        ...             ...          ...  \n",
       "34848            5     RATING  United Kingdom     0.000861  \n",
       "34849            5     RATING  United Kingdom     0.000861  \n",
       "34850            5     RATING  United Kingdom     0.000861  \n",
       "34851            9     RATING          Mexico     0.000889  \n",
       "34852            4     RATING  United Kingdom     0.025651  \n",
       "\n",
       "[34853 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf387015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df = train_df[[\"ITEM_ID\"]].drop_duplicates(\"ITEM_ID\")\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(item_df.to_dict(\"list\")).batch(32)\n",
    "item_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6083b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols = req_cols+[\"probability\",\"EVENT_VALUE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b3e53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =  tf.data.Dataset.from_tensor_slices(train_df[req_cols].to_dict(\"list\")).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b21ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"USER_ID\"]))))\n",
    "\n",
    "CABIN_TYPE_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"CABIN_TYPE\"]))))\n",
    "\n",
    "USER_RESIDENCE_unique = np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"USER_RESIDENCE\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb359ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_unique =  np.unique(np.concatenate(list(train_ds.map(\n",
    "        lambda x: x[\"ITEM_ID\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7712418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rankL(np_rank):\n",
    "#     r = int(np_rank[-1])\n",
    "#     _l = 0\n",
    "#     for k in range(1, r+1):\n",
    "#         _l += 1./k\n",
    "#     return np.float32(_l)\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# labels are assumed to be 1 hot encoded\n",
    "# \"\"\"\n",
    "# def warp_loss(labels, logits):\n",
    "#     # for easy broadcasting\n",
    "#     labels, logits = tf.transpose(labels, [1, 0]), tf.transpose(logits, [1, 0])\n",
    "#     f_y = tf.reduce_sum(logits*labels, axis=0)\n",
    "#     rank = tf.reduce_sum(tf.maximum(tf.sign(1+logits-f_y), 0), axis=0)\n",
    "#     diff = tf.reduce_sum(tf.maximum(1+logits-f_y, 0), axis=0)\n",
    "#     with tf.control_dependencies([tf.assert_greater(rank, tf.zeros_like(rank))]):\n",
    "#         return tf.py_func(rankL, [rank], tf.float32) * diff/rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "876e1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        emb_dim = 8    \n",
    "        self.user_id_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=USER_ID_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(USER_ID_unique) + 1, 16),\n",
    "        ])\n",
    "            \n",
    "        self.cabin_type_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary= CABIN_TYPE_unique, mask_token=None),  \n",
    "            tf.keras.layers.Embedding(len(CABIN_TYPE_unique) + 1, emb_dim),\n",
    "        ])\n",
    "\n",
    "        self.user_residence_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=USER_RESIDENCE_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(USER_RESIDENCE_unique) + 1, emb_dim),\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def call(self, user_interation_data):\n",
    "        return tf.concat([                          \n",
    "            self.user_id_embedding(user_interation_data[\"USER_ID\"]), \n",
    "            self.cabin_type_embedding(user_interation_data[\"CABIN_TYPE\"]), \n",
    "            self.user_residence_embedding(user_interation_data[\"USER_RESIDENCE\"]),\n",
    "        ], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "915250ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=item_unique, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(item_unique) + 1, 32),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, user_interation_data):\n",
    "\n",
    "        return tf.concat([\n",
    "            self.item_embedding(user_interation_data[\"ITEM_ID\"])\n",
    "            \n",
    "            ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5793fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRFSRetrievalModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, UserModel,ItemModel, item_ds ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.query_model = tf.keras.Sequential([#,UserModel()\n",
    "          UserModel(),\n",
    "#           tf.keras.layers.Dense(32 , kernel_initializer= tf.keras.initializers.RandomNormal(seed=99)),  \n",
    "#           tf.keras.layers.Dropout(0.2),\n",
    "        ])\n",
    "        \n",
    "\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "          ItemModel(),\n",
    "#           tf.keras.layers.Dense(32, kernel_initializer= tf.keras.initializers.RandomNormal(seed=1)),\n",
    "#           tf.keras.layers.Dropout(0.2),\n",
    "        ]) \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         metrics = [\n",
    "#           tf.keras.metrics.TopKCategoricalAccuracy(\n",
    "#               k=x, name=f\"factorized_top_k/top_{x}_categorical_accuracy\")\n",
    "#           for x in [3,5,10,15, 25]\n",
    "#         ]  \n",
    "        \n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "#             loss=warp_loss,\n",
    "#             num_hard_negatives=100,\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "            item_ds.map(self.candidate_model),\n",
    "                ks= (3, 5, 10,15, 25)),\n",
    "                          \n",
    "\n",
    "        )\n",
    "        \n",
    "#         self.task = tfrs.tasks.Retrieval(\n",
    "#             metrics=tfrs.metrics.FactorizedTopK(\n",
    "#                 candidates=item_ds.map(self.candidate_model),\n",
    "#                 metrics = metrics,\n",
    "#                 k = 100\n",
    "#             ),\n",
    "#             # temperature = 0.5,\n",
    "#             num_hard_negatives = 5\n",
    "#         )\n",
    "\n",
    "    def compute_loss(self, features, training= True):\n",
    "\n",
    "        item_features = {\"ITEM_ID\":features.pop(\"ITEM_ID\") }\n",
    "        query_embeddings = self.query_model(features)\n",
    "        item_embeddings = self.candidate_model(item_features)\n",
    "        candidate_sampling_probability = features.pop(\"probability\")\n",
    "        sample_weight= features.pop(\"EVENT_VALUE\")\n",
    "        return self.task(query_embeddings, \n",
    "        item_embeddings, \n",
    "        compute_metrics=True,\n",
    "#         sample_weight= sample_weight,\n",
    "        candidate_sampling_probability = candidate_sampling_probability\n",
    "        )\n",
    "\n",
    "    def call(self, test):\n",
    "        features= test.copy()\n",
    "        item_features = {\"ITEM_ID\":features.pop(\"ITEM_ID\") }\n",
    "        query_embeddings = self.query_model(features)\n",
    "        item_embeddings = self.candidate_model(item_features)\n",
    "\n",
    "        return query_embeddings, item_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f5d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max_index = math.floor(train_df.shape[0]*0.1)\n",
    "train_split_len = train_df.shape[0] - test_max_index\n",
    "data_set_tf = tf.data.Dataset.from_tensor_slices(train_df[req_cols].to_dict(\"list\"))\n",
    "test = data_set_tf.take(test_max_index)\n",
    "train = data_set_tf.skip(test_max_index).take(train_split_len)\n",
    "shuffled = train.shuffle(train_split_len, seed=42, reshuffle_each_iteration=True)\n",
    "cached_train = shuffled.batch(512).prefetch(4096)#train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(512).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74fcf471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34853, 3485)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0], test_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92aff5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_check_points(fpath= 'new_amazon_check_points/*'):\n",
    "    files = glob.glob(fpath)\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a2625b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_call_back_fun(K):\n",
    "    delete_all_check_points()\n",
    "    model_path = f\"new_amazon_check_points/best_check_point_{K}k\"\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_weights_only=True,\n",
    "        monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    early_stoping = tf.keras.callbacks.EarlyStopping(monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy',\n",
    "                                                     mode='min',\n",
    "                                                     patience=5)\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=f'val_factorized_top_k/top_{K}_categorical_accuracy', \n",
    "                                                     factor=0.6,\n",
    "                                                     #mode='min',\n",
    "                                                     patience=9, \n",
    "                                                     min_lr=1e-6\n",
    "    )\n",
    "    return model_path, model_checkpoint_callback, early_stoping, reduce_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf39bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path, model_checkpoint_callback, early_stoping, reduce_lr = get_call_back_fun(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45c02e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "model = TRFSRetrievalModel(UserModel, ItemModel, item_ds)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f49834c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'USER_ID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'CABIN_TYPE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'USER_RESIDENCE': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'probability': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'EVENT_VALUE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'USER_ID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'CABIN_TYPE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'USER_RESIDENCE': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'probability': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'EVENT_VALUE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "61/62 [============================>.] - ETA: 0s - factorized_top_k/top_3_categorical_accuracy: 0.0824 - factorized_top_k/top_5_categorical_accuracy: 0.1362 - factorized_top_k/top_10_categorical_accuracy: 0.2147 - factorized_top_k/top_15_categorical_accuracy: 0.2740 - factorized_top_k/top_25_categorical_accuracy: 0.3746 - loss: 3598.3802 - regularization_loss: 0.0000e+00 - total_loss: 3598.3802WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'USER_ID': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'CABIN_TYPE': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'USER_RESIDENCE': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'probability': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'EVENT_VALUE': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'ITEM_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "62/62 [==============================] - 5s 51ms/step - factorized_top_k/top_3_categorical_accuracy: 0.0825 - factorized_top_k/top_5_categorical_accuracy: 0.1362 - factorized_top_k/top_10_categorical_accuracy: 0.2149 - factorized_top_k/top_15_categorical_accuracy: 0.2743 - factorized_top_k/top_25_categorical_accuracy: 0.3747 - loss: 3508.6767 - regularization_loss: 0.0000e+00 - total_loss: 3508.6767 - val_factorized_top_k/top_3_categorical_accuracy: 0.1802 - val_factorized_top_k/top_5_categorical_accuracy: 0.2614 - val_factorized_top_k/top_10_categorical_accuracy: 0.3865 - val_factorized_top_k/top_15_categorical_accuracy: 0.4580 - val_factorized_top_k/top_25_categorical_accuracy: 0.5455 - val_loss: 2643.5830 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2643.5830 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1012 - factorized_top_k/top_5_categorical_accuracy: 0.1650 - factorized_top_k/top_10_categorical_accuracy: 0.2656 - factorized_top_k/top_15_categorical_accuracy: 0.3332 - factorized_top_k/top_25_categorical_accuracy: 0.4453 - loss: 3365.4230 - regularization_loss: 0.0000e+00 - total_loss: 3365.4230 - val_factorized_top_k/top_3_categorical_accuracy: 0.1902 - val_factorized_top_k/top_5_categorical_accuracy: 0.2763 - val_factorized_top_k/top_10_categorical_accuracy: 0.3960 - val_factorized_top_k/top_15_categorical_accuracy: 0.4657 - val_factorized_top_k/top_25_categorical_accuracy: 0.5578 - val_loss: 2543.4395 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2543.4395 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1040 - factorized_top_k/top_5_categorical_accuracy: 0.1696 - factorized_top_k/top_10_categorical_accuracy: 0.2811 - factorized_top_k/top_15_categorical_accuracy: 0.3469 - factorized_top_k/top_25_categorical_accuracy: 0.4542 - loss: 3245.4376 - regularization_loss: 0.0000e+00 - total_loss: 3245.4376 - val_factorized_top_k/top_3_categorical_accuracy: 0.1902 - val_factorized_top_k/top_5_categorical_accuracy: 0.2832 - val_factorized_top_k/top_10_categorical_accuracy: 0.3994 - val_factorized_top_k/top_15_categorical_accuracy: 0.4703 - val_factorized_top_k/top_25_categorical_accuracy: 0.5659 - val_loss: 2479.1331 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2479.1331 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1054 - factorized_top_k/top_5_categorical_accuracy: 0.1731 - factorized_top_k/top_10_categorical_accuracy: 0.2862 - factorized_top_k/top_15_categorical_accuracy: 0.3516 - factorized_top_k/top_25_categorical_accuracy: 0.4581 - loss: 3163.0213 - regularization_loss: 0.0000e+00 - total_loss: 3163.0213 - val_factorized_top_k/top_3_categorical_accuracy: 0.1937 - val_factorized_top_k/top_5_categorical_accuracy: 0.2835 - val_factorized_top_k/top_10_categorical_accuracy: 0.4020 - val_factorized_top_k/top_15_categorical_accuracy: 0.4769 - val_factorized_top_k/top_25_categorical_accuracy: 0.6086 - val_loss: 2437.6538 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2437.6538 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1066 - factorized_top_k/top_5_categorical_accuracy: 0.1833 - factorized_top_k/top_10_categorical_accuracy: 0.2872 - factorized_top_k/top_15_categorical_accuracy: 0.3573 - factorized_top_k/top_25_categorical_accuracy: 0.4665 - loss: 3107.0845 - regularization_loss: 0.0000e+00 - total_loss: 3107.0845 - val_factorized_top_k/top_3_categorical_accuracy: 0.1983 - val_factorized_top_k/top_5_categorical_accuracy: 0.2769 - val_factorized_top_k/top_10_categorical_accuracy: 0.4017 - val_factorized_top_k/top_15_categorical_accuracy: 0.4829 - val_factorized_top_k/top_25_categorical_accuracy: 0.6232 - val_loss: 2408.8518 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2408.8518 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1093 - factorized_top_k/top_5_categorical_accuracy: 0.1894 - factorized_top_k/top_10_categorical_accuracy: 0.2898 - factorized_top_k/top_15_categorical_accuracy: 0.3642 - factorized_top_k/top_25_categorical_accuracy: 0.4795 - loss: 3065.9650 - regularization_loss: 0.0000e+00 - total_loss: 3065.9650 - val_factorized_top_k/top_3_categorical_accuracy: 0.1989 - val_factorized_top_k/top_5_categorical_accuracy: 0.2743 - val_factorized_top_k/top_10_categorical_accuracy: 0.4014 - val_factorized_top_k/top_15_categorical_accuracy: 0.5349 - val_factorized_top_k/top_25_categorical_accuracy: 0.6261 - val_loss: 2387.7456 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2387.7456 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1167 - factorized_top_k/top_5_categorical_accuracy: 0.1906 - factorized_top_k/top_10_categorical_accuracy: 0.2957 - factorized_top_k/top_15_categorical_accuracy: 0.3749 - factorized_top_k/top_25_categorical_accuracy: 0.4937 - loss: 3033.0555 - regularization_loss: 0.0000e+00 - total_loss: 3033.0555 - val_factorized_top_k/top_3_categorical_accuracy: 0.2123 - val_factorized_top_k/top_5_categorical_accuracy: 0.2898 - val_factorized_top_k/top_10_categorical_accuracy: 0.4416 - val_factorized_top_k/top_15_categorical_accuracy: 0.5383 - val_factorized_top_k/top_25_categorical_accuracy: 0.6350 - val_loss: 2371.4675 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2371.4675 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1262 - factorized_top_k/top_5_categorical_accuracy: 0.1972 - factorized_top_k/top_10_categorical_accuracy: 0.3048 - factorized_top_k/top_15_categorical_accuracy: 0.3880 - factorized_top_k/top_25_categorical_accuracy: 0.5147 - loss: 3004.6671 - regularization_loss: 0.0000e+00 - total_loss: 3004.6671 - val_factorized_top_k/top_3_categorical_accuracy: 0.2100 - val_factorized_top_k/top_5_categorical_accuracy: 0.2938 - val_factorized_top_k/top_10_categorical_accuracy: 0.4580 - val_factorized_top_k/top_15_categorical_accuracy: 0.5377 - val_factorized_top_k/top_25_categorical_accuracy: 0.6410 - val_loss: 2358.3516 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2358.3516 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1340 - factorized_top_k/top_5_categorical_accuracy: 0.2060 - factorized_top_k/top_10_categorical_accuracy: 0.3188 - factorized_top_k/top_15_categorical_accuracy: 0.4034 - factorized_top_k/top_25_categorical_accuracy: 0.5294 - loss: 2979.9728 - regularization_loss: 0.0000e+00 - total_loss: 2979.9728 - val_factorized_top_k/top_3_categorical_accuracy: 0.2135 - val_factorized_top_k/top_5_categorical_accuracy: 0.2964 - val_factorized_top_k/top_10_categorical_accuracy: 0.4646 - val_factorized_top_k/top_15_categorical_accuracy: 0.5415 - val_factorized_top_k/top_25_categorical_accuracy: 0.6451 - val_loss: 2347.3054 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2347.3054 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1408 - factorized_top_k/top_5_categorical_accuracy: 0.2177 - factorized_top_k/top_10_categorical_accuracy: 0.3370 - factorized_top_k/top_15_categorical_accuracy: 0.4193 - factorized_top_k/top_25_categorical_accuracy: 0.5429 - loss: 2956.2047 - regularization_loss: 0.0000e+00 - total_loss: 2956.2047 - val_factorized_top_k/top_3_categorical_accuracy: 0.2118 - val_factorized_top_k/top_5_categorical_accuracy: 0.2978 - val_factorized_top_k/top_10_categorical_accuracy: 0.4740 - val_factorized_top_k/top_15_categorical_accuracy: 0.5463 - val_factorized_top_k/top_25_categorical_accuracy: 0.6488 - val_loss: 2337.6348 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2337.6348 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1502 - factorized_top_k/top_5_categorical_accuracy: 0.2293 - factorized_top_k/top_10_categorical_accuracy: 0.3539 - factorized_top_k/top_15_categorical_accuracy: 0.4381 - factorized_top_k/top_25_categorical_accuracy: 0.5578 - loss: 2932.7299 - regularization_loss: 0.0000e+00 - total_loss: 2932.7299 - val_factorized_top_k/top_3_categorical_accuracy: 0.2155 - val_factorized_top_k/top_5_categorical_accuracy: 0.3059 - val_factorized_top_k/top_10_categorical_accuracy: 0.4783 - val_factorized_top_k/top_15_categorical_accuracy: 0.5458 - val_factorized_top_k/top_25_categorical_accuracy: 0.6537 - val_loss: 2328.9282 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2328.9282 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1588 - factorized_top_k/top_5_categorical_accuracy: 0.2407 - factorized_top_k/top_10_categorical_accuracy: 0.3710 - factorized_top_k/top_15_categorical_accuracy: 0.4585 - factorized_top_k/top_25_categorical_accuracy: 0.5736 - loss: 2909.8169 - regularization_loss: 0.0000e+00 - total_loss: 2909.8169 - val_factorized_top_k/top_3_categorical_accuracy: 0.2181 - val_factorized_top_k/top_5_categorical_accuracy: 0.3056 - val_factorized_top_k/top_10_categorical_accuracy: 0.4775 - val_factorized_top_k/top_15_categorical_accuracy: 0.5472 - val_factorized_top_k/top_25_categorical_accuracy: 0.6554 - val_loss: 2320.8987 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2320.8987 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1693 - factorized_top_k/top_5_categorical_accuracy: 0.2569 - factorized_top_k/top_10_categorical_accuracy: 0.3914 - factorized_top_k/top_15_categorical_accuracy: 0.4780 - factorized_top_k/top_25_categorical_accuracy: 0.5853 - loss: 2886.9529 - regularization_loss: 0.0000e+00 - total_loss: 2886.9529 - val_factorized_top_k/top_3_categorical_accuracy: 0.2224 - val_factorized_top_k/top_5_categorical_accuracy: 0.3001 - val_factorized_top_k/top_10_categorical_accuracy: 0.4841 - val_factorized_top_k/top_15_categorical_accuracy: 0.5472 - val_factorized_top_k/top_25_categorical_accuracy: 0.6614 - val_loss: 2313.4307 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2313.4307 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1819 - factorized_top_k/top_5_categorical_accuracy: 0.2734 - factorized_top_k/top_10_categorical_accuracy: 0.4125 - factorized_top_k/top_15_categorical_accuracy: 0.4942 - factorized_top_k/top_25_categorical_accuracy: 0.5982 - loss: 2864.0214 - regularization_loss: 0.0000e+00 - total_loss: 2864.0214 - val_factorized_top_k/top_3_categorical_accuracy: 0.2227 - val_factorized_top_k/top_5_categorical_accuracy: 0.3053 - val_factorized_top_k/top_10_categorical_accuracy: 0.4864 - val_factorized_top_k/top_15_categorical_accuracy: 0.5512 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2306.4229 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2306.4229 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.1986 - factorized_top_k/top_5_categorical_accuracy: 0.2928 - factorized_top_k/top_10_categorical_accuracy: 0.4284 - factorized_top_k/top_15_categorical_accuracy: 0.5073 - factorized_top_k/top_25_categorical_accuracy: 0.6132 - loss: 2840.7022 - regularization_loss: 0.0000e+00 - total_loss: 2840.7022 - val_factorized_top_k/top_3_categorical_accuracy: 0.2224 - val_factorized_top_k/top_5_categorical_accuracy: 0.3050 - val_factorized_top_k/top_10_categorical_accuracy: 0.4855 - val_factorized_top_k/top_15_categorical_accuracy: 0.5558 - val_factorized_top_k/top_25_categorical_accuracy: 0.6651 - val_loss: 2299.8091 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2299.8091 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.2156 - factorized_top_k/top_5_categorical_accuracy: 0.3125 - factorized_top_k/top_10_categorical_accuracy: 0.4433 - factorized_top_k/top_15_categorical_accuracy: 0.5199 - factorized_top_k/top_25_categorical_accuracy: 0.6295 - loss: 2817.3697 - regularization_loss: 0.0000e+00 - total_loss: 2817.3697 - val_factorized_top_k/top_3_categorical_accuracy: 0.2253 - val_factorized_top_k/top_5_categorical_accuracy: 0.3116 - val_factorized_top_k/top_10_categorical_accuracy: 0.4878 - val_factorized_top_k/top_15_categorical_accuracy: 0.5564 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2293.6199 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2293.6199 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.2317 - factorized_top_k/top_5_categorical_accuracy: 0.3318 - factorized_top_k/top_10_categorical_accuracy: 0.4576 - factorized_top_k/top_15_categorical_accuracy: 0.5331 - factorized_top_k/top_25_categorical_accuracy: 0.6434 - loss: 2794.0511 - regularization_loss: 0.0000e+00 - total_loss: 2794.0511 - val_factorized_top_k/top_3_categorical_accuracy: 0.2264 - val_factorized_top_k/top_5_categorical_accuracy: 0.3088 - val_factorized_top_k/top_10_categorical_accuracy: 0.4881 - val_factorized_top_k/top_15_categorical_accuracy: 0.5575 - val_factorized_top_k/top_25_categorical_accuracy: 0.6654 - val_loss: 2287.7554 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2287.7554 - lr: 0.0100\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.2493 - factorized_top_k/top_5_categorical_accuracy: 0.3481 - factorized_top_k/top_10_categorical_accuracy: 0.4728 - factorized_top_k/top_15_categorical_accuracy: 0.5458 - factorized_top_k/top_25_categorical_accuracy: 0.6571 - loss: 2769.8319 - regularization_loss: 0.0000e+00 - total_loss: 2769.8319 - val_factorized_top_k/top_3_categorical_accuracy: 0.2267 - val_factorized_top_k/top_5_categorical_accuracy: 0.3145 - val_factorized_top_k/top_10_categorical_accuracy: 0.4881 - val_factorized_top_k/top_15_categorical_accuracy: 0.5598 - val_factorized_top_k/top_25_categorical_accuracy: 0.6663 - val_loss: 2282.2124 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2282.2124 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 4s 70ms/step - factorized_top_k/top_3_categorical_accuracy: 0.2692 - factorized_top_k/top_5_categorical_accuracy: 0.3645 - factorized_top_k/top_10_categorical_accuracy: 0.4865 - factorized_top_k/top_15_categorical_accuracy: 0.5595 - factorized_top_k/top_25_categorical_accuracy: 0.6673 - loss: 2746.0023 - regularization_loss: 0.0000e+00 - total_loss: 2746.0023 - val_factorized_top_k/top_3_categorical_accuracy: 0.2321 - val_factorized_top_k/top_5_categorical_accuracy: 0.3148 - val_factorized_top_k/top_10_categorical_accuracy: 0.4892 - val_factorized_top_k/top_15_categorical_accuracy: 0.5621 - val_factorized_top_k/top_25_categorical_accuracy: 0.6660 - val_loss: 2276.9978 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2276.9978 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 4s 61ms/step - factorized_top_k/top_3_categorical_accuracy: 0.2867 - factorized_top_k/top_5_categorical_accuracy: 0.3788 - factorized_top_k/top_10_categorical_accuracy: 0.4996 - factorized_top_k/top_15_categorical_accuracy: 0.5738 - factorized_top_k/top_25_categorical_accuracy: 0.6779 - loss: 2722.1820 - regularization_loss: 0.0000e+00 - total_loss: 2722.1820 - val_factorized_top_k/top_3_categorical_accuracy: 0.2327 - val_factorized_top_k/top_5_categorical_accuracy: 0.3159 - val_factorized_top_k/top_10_categorical_accuracy: 0.4872 - val_factorized_top_k/top_15_categorical_accuracy: 0.5610 - val_factorized_top_k/top_25_categorical_accuracy: 0.6680 - val_loss: 2272.0444 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2272.0444 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.3072 - factorized_top_k/top_5_categorical_accuracy: 0.3936 - factorized_top_k/top_10_categorical_accuracy: 0.5120 - factorized_top_k/top_15_categorical_accuracy: 0.5858 - factorized_top_k/top_25_categorical_accuracy: 0.6899 - loss: 2697.6779 - regularization_loss: 0.0000e+00 - total_loss: 2697.6779 - val_factorized_top_k/top_3_categorical_accuracy: 0.2344 - val_factorized_top_k/top_5_categorical_accuracy: 0.3214 - val_factorized_top_k/top_10_categorical_accuracy: 0.4881 - val_factorized_top_k/top_15_categorical_accuracy: 0.5613 - val_factorized_top_k/top_25_categorical_accuracy: 0.6677 - val_loss: 2267.3660 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2267.3660 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 3s 51ms/step - factorized_top_k/top_3_categorical_accuracy: 0.3230 - factorized_top_k/top_5_categorical_accuracy: 0.4058 - factorized_top_k/top_10_categorical_accuracy: 0.5247 - factorized_top_k/top_15_categorical_accuracy: 0.5991 - factorized_top_k/top_25_categorical_accuracy: 0.7020 - loss: 2673.7723 - regularization_loss: 0.0000e+00 - total_loss: 2673.7723 - val_factorized_top_k/top_3_categorical_accuracy: 0.2301 - val_factorized_top_k/top_5_categorical_accuracy: 0.3211 - val_factorized_top_k/top_10_categorical_accuracy: 0.4867 - val_factorized_top_k/top_15_categorical_accuracy: 0.5610 - val_factorized_top_k/top_25_categorical_accuracy: 0.6703 - val_loss: 2262.9541 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2262.9541 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 3s 53ms/step - factorized_top_k/top_3_categorical_accuracy: 0.3393 - factorized_top_k/top_5_categorical_accuracy: 0.4202 - factorized_top_k/top_10_categorical_accuracy: 0.5368 - factorized_top_k/top_15_categorical_accuracy: 0.6126 - factorized_top_k/top_25_categorical_accuracy: 0.7121 - loss: 2649.5597 - regularization_loss: 0.0000e+00 - total_loss: 2649.5597 - val_factorized_top_k/top_3_categorical_accuracy: 0.2316 - val_factorized_top_k/top_5_categorical_accuracy: 0.3237 - val_factorized_top_k/top_10_categorical_accuracy: 0.4864 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6694 - val_loss: 2258.8328 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2258.8328 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 3s 49ms/step - factorized_top_k/top_3_categorical_accuracy: 0.3542 - factorized_top_k/top_5_categorical_accuracy: 0.4331 - factorized_top_k/top_10_categorical_accuracy: 0.5500 - factorized_top_k/top_15_categorical_accuracy: 0.6260 - factorized_top_k/top_25_categorical_accuracy: 0.7209 - loss: 2625.7326 - regularization_loss: 0.0000e+00 - total_loss: 2625.7326 - val_factorized_top_k/top_3_categorical_accuracy: 0.2341 - val_factorized_top_k/top_5_categorical_accuracy: 0.3300 - val_factorized_top_k/top_10_categorical_accuracy: 0.4855 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6680 - val_loss: 2254.9126 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2254.9126 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.3660 - factorized_top_k/top_5_categorical_accuracy: 0.4480 - factorized_top_k/top_10_categorical_accuracy: 0.5619 - factorized_top_k/top_15_categorical_accuracy: 0.6378 - factorized_top_k/top_25_categorical_accuracy: 0.7300 - loss: 2601.7090 - regularization_loss: 0.0000e+00 - total_loss: 2601.7090 - val_factorized_top_k/top_3_categorical_accuracy: 0.2379 - val_factorized_top_k/top_5_categorical_accuracy: 0.3331 - val_factorized_top_k/top_10_categorical_accuracy: 0.4884 - val_factorized_top_k/top_15_categorical_accuracy: 0.5656 - val_factorized_top_k/top_25_categorical_accuracy: 0.6683 - val_loss: 2251.2319 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2251.2319 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 5s 73ms/step - factorized_top_k/top_3_categorical_accuracy: 0.3786 - factorized_top_k/top_5_categorical_accuracy: 0.4613 - factorized_top_k/top_10_categorical_accuracy: 0.5747 - factorized_top_k/top_15_categorical_accuracy: 0.6491 - factorized_top_k/top_25_categorical_accuracy: 0.7390 - loss: 2578.1538 - regularization_loss: 0.0000e+00 - total_loss: 2578.1538 - val_factorized_top_k/top_3_categorical_accuracy: 0.2407 - val_factorized_top_k/top_5_categorical_accuracy: 0.3349 - val_factorized_top_k/top_10_categorical_accuracy: 0.4872 - val_factorized_top_k/top_15_categorical_accuracy: 0.5681 - val_factorized_top_k/top_25_categorical_accuracy: 0.6671 - val_loss: 2247.7617 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2247.7617 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 4s 55ms/step - factorized_top_k/top_3_categorical_accuracy: 0.3910 - factorized_top_k/top_5_categorical_accuracy: 0.4755 - factorized_top_k/top_10_categorical_accuracy: 0.5889 - factorized_top_k/top_15_categorical_accuracy: 0.6596 - factorized_top_k/top_25_categorical_accuracy: 0.7480 - loss: 2554.4487 - regularization_loss: 0.0000e+00 - total_loss: 2554.4487 - val_factorized_top_k/top_3_categorical_accuracy: 0.2370 - val_factorized_top_k/top_5_categorical_accuracy: 0.3406 - val_factorized_top_k/top_10_categorical_accuracy: 0.4869 - val_factorized_top_k/top_15_categorical_accuracy: 0.5696 - val_factorized_top_k/top_25_categorical_accuracy: 0.6666 - val_loss: 2244.5083 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2244.5083 - lr: 0.0100\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4015 - factorized_top_k/top_5_categorical_accuracy: 0.4872 - factorized_top_k/top_10_categorical_accuracy: 0.6002 - factorized_top_k/top_15_categorical_accuracy: 0.6702 - factorized_top_k/top_25_categorical_accuracy: 0.7554 - loss: 2531.1291 - regularization_loss: 0.0000e+00 - total_loss: 2531.1291 - val_factorized_top_k/top_3_categorical_accuracy: 0.2416 - val_factorized_top_k/top_5_categorical_accuracy: 0.3392 - val_factorized_top_k/top_10_categorical_accuracy: 0.4852 - val_factorized_top_k/top_15_categorical_accuracy: 0.5676 - val_factorized_top_k/top_25_categorical_accuracy: 0.6674 - val_loss: 2241.4944 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2241.4944 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4151 - factorized_top_k/top_5_categorical_accuracy: 0.4974 - factorized_top_k/top_10_categorical_accuracy: 0.6109 - factorized_top_k/top_15_categorical_accuracy: 0.6801 - factorized_top_k/top_25_categorical_accuracy: 0.7630 - loss: 2508.3263 - regularization_loss: 0.0000e+00 - total_loss: 2508.3263 - val_factorized_top_k/top_3_categorical_accuracy: 0.2393 - val_factorized_top_k/top_5_categorical_accuracy: 0.3377 - val_factorized_top_k/top_10_categorical_accuracy: 0.4875 - val_factorized_top_k/top_15_categorical_accuracy: 0.5690 - val_factorized_top_k/top_25_categorical_accuracy: 0.6686 - val_loss: 2238.6624 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2238.6624 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4265 - factorized_top_k/top_5_categorical_accuracy: 0.5088 - factorized_top_k/top_10_categorical_accuracy: 0.6231 - factorized_top_k/top_15_categorical_accuracy: 0.6890 - factorized_top_k/top_25_categorical_accuracy: 0.7704 - loss: 2485.0124 - regularization_loss: 0.0000e+00 - total_loss: 2485.0124 - val_factorized_top_k/top_3_categorical_accuracy: 0.2387 - val_factorized_top_k/top_5_categorical_accuracy: 0.3389 - val_factorized_top_k/top_10_categorical_accuracy: 0.4864 - val_factorized_top_k/top_15_categorical_accuracy: 0.5690 - val_factorized_top_k/top_25_categorical_accuracy: 0.6677 - val_loss: 2236.0322 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2236.0322 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4374 - factorized_top_k/top_5_categorical_accuracy: 0.5197 - factorized_top_k/top_10_categorical_accuracy: 0.6343 - factorized_top_k/top_15_categorical_accuracy: 0.6990 - factorized_top_k/top_25_categorical_accuracy: 0.7775 - loss: 2462.2891 - regularization_loss: 0.0000e+00 - total_loss: 2462.2891 - val_factorized_top_k/top_3_categorical_accuracy: 0.2393 - val_factorized_top_k/top_5_categorical_accuracy: 0.3452 - val_factorized_top_k/top_10_categorical_accuracy: 0.4867 - val_factorized_top_k/top_15_categorical_accuracy: 0.5693 - val_factorized_top_k/top_25_categorical_accuracy: 0.6706 - val_loss: 2233.5696 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2233.5696 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4480 - factorized_top_k/top_5_categorical_accuracy: 0.5316 - factorized_top_k/top_10_categorical_accuracy: 0.6440 - factorized_top_k/top_15_categorical_accuracy: 0.7066 - factorized_top_k/top_25_categorical_accuracy: 0.7838 - loss: 2439.7147 - regularization_loss: 0.0000e+00 - total_loss: 2439.7147 - val_factorized_top_k/top_3_categorical_accuracy: 0.2436 - val_factorized_top_k/top_5_categorical_accuracy: 0.3504 - val_factorized_top_k/top_10_categorical_accuracy: 0.4869 - val_factorized_top_k/top_15_categorical_accuracy: 0.5687 - val_factorized_top_k/top_25_categorical_accuracy: 0.6677 - val_loss: 2231.3181 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2231.3181 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4589 - factorized_top_k/top_5_categorical_accuracy: 0.5419 - factorized_top_k/top_10_categorical_accuracy: 0.6529 - factorized_top_k/top_15_categorical_accuracy: 0.7148 - factorized_top_k/top_25_categorical_accuracy: 0.7894 - loss: 2417.9931 - regularization_loss: 0.0000e+00 - total_loss: 2417.9931 - val_factorized_top_k/top_3_categorical_accuracy: 0.2425 - val_factorized_top_k/top_5_categorical_accuracy: 0.3484 - val_factorized_top_k/top_10_categorical_accuracy: 0.4864 - val_factorized_top_k/top_15_categorical_accuracy: 0.5681 - val_factorized_top_k/top_25_categorical_accuracy: 0.6689 - val_loss: 2229.2791 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2229.2791 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4695 - factorized_top_k/top_5_categorical_accuracy: 0.5530 - factorized_top_k/top_10_categorical_accuracy: 0.6608 - factorized_top_k/top_15_categorical_accuracy: 0.7228 - factorized_top_k/top_25_categorical_accuracy: 0.7949 - loss: 2395.7847 - regularization_loss: 0.0000e+00 - total_loss: 2395.7847 - val_factorized_top_k/top_3_categorical_accuracy: 0.2442 - val_factorized_top_k/top_5_categorical_accuracy: 0.3501 - val_factorized_top_k/top_10_categorical_accuracy: 0.4872 - val_factorized_top_k/top_15_categorical_accuracy: 0.5696 - val_factorized_top_k/top_25_categorical_accuracy: 0.6703 - val_loss: 2227.3660 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2227.3660 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4814 - factorized_top_k/top_5_categorical_accuracy: 0.5643 - factorized_top_k/top_10_categorical_accuracy: 0.6691 - factorized_top_k/top_15_categorical_accuracy: 0.7313 - factorized_top_k/top_25_categorical_accuracy: 0.8012 - loss: 2374.1672 - regularization_loss: 0.0000e+00 - total_loss: 2374.1672 - val_factorized_top_k/top_3_categorical_accuracy: 0.2445 - val_factorized_top_k/top_5_categorical_accuracy: 0.3509 - val_factorized_top_k/top_10_categorical_accuracy: 0.4881 - val_factorized_top_k/top_15_categorical_accuracy: 0.5704 - val_factorized_top_k/top_25_categorical_accuracy: 0.6709 - val_loss: 2225.6238 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2225.6238 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 3s 48ms/step - factorized_top_k/top_3_categorical_accuracy: 0.4920 - factorized_top_k/top_5_categorical_accuracy: 0.5744 - factorized_top_k/top_10_categorical_accuracy: 0.6766 - factorized_top_k/top_15_categorical_accuracy: 0.7384 - factorized_top_k/top_25_categorical_accuracy: 0.8068 - loss: 2352.9218 - regularization_loss: 0.0000e+00 - total_loss: 2352.9218 - val_factorized_top_k/top_3_categorical_accuracy: 0.2422 - val_factorized_top_k/top_5_categorical_accuracy: 0.3549 - val_factorized_top_k/top_10_categorical_accuracy: 0.4878 - val_factorized_top_k/top_15_categorical_accuracy: 0.5727 - val_factorized_top_k/top_25_categorical_accuracy: 0.6714 - val_loss: 2224.0430 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2224.0430 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5022 - factorized_top_k/top_5_categorical_accuracy: 0.5837 - factorized_top_k/top_10_categorical_accuracy: 0.6845 - factorized_top_k/top_15_categorical_accuracy: 0.7448 - factorized_top_k/top_25_categorical_accuracy: 0.8121 - loss: 2331.8064 - regularization_loss: 0.0000e+00 - total_loss: 2331.8064 - val_factorized_top_k/top_3_categorical_accuracy: 0.2485 - val_factorized_top_k/top_5_categorical_accuracy: 0.3492 - val_factorized_top_k/top_10_categorical_accuracy: 0.4875 - val_factorized_top_k/top_15_categorical_accuracy: 0.5707 - val_factorized_top_k/top_25_categorical_accuracy: 0.6700 - val_loss: 2222.5557 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2222.5557 - lr: 0.0100\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 50ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5132 - factorized_top_k/top_5_categorical_accuracy: 0.5923 - factorized_top_k/top_10_categorical_accuracy: 0.6915 - factorized_top_k/top_15_categorical_accuracy: 0.7521 - factorized_top_k/top_25_categorical_accuracy: 0.8176 - loss: 2311.4851 - regularization_loss: 0.0000e+00 - total_loss: 2311.4851 - val_factorized_top_k/top_3_categorical_accuracy: 0.2462 - val_factorized_top_k/top_5_categorical_accuracy: 0.3529 - val_factorized_top_k/top_10_categorical_accuracy: 0.4884 - val_factorized_top_k/top_15_categorical_accuracy: 0.5699 - val_factorized_top_k/top_25_categorical_accuracy: 0.6709 - val_loss: 2221.2979 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2221.2979 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5230 - factorized_top_k/top_5_categorical_accuracy: 0.6003 - factorized_top_k/top_10_categorical_accuracy: 0.7002 - factorized_top_k/top_15_categorical_accuracy: 0.7588 - factorized_top_k/top_25_categorical_accuracy: 0.8224 - loss: 2291.2049 - regularization_loss: 0.0000e+00 - total_loss: 2291.2049 - val_factorized_top_k/top_3_categorical_accuracy: 0.2514 - val_factorized_top_k/top_5_categorical_accuracy: 0.3564 - val_factorized_top_k/top_10_categorical_accuracy: 0.4864 - val_factorized_top_k/top_15_categorical_accuracy: 0.5702 - val_factorized_top_k/top_25_categorical_accuracy: 0.6703 - val_loss: 2220.1670 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2220.1670 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5308 - factorized_top_k/top_5_categorical_accuracy: 0.6076 - factorized_top_k/top_10_categorical_accuracy: 0.7080 - factorized_top_k/top_15_categorical_accuracy: 0.7646 - factorized_top_k/top_25_categorical_accuracy: 0.8264 - loss: 2270.9605 - regularization_loss: 0.0000e+00 - total_loss: 2270.9605 - val_factorized_top_k/top_3_categorical_accuracy: 0.2496 - val_factorized_top_k/top_5_categorical_accuracy: 0.3518 - val_factorized_top_k/top_10_categorical_accuracy: 0.4887 - val_factorized_top_k/top_15_categorical_accuracy: 0.5716 - val_factorized_top_k/top_25_categorical_accuracy: 0.6703 - val_loss: 2219.1687 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2219.1687 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5388 - factorized_top_k/top_5_categorical_accuracy: 0.6155 - factorized_top_k/top_10_categorical_accuracy: 0.7154 - factorized_top_k/top_15_categorical_accuracy: 0.7697 - factorized_top_k/top_25_categorical_accuracy: 0.8302 - loss: 2251.7883 - regularization_loss: 0.0000e+00 - total_loss: 2251.7883 - val_factorized_top_k/top_3_categorical_accuracy: 0.2491 - val_factorized_top_k/top_5_categorical_accuracy: 0.3538 - val_factorized_top_k/top_10_categorical_accuracy: 0.4887 - val_factorized_top_k/top_15_categorical_accuracy: 0.5716 - val_factorized_top_k/top_25_categorical_accuracy: 0.6694 - val_loss: 2218.2668 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2218.2668 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5476 - factorized_top_k/top_5_categorical_accuracy: 0.6224 - factorized_top_k/top_10_categorical_accuracy: 0.7229 - factorized_top_k/top_15_categorical_accuracy: 0.7757 - factorized_top_k/top_25_categorical_accuracy: 0.8336 - loss: 2232.0941 - regularization_loss: 0.0000e+00 - total_loss: 2232.0941 - val_factorized_top_k/top_3_categorical_accuracy: 0.2482 - val_factorized_top_k/top_5_categorical_accuracy: 0.3570 - val_factorized_top_k/top_10_categorical_accuracy: 0.4878 - val_factorized_top_k/top_15_categorical_accuracy: 0.5733 - val_factorized_top_k/top_25_categorical_accuracy: 0.6703 - val_loss: 2217.5254 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5254 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5552 - factorized_top_k/top_5_categorical_accuracy: 0.6317 - factorized_top_k/top_10_categorical_accuracy: 0.7299 - factorized_top_k/top_15_categorical_accuracy: 0.7818 - factorized_top_k/top_25_categorical_accuracy: 0.8367 - loss: 2212.9904 - regularization_loss: 0.0000e+00 - total_loss: 2212.9904 - val_factorized_top_k/top_3_categorical_accuracy: 0.2551 - val_factorized_top_k/top_5_categorical_accuracy: 0.3613 - val_factorized_top_k/top_10_categorical_accuracy: 0.4881 - val_factorized_top_k/top_15_categorical_accuracy: 0.5722 - val_factorized_top_k/top_25_categorical_accuracy: 0.6689 - val_loss: 2216.9028 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.9028 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5623 - factorized_top_k/top_5_categorical_accuracy: 0.6385 - factorized_top_k/top_10_categorical_accuracy: 0.7371 - factorized_top_k/top_15_categorical_accuracy: 0.7872 - factorized_top_k/top_25_categorical_accuracy: 0.8399 - loss: 2194.1901 - regularization_loss: 0.0000e+00 - total_loss: 2194.1901 - val_factorized_top_k/top_3_categorical_accuracy: 0.2531 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4858 - val_factorized_top_k/top_15_categorical_accuracy: 0.5693 - val_factorized_top_k/top_25_categorical_accuracy: 0.6686 - val_loss: 2216.3611 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.3611 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5697 - factorized_top_k/top_5_categorical_accuracy: 0.6463 - factorized_top_k/top_10_categorical_accuracy: 0.7432 - factorized_top_k/top_15_categorical_accuracy: 0.7927 - factorized_top_k/top_25_categorical_accuracy: 0.8427 - loss: 2175.7576 - regularization_loss: 0.0000e+00 - total_loss: 2175.7576 - val_factorized_top_k/top_3_categorical_accuracy: 0.2588 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4872 - val_factorized_top_k/top_15_categorical_accuracy: 0.5693 - val_factorized_top_k/top_25_categorical_accuracy: 0.6677 - val_loss: 2215.9399 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.9399 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5779 - factorized_top_k/top_5_categorical_accuracy: 0.6524 - factorized_top_k/top_10_categorical_accuracy: 0.7488 - factorized_top_k/top_15_categorical_accuracy: 0.7979 - factorized_top_k/top_25_categorical_accuracy: 0.8458 - loss: 2159.6673 - regularization_loss: 0.0000e+00 - total_loss: 2159.6673 - val_factorized_top_k/top_3_categorical_accuracy: 0.2582 - val_factorized_top_k/top_5_categorical_accuracy: 0.3564 - val_factorized_top_k/top_10_categorical_accuracy: 0.4861 - val_factorized_top_k/top_15_categorical_accuracy: 0.5702 - val_factorized_top_k/top_25_categorical_accuracy: 0.6689 - val_loss: 2215.7410 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.7410 - lr: 0.0060\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5820 - factorized_top_k/top_5_categorical_accuracy: 0.6565 - factorized_top_k/top_10_categorical_accuracy: 0.7520 - factorized_top_k/top_15_categorical_accuracy: 0.8009 - factorized_top_k/top_25_categorical_accuracy: 0.8471 - loss: 2148.0778 - regularization_loss: 0.0000e+00 - total_loss: 2148.0778 - val_factorized_top_k/top_3_categorical_accuracy: 0.2548 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4844 - val_factorized_top_k/top_15_categorical_accuracy: 0.5684 - val_factorized_top_k/top_25_categorical_accuracy: 0.6674 - val_loss: 2215.5503 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.5503 - lr: 0.0060\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5862 - factorized_top_k/top_5_categorical_accuracy: 0.6610 - factorized_top_k/top_10_categorical_accuracy: 0.7552 - factorized_top_k/top_15_categorical_accuracy: 0.8042 - factorized_top_k/top_25_categorical_accuracy: 0.8491 - loss: 2137.9908 - regularization_loss: 0.0000e+00 - total_loss: 2137.9908 - val_factorized_top_k/top_3_categorical_accuracy: 0.2557 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4881 - val_factorized_top_k/top_15_categorical_accuracy: 0.5693 - val_factorized_top_k/top_25_categorical_accuracy: 0.6669 - val_loss: 2215.4275 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.4275 - lr: 0.0060\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5894 - factorized_top_k/top_5_categorical_accuracy: 0.6656 - factorized_top_k/top_10_categorical_accuracy: 0.7587 - factorized_top_k/top_15_categorical_accuracy: 0.8062 - factorized_top_k/top_25_categorical_accuracy: 0.8513 - loss: 2127.9628 - regularization_loss: 0.0000e+00 - total_loss: 2127.9628 - val_factorized_top_k/top_3_categorical_accuracy: 0.2568 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4867 - val_factorized_top_k/top_15_categorical_accuracy: 0.5664 - val_factorized_top_k/top_25_categorical_accuracy: 0.6671 - val_loss: 2215.3481 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.3481 - lr: 0.0060\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5929 - factorized_top_k/top_5_categorical_accuracy: 0.6692 - factorized_top_k/top_10_categorical_accuracy: 0.7619 - factorized_top_k/top_15_categorical_accuracy: 0.8092 - factorized_top_k/top_25_categorical_accuracy: 0.8537 - loss: 2118.0916 - regularization_loss: 0.0000e+00 - total_loss: 2118.0916 - val_factorized_top_k/top_3_categorical_accuracy: 0.2585 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4861 - val_factorized_top_k/top_15_categorical_accuracy: 0.5661 - val_factorized_top_k/top_25_categorical_accuracy: 0.6674 - val_loss: 2215.2830 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.2830 - lr: 0.0060\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.5976 - factorized_top_k/top_5_categorical_accuracy: 0.6733 - factorized_top_k/top_10_categorical_accuracy: 0.7648 - factorized_top_k/top_15_categorical_accuracy: 0.8116 - factorized_top_k/top_25_categorical_accuracy: 0.8548 - loss: 2107.6913 - regularization_loss: 0.0000e+00 - total_loss: 2107.6913 - val_factorized_top_k/top_3_categorical_accuracy: 0.2594 - val_factorized_top_k/top_5_categorical_accuracy: 0.3618 - val_factorized_top_k/top_10_categorical_accuracy: 0.4864 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6677 - val_loss: 2215.2490 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.2490 - lr: 0.0060\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6009 - factorized_top_k/top_5_categorical_accuracy: 0.6764 - factorized_top_k/top_10_categorical_accuracy: 0.7681 - factorized_top_k/top_15_categorical_accuracy: 0.8135 - factorized_top_k/top_25_categorical_accuracy: 0.8563 - loss: 2098.6835 - regularization_loss: 0.0000e+00 - total_loss: 2098.6835 - val_factorized_top_k/top_3_categorical_accuracy: 0.2637 - val_factorized_top_k/top_5_categorical_accuracy: 0.3587 - val_factorized_top_k/top_10_categorical_accuracy: 0.4861 - val_factorized_top_k/top_15_categorical_accuracy: 0.5679 - val_factorized_top_k/top_25_categorical_accuracy: 0.6674 - val_loss: 2215.2522 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.2522 - lr: 0.0060\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6049 - factorized_top_k/top_5_categorical_accuracy: 0.6799 - factorized_top_k/top_10_categorical_accuracy: 0.7709 - factorized_top_k/top_15_categorical_accuracy: 0.8158 - factorized_top_k/top_25_categorical_accuracy: 0.8575 - loss: 2088.5160 - regularization_loss: 0.0000e+00 - total_loss: 2088.5160 - val_factorized_top_k/top_3_categorical_accuracy: 0.2626 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4838 - val_factorized_top_k/top_15_categorical_accuracy: 0.5656 - val_factorized_top_k/top_25_categorical_accuracy: 0.6674 - val_loss: 2215.2678 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.2678 - lr: 0.0060\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6089 - factorized_top_k/top_5_categorical_accuracy: 0.6844 - factorized_top_k/top_10_categorical_accuracy: 0.7739 - factorized_top_k/top_15_categorical_accuracy: 0.8173 - factorized_top_k/top_25_categorical_accuracy: 0.8589 - loss: 2079.4456 - regularization_loss: 0.0000e+00 - total_loss: 2079.4456 - val_factorized_top_k/top_3_categorical_accuracy: 0.2631 - val_factorized_top_k/top_5_categorical_accuracy: 0.3575 - val_factorized_top_k/top_10_categorical_accuracy: 0.4858 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6677 - val_loss: 2215.3225 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.3225 - lr: 0.0060\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6121 - factorized_top_k/top_5_categorical_accuracy: 0.6878 - factorized_top_k/top_10_categorical_accuracy: 0.7770 - factorized_top_k/top_15_categorical_accuracy: 0.8192 - factorized_top_k/top_25_categorical_accuracy: 0.8604 - loss: 2070.2803 - regularization_loss: 0.0000e+00 - total_loss: 2070.2803 - val_factorized_top_k/top_3_categorical_accuracy: 0.2617 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4844 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6674 - val_loss: 2215.3760 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.3760 - lr: 0.0036\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6137 - factorized_top_k/top_5_categorical_accuracy: 0.6901 - factorized_top_k/top_10_categorical_accuracy: 0.7786 - factorized_top_k/top_15_categorical_accuracy: 0.8202 - factorized_top_k/top_25_categorical_accuracy: 0.8613 - loss: 2065.5620 - regularization_loss: 0.0000e+00 - total_loss: 2065.5620 - val_factorized_top_k/top_3_categorical_accuracy: 0.2660 - val_factorized_top_k/top_5_categorical_accuracy: 0.3613 - val_factorized_top_k/top_10_categorical_accuracy: 0.4829 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6666 - val_loss: 2215.4292 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.4292 - lr: 0.0036\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6157 - factorized_top_k/top_5_categorical_accuracy: 0.6927 - factorized_top_k/top_10_categorical_accuracy: 0.7801 - factorized_top_k/top_15_categorical_accuracy: 0.8214 - factorized_top_k/top_25_categorical_accuracy: 0.8622 - loss: 2059.1726 - regularization_loss: 0.0000e+00 - total_loss: 2059.1726 - val_factorized_top_k/top_3_categorical_accuracy: 0.2620 - val_factorized_top_k/top_5_categorical_accuracy: 0.3570 - val_factorized_top_k/top_10_categorical_accuracy: 0.4826 - val_factorized_top_k/top_15_categorical_accuracy: 0.5676 - val_factorized_top_k/top_25_categorical_accuracy: 0.6663 - val_loss: 2215.4832 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.4832 - lr: 0.0036\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 4s 57ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6175 - factorized_top_k/top_5_categorical_accuracy: 0.6942 - factorized_top_k/top_10_categorical_accuracy: 0.7825 - factorized_top_k/top_15_categorical_accuracy: 0.8227 - factorized_top_k/top_25_categorical_accuracy: 0.8630 - loss: 2054.7270 - regularization_loss: 0.0000e+00 - total_loss: 2054.7270 - val_factorized_top_k/top_3_categorical_accuracy: 0.2640 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4844 - val_factorized_top_k/top_15_categorical_accuracy: 0.5661 - val_factorized_top_k/top_25_categorical_accuracy: 0.6657 - val_loss: 2215.5544 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.5544 - lr: 0.0036\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 5s 71ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6191 - factorized_top_k/top_5_categorical_accuracy: 0.6969 - factorized_top_k/top_10_categorical_accuracy: 0.7835 - factorized_top_k/top_15_categorical_accuracy: 0.8235 - factorized_top_k/top_25_categorical_accuracy: 0.8640 - loss: 2049.2098 - regularization_loss: 0.0000e+00 - total_loss: 2049.2098 - val_factorized_top_k/top_3_categorical_accuracy: 0.2637 - val_factorized_top_k/top_5_categorical_accuracy: 0.3613 - val_factorized_top_k/top_10_categorical_accuracy: 0.4844 - val_factorized_top_k/top_15_categorical_accuracy: 0.5667 - val_factorized_top_k/top_25_categorical_accuracy: 0.6674 - val_loss: 2215.6199 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.6199 - lr: 0.0036\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 3s 50ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6208 - factorized_top_k/top_5_categorical_accuracy: 0.6988 - factorized_top_k/top_10_categorical_accuracy: 0.7851 - factorized_top_k/top_15_categorical_accuracy: 0.8239 - factorized_top_k/top_25_categorical_accuracy: 0.8650 - loss: 2043.6676 - regularization_loss: 0.0000e+00 - total_loss: 2043.6676 - val_factorized_top_k/top_3_categorical_accuracy: 0.2654 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4849 - val_factorized_top_k/top_15_categorical_accuracy: 0.5673 - val_factorized_top_k/top_25_categorical_accuracy: 0.6657 - val_loss: 2215.7039 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.7039 - lr: 0.0036\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6235 - factorized_top_k/top_5_categorical_accuracy: 0.7008 - factorized_top_k/top_10_categorical_accuracy: 0.7861 - factorized_top_k/top_15_categorical_accuracy: 0.8248 - factorized_top_k/top_25_categorical_accuracy: 0.8658 - loss: 2039.0475 - regularization_loss: 0.0000e+00 - total_loss: 2039.0475 - val_factorized_top_k/top_3_categorical_accuracy: 0.2614 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4835 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6663 - val_loss: 2215.7854 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.7854 - lr: 0.0036\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6240 - factorized_top_k/top_5_categorical_accuracy: 0.7032 - factorized_top_k/top_10_categorical_accuracy: 0.7878 - factorized_top_k/top_15_categorical_accuracy: 0.8253 - factorized_top_k/top_25_categorical_accuracy: 0.8663 - loss: 2033.9963 - regularization_loss: 0.0000e+00 - total_loss: 2033.9963 - val_factorized_top_k/top_3_categorical_accuracy: 0.2651 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4829 - val_factorized_top_k/top_15_categorical_accuracy: 0.5659 - val_factorized_top_k/top_25_categorical_accuracy: 0.6669 - val_loss: 2215.8840 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2215.8840 - lr: 0.0036\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6273 - factorized_top_k/top_5_categorical_accuracy: 0.7056 - factorized_top_k/top_10_categorical_accuracy: 0.7895 - factorized_top_k/top_15_categorical_accuracy: 0.8264 - factorized_top_k/top_25_categorical_accuracy: 0.8669 - loss: 2029.3049 - regularization_loss: 0.0000e+00 - total_loss: 2029.3049 - val_factorized_top_k/top_3_categorical_accuracy: 0.2669 - val_factorized_top_k/top_5_categorical_accuracy: 0.3572 - val_factorized_top_k/top_10_categorical_accuracy: 0.4832 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6669 - val_loss: 2216.0039 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.0039 - lr: 0.0036\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6282 - factorized_top_k/top_5_categorical_accuracy: 0.7068 - factorized_top_k/top_10_categorical_accuracy: 0.7909 - factorized_top_k/top_15_categorical_accuracy: 0.8271 - factorized_top_k/top_25_categorical_accuracy: 0.8676 - loss: 2024.2756 - regularization_loss: 0.0000e+00 - total_loss: 2024.2756 - val_factorized_top_k/top_3_categorical_accuracy: 0.2686 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4835 - val_factorized_top_k/top_15_categorical_accuracy: 0.5659 - val_factorized_top_k/top_25_categorical_accuracy: 0.6646 - val_loss: 2216.0757 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.0757 - lr: 0.0022\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6301 - factorized_top_k/top_5_categorical_accuracy: 0.7087 - factorized_top_k/top_10_categorical_accuracy: 0.7916 - factorized_top_k/top_15_categorical_accuracy: 0.8276 - factorized_top_k/top_25_categorical_accuracy: 0.8682 - loss: 2021.3572 - regularization_loss: 0.0000e+00 - total_loss: 2021.3572 - val_factorized_top_k/top_3_categorical_accuracy: 0.2686 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4844 - val_factorized_top_k/top_15_categorical_accuracy: 0.5659 - val_factorized_top_k/top_25_categorical_accuracy: 0.6654 - val_loss: 2216.1453 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.1453 - lr: 0.0022\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6296 - factorized_top_k/top_5_categorical_accuracy: 0.7095 - factorized_top_k/top_10_categorical_accuracy: 0.7926 - factorized_top_k/top_15_categorical_accuracy: 0.8283 - factorized_top_k/top_25_categorical_accuracy: 0.8685 - loss: 2018.9892 - regularization_loss: 0.0000e+00 - total_loss: 2018.9892 - val_factorized_top_k/top_3_categorical_accuracy: 0.2666 - val_factorized_top_k/top_5_categorical_accuracy: 0.3575 - val_factorized_top_k/top_10_categorical_accuracy: 0.4829 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6663 - val_loss: 2216.2119 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.2119 - lr: 0.0022\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6312 - factorized_top_k/top_5_categorical_accuracy: 0.7108 - factorized_top_k/top_10_categorical_accuracy: 0.7934 - factorized_top_k/top_15_categorical_accuracy: 0.8287 - factorized_top_k/top_25_categorical_accuracy: 0.8687 - loss: 2016.0332 - regularization_loss: 0.0000e+00 - total_loss: 2016.0332 - val_factorized_top_k/top_3_categorical_accuracy: 0.2657 - val_factorized_top_k/top_5_categorical_accuracy: 0.3598 - val_factorized_top_k/top_10_categorical_accuracy: 0.4832 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6669 - val_loss: 2216.2766 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.2766 - lr: 0.0022\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6329 - factorized_top_k/top_5_categorical_accuracy: 0.7114 - factorized_top_k/top_10_categorical_accuracy: 0.7936 - factorized_top_k/top_15_categorical_accuracy: 0.8296 - factorized_top_k/top_25_categorical_accuracy: 0.8692 - loss: 2013.4869 - regularization_loss: 0.0000e+00 - total_loss: 2013.4869 - val_factorized_top_k/top_3_categorical_accuracy: 0.2620 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6669 - val_loss: 2216.3489 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.3489 - lr: 0.0022\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6330 - factorized_top_k/top_5_categorical_accuracy: 0.7126 - factorized_top_k/top_10_categorical_accuracy: 0.7946 - factorized_top_k/top_15_categorical_accuracy: 0.8300 - factorized_top_k/top_25_categorical_accuracy: 0.8699 - loss: 2010.6540 - regularization_loss: 0.0000e+00 - total_loss: 2010.6540 - val_factorized_top_k/top_3_categorical_accuracy: 0.2660 - val_factorized_top_k/top_5_categorical_accuracy: 0.3587 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6660 - val_loss: 2216.4319 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.4319 - lr: 0.0022\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6343 - factorized_top_k/top_5_categorical_accuracy: 0.7134 - factorized_top_k/top_10_categorical_accuracy: 0.7952 - factorized_top_k/top_15_categorical_accuracy: 0.8304 - factorized_top_k/top_25_categorical_accuracy: 0.8702 - loss: 2008.0088 - regularization_loss: 0.0000e+00 - total_loss: 2008.0088 - val_factorized_top_k/top_3_categorical_accuracy: 0.2628 - val_factorized_top_k/top_5_categorical_accuracy: 0.3561 - val_factorized_top_k/top_10_categorical_accuracy: 0.4835 - val_factorized_top_k/top_15_categorical_accuracy: 0.5659 - val_factorized_top_k/top_25_categorical_accuracy: 0.6648 - val_loss: 2216.5088 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.5088 - lr: 0.0022\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6354 - factorized_top_k/top_5_categorical_accuracy: 0.7140 - factorized_top_k/top_10_categorical_accuracy: 0.7960 - factorized_top_k/top_15_categorical_accuracy: 0.8312 - factorized_top_k/top_25_categorical_accuracy: 0.8706 - loss: 2005.1749 - regularization_loss: 0.0000e+00 - total_loss: 2005.1749 - val_factorized_top_k/top_3_categorical_accuracy: 0.2648 - val_factorized_top_k/top_5_categorical_accuracy: 0.3587 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2216.5908 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.5908 - lr: 0.0022\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6361 - factorized_top_k/top_5_categorical_accuracy: 0.7159 - factorized_top_k/top_10_categorical_accuracy: 0.7970 - factorized_top_k/top_15_categorical_accuracy: 0.8313 - factorized_top_k/top_25_categorical_accuracy: 0.8711 - loss: 2002.2363 - regularization_loss: 0.0000e+00 - total_loss: 2002.2363 - val_factorized_top_k/top_3_categorical_accuracy: 0.2654 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4838 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6654 - val_loss: 2216.6743 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.6743 - lr: 0.0022\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6378 - factorized_top_k/top_5_categorical_accuracy: 0.7164 - factorized_top_k/top_10_categorical_accuracy: 0.7972 - factorized_top_k/top_15_categorical_accuracy: 0.8320 - factorized_top_k/top_25_categorical_accuracy: 0.8714 - loss: 2000.2773 - regularization_loss: 0.0000e+00 - total_loss: 2000.2773 - val_factorized_top_k/top_3_categorical_accuracy: 0.2657 - val_factorized_top_k/top_5_categorical_accuracy: 0.3621 - val_factorized_top_k/top_10_categorical_accuracy: 0.4826 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6648 - val_loss: 2216.7192 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.7192 - lr: 0.0013\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6381 - factorized_top_k/top_5_categorical_accuracy: 0.7170 - factorized_top_k/top_10_categorical_accuracy: 0.7978 - factorized_top_k/top_15_categorical_accuracy: 0.8322 - factorized_top_k/top_25_categorical_accuracy: 0.8715 - loss: 1998.3590 - regularization_loss: 0.0000e+00 - total_loss: 1998.3590 - val_factorized_top_k/top_3_categorical_accuracy: 0.2689 - val_factorized_top_k/top_5_categorical_accuracy: 0.3598 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6648 - val_loss: 2216.7620 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.7620 - lr: 0.0013\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6384 - factorized_top_k/top_5_categorical_accuracy: 0.7170 - factorized_top_k/top_10_categorical_accuracy: 0.7981 - factorized_top_k/top_15_categorical_accuracy: 0.8324 - factorized_top_k/top_25_categorical_accuracy: 0.8717 - loss: 1996.8392 - regularization_loss: 0.0000e+00 - total_loss: 1996.8392 - val_factorized_top_k/top_3_categorical_accuracy: 0.2686 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4829 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6651 - val_loss: 2216.8101 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.8101 - lr: 0.0013\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6391 - factorized_top_k/top_5_categorical_accuracy: 0.7175 - factorized_top_k/top_10_categorical_accuracy: 0.7987 - factorized_top_k/top_15_categorical_accuracy: 0.8327 - factorized_top_k/top_25_categorical_accuracy: 0.8718 - loss: 1995.1760 - regularization_loss: 0.0000e+00 - total_loss: 1995.1760 - val_factorized_top_k/top_3_categorical_accuracy: 0.2680 - val_factorized_top_k/top_5_categorical_accuracy: 0.3615 - val_factorized_top_k/top_10_categorical_accuracy: 0.4841 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2216.8584 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.8584 - lr: 0.0013\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6398 - factorized_top_k/top_5_categorical_accuracy: 0.7184 - factorized_top_k/top_10_categorical_accuracy: 0.7988 - factorized_top_k/top_15_categorical_accuracy: 0.8330 - factorized_top_k/top_25_categorical_accuracy: 0.8721 - loss: 1993.9230 - regularization_loss: 0.0000e+00 - total_loss: 1993.9230 - val_factorized_top_k/top_3_categorical_accuracy: 0.2660 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5656 - val_factorized_top_k/top_25_categorical_accuracy: 0.6651 - val_loss: 2216.9080 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.9080 - lr: 0.0013\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6403 - factorized_top_k/top_5_categorical_accuracy: 0.7195 - factorized_top_k/top_10_categorical_accuracy: 0.7989 - factorized_top_k/top_15_categorical_accuracy: 0.8334 - factorized_top_k/top_25_categorical_accuracy: 0.8724 - loss: 1992.3283 - regularization_loss: 0.0000e+00 - total_loss: 1992.3283 - val_factorized_top_k/top_3_categorical_accuracy: 0.2626 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2216.9587 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2216.9587 - lr: 0.0013\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6408 - factorized_top_k/top_5_categorical_accuracy: 0.7200 - factorized_top_k/top_10_categorical_accuracy: 0.7989 - factorized_top_k/top_15_categorical_accuracy: 0.8335 - factorized_top_k/top_25_categorical_accuracy: 0.8727 - loss: 1990.9322 - regularization_loss: 0.0000e+00 - total_loss: 1990.9322 - val_factorized_top_k/top_3_categorical_accuracy: 0.2666 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4806 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6648 - val_loss: 2217.0095 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.0095 - lr: 0.0013\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6418 - factorized_top_k/top_5_categorical_accuracy: 0.7203 - factorized_top_k/top_10_categorical_accuracy: 0.7993 - factorized_top_k/top_15_categorical_accuracy: 0.8338 - factorized_top_k/top_25_categorical_accuracy: 0.8729 - loss: 1989.9949 - regularization_loss: 0.0000e+00 - total_loss: 1989.9949 - val_factorized_top_k/top_3_categorical_accuracy: 0.2706 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4832 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.0571 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.0571 - lr: 0.0013\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6423 - factorized_top_k/top_5_categorical_accuracy: 0.7208 - factorized_top_k/top_10_categorical_accuracy: 0.7999 - factorized_top_k/top_15_categorical_accuracy: 0.8338 - factorized_top_k/top_25_categorical_accuracy: 0.8730 - loss: 1987.9437 - regularization_loss: 0.0000e+00 - total_loss: 1987.9437 - val_factorized_top_k/top_3_categorical_accuracy: 0.2712 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4835 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.1106 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.1106 - lr: 0.0013\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6429 - factorized_top_k/top_5_categorical_accuracy: 0.7208 - factorized_top_k/top_10_categorical_accuracy: 0.8002 - factorized_top_k/top_15_categorical_accuracy: 0.8339 - factorized_top_k/top_25_categorical_accuracy: 0.8732 - loss: 1986.6169 - regularization_loss: 0.0000e+00 - total_loss: 1986.6169 - val_factorized_top_k/top_3_categorical_accuracy: 0.2712 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.1375 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.1375 - lr: 7.7760e-04\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6433 - factorized_top_k/top_5_categorical_accuracy: 0.7213 - factorized_top_k/top_10_categorical_accuracy: 0.8006 - factorized_top_k/top_15_categorical_accuracy: 0.8343 - factorized_top_k/top_25_categorical_accuracy: 0.8734 - loss: 1985.7748 - regularization_loss: 0.0000e+00 - total_loss: 1985.7748 - val_factorized_top_k/top_3_categorical_accuracy: 0.2680 - val_factorized_top_k/top_5_categorical_accuracy: 0.3561 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.1672 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.1672 - lr: 7.7760e-04\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6434 - factorized_top_k/top_5_categorical_accuracy: 0.7214 - factorized_top_k/top_10_categorical_accuracy: 0.8006 - factorized_top_k/top_15_categorical_accuracy: 0.8345 - factorized_top_k/top_25_categorical_accuracy: 0.8734 - loss: 1984.8260 - regularization_loss: 0.0000e+00 - total_loss: 1984.8260 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3581 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5656 - val_factorized_top_k/top_25_categorical_accuracy: 0.6646 - val_loss: 2217.1997 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.1997 - lr: 7.7760e-04\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6438 - factorized_top_k/top_5_categorical_accuracy: 0.7221 - factorized_top_k/top_10_categorical_accuracy: 0.8008 - factorized_top_k/top_15_categorical_accuracy: 0.8344 - factorized_top_k/top_25_categorical_accuracy: 0.8735 - loss: 1983.7417 - regularization_loss: 0.0000e+00 - total_loss: 1983.7417 - val_factorized_top_k/top_3_categorical_accuracy: 0.2680 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6651 - val_loss: 2217.2271 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.2271 - lr: 7.7760e-04\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6445 - factorized_top_k/top_5_categorical_accuracy: 0.7221 - factorized_top_k/top_10_categorical_accuracy: 0.8011 - factorized_top_k/top_15_categorical_accuracy: 0.8349 - factorized_top_k/top_25_categorical_accuracy: 0.8736 - loss: 1983.4292 - regularization_loss: 0.0000e+00 - total_loss: 1983.4292 - val_factorized_top_k/top_3_categorical_accuracy: 0.2663 - val_factorized_top_k/top_5_categorical_accuracy: 0.3570 - val_factorized_top_k/top_10_categorical_accuracy: 0.4806 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6646 - val_loss: 2217.2551 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.2551 - lr: 7.7760e-04\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6446 - factorized_top_k/top_5_categorical_accuracy: 0.7224 - factorized_top_k/top_10_categorical_accuracy: 0.8013 - factorized_top_k/top_15_categorical_accuracy: 0.8349 - factorized_top_k/top_25_categorical_accuracy: 0.8736 - loss: 1981.9523 - regularization_loss: 0.0000e+00 - total_loss: 1981.9523 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.2869 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.2869 - lr: 7.7760e-04\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6450 - factorized_top_k/top_5_categorical_accuracy: 0.7229 - factorized_top_k/top_10_categorical_accuracy: 0.8013 - factorized_top_k/top_15_categorical_accuracy: 0.8348 - factorized_top_k/top_25_categorical_accuracy: 0.8736 - loss: 1981.5951 - regularization_loss: 0.0000e+00 - total_loss: 1981.5951 - val_factorized_top_k/top_3_categorical_accuracy: 0.2692 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4806 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.3169 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.3169 - lr: 7.7760e-04\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6460 - factorized_top_k/top_5_categorical_accuracy: 0.7232 - factorized_top_k/top_10_categorical_accuracy: 0.8016 - factorized_top_k/top_15_categorical_accuracy: 0.8350 - factorized_top_k/top_25_categorical_accuracy: 0.8738 - loss: 1980.5048 - regularization_loss: 0.0000e+00 - total_loss: 1980.5048 - val_factorized_top_k/top_3_categorical_accuracy: 0.2723 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.3464 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.3464 - lr: 7.7760e-04\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6461 - factorized_top_k/top_5_categorical_accuracy: 0.7233 - factorized_top_k/top_10_categorical_accuracy: 0.8018 - factorized_top_k/top_15_categorical_accuracy: 0.8350 - factorized_top_k/top_25_categorical_accuracy: 0.8739 - loss: 1979.9570 - regularization_loss: 0.0000e+00 - total_loss: 1979.9570 - val_factorized_top_k/top_3_categorical_accuracy: 0.2712 - val_factorized_top_k/top_5_categorical_accuracy: 0.3613 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.3750 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.3750 - lr: 7.7760e-04\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6462 - factorized_top_k/top_5_categorical_accuracy: 0.7235 - factorized_top_k/top_10_categorical_accuracy: 0.8019 - factorized_top_k/top_15_categorical_accuracy: 0.8352 - factorized_top_k/top_25_categorical_accuracy: 0.8740 - loss: 1979.1873 - regularization_loss: 0.0000e+00 - total_loss: 1979.1873 - val_factorized_top_k/top_3_categorical_accuracy: 0.2723 - val_factorized_top_k/top_5_categorical_accuracy: 0.3570 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.3938 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.3938 - lr: 4.6656e-04\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6466 - factorized_top_k/top_5_categorical_accuracy: 0.7236 - factorized_top_k/top_10_categorical_accuracy: 0.8020 - factorized_top_k/top_15_categorical_accuracy: 0.8354 - factorized_top_k/top_25_categorical_accuracy: 0.8742 - loss: 1978.4324 - regularization_loss: 0.0000e+00 - total_loss: 1978.4324 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3615 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.4121 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.4121 - lr: 4.6656e-04\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6461 - factorized_top_k/top_5_categorical_accuracy: 0.7240 - factorized_top_k/top_10_categorical_accuracy: 0.8022 - factorized_top_k/top_15_categorical_accuracy: 0.8353 - factorized_top_k/top_25_categorical_accuracy: 0.8742 - loss: 1978.6145 - regularization_loss: 0.0000e+00 - total_loss: 1978.6145 - val_factorized_top_k/top_3_categorical_accuracy: 0.2720 - val_factorized_top_k/top_5_categorical_accuracy: 0.3598 - val_factorized_top_k/top_10_categorical_accuracy: 0.4798 - val_factorized_top_k/top_15_categorical_accuracy: 0.5656 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.4316 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.4316 - lr: 4.6656e-04\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6472 - factorized_top_k/top_5_categorical_accuracy: 0.7241 - factorized_top_k/top_10_categorical_accuracy: 0.8024 - factorized_top_k/top_15_categorical_accuracy: 0.8352 - factorized_top_k/top_25_categorical_accuracy: 0.8744 - loss: 1977.9374 - regularization_loss: 0.0000e+00 - total_loss: 1977.9374 - val_factorized_top_k/top_3_categorical_accuracy: 0.2732 - val_factorized_top_k/top_5_categorical_accuracy: 0.3598 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.4490 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.4490 - lr: 4.6656e-04\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6470 - factorized_top_k/top_5_categorical_accuracy: 0.7242 - factorized_top_k/top_10_categorical_accuracy: 0.8022 - factorized_top_k/top_15_categorical_accuracy: 0.8352 - factorized_top_k/top_25_categorical_accuracy: 0.8743 - loss: 1977.4197 - regularization_loss: 0.0000e+00 - total_loss: 1977.4197 - val_factorized_top_k/top_3_categorical_accuracy: 0.2689 - val_factorized_top_k/top_5_categorical_accuracy: 0.3572 - val_factorized_top_k/top_10_categorical_accuracy: 0.4798 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.4675 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.4675 - lr: 4.6656e-04\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6464 - factorized_top_k/top_5_categorical_accuracy: 0.7247 - factorized_top_k/top_10_categorical_accuracy: 0.8024 - factorized_top_k/top_15_categorical_accuracy: 0.8353 - factorized_top_k/top_25_categorical_accuracy: 0.8744 - loss: 1977.1967 - regularization_loss: 0.0000e+00 - total_loss: 1977.1967 - val_factorized_top_k/top_3_categorical_accuracy: 0.2692 - val_factorized_top_k/top_5_categorical_accuracy: 0.3598 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.4866 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.4866 - lr: 4.6656e-04\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6461 - factorized_top_k/top_5_categorical_accuracy: 0.7250 - factorized_top_k/top_10_categorical_accuracy: 0.8025 - factorized_top_k/top_15_categorical_accuracy: 0.8357 - factorized_top_k/top_25_categorical_accuracy: 0.8746 - loss: 1976.7974 - regularization_loss: 0.0000e+00 - total_loss: 1976.7974 - val_factorized_top_k/top_3_categorical_accuracy: 0.2689 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4798 - val_factorized_top_k/top_15_categorical_accuracy: 0.5624 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.5029 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5029 - lr: 4.6656e-04\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 4s 60ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6472 - factorized_top_k/top_5_categorical_accuracy: 0.7249 - factorized_top_k/top_10_categorical_accuracy: 0.8027 - factorized_top_k/top_15_categorical_accuracy: 0.8355 - factorized_top_k/top_25_categorical_accuracy: 0.8746 - loss: 1976.0483 - regularization_loss: 0.0000e+00 - total_loss: 1976.0483 - val_factorized_top_k/top_3_categorical_accuracy: 0.2717 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4826 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.5203 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5203 - lr: 4.6656e-04\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 5s 71ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6473 - factorized_top_k/top_5_categorical_accuracy: 0.7250 - factorized_top_k/top_10_categorical_accuracy: 0.8028 - factorized_top_k/top_15_categorical_accuracy: 0.8356 - factorized_top_k/top_25_categorical_accuracy: 0.8747 - loss: 1976.1646 - regularization_loss: 0.0000e+00 - total_loss: 1976.1646 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3572 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6617 - val_loss: 2217.5386 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5386 - lr: 4.6656e-04\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 3s 50ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6473 - factorized_top_k/top_5_categorical_accuracy: 0.7249 - factorized_top_k/top_10_categorical_accuracy: 0.8027 - factorized_top_k/top_15_categorical_accuracy: 0.8357 - factorized_top_k/top_25_categorical_accuracy: 0.8746 - loss: 1974.4667 - regularization_loss: 0.0000e+00 - total_loss: 1974.4667 - val_factorized_top_k/top_3_categorical_accuracy: 0.2683 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.5486 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5486 - lr: 2.7994e-04\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 3s 48ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6478 - factorized_top_k/top_5_categorical_accuracy: 0.7252 - factorized_top_k/top_10_categorical_accuracy: 0.8030 - factorized_top_k/top_15_categorical_accuracy: 0.8357 - factorized_top_k/top_25_categorical_accuracy: 0.8747 - loss: 1975.2505 - regularization_loss: 0.0000e+00 - total_loss: 1975.2505 - val_factorized_top_k/top_3_categorical_accuracy: 0.2740 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.5598 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5598 - lr: 2.7994e-04\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6480 - factorized_top_k/top_5_categorical_accuracy: 0.7249 - factorized_top_k/top_10_categorical_accuracy: 0.8031 - factorized_top_k/top_15_categorical_accuracy: 0.8359 - factorized_top_k/top_25_categorical_accuracy: 0.8747 - loss: 1974.0499 - regularization_loss: 0.0000e+00 - total_loss: 1974.0499 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.5701 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5701 - lr: 2.7994e-04\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6479 - factorized_top_k/top_5_categorical_accuracy: 0.7258 - factorized_top_k/top_10_categorical_accuracy: 0.8028 - factorized_top_k/top_15_categorical_accuracy: 0.8358 - factorized_top_k/top_25_categorical_accuracy: 0.8747 - loss: 1974.1070 - regularization_loss: 0.0000e+00 - total_loss: 1974.1070 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.5803 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5803 - lr: 2.7994e-04\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6479 - factorized_top_k/top_5_categorical_accuracy: 0.7256 - factorized_top_k/top_10_categorical_accuracy: 0.8029 - factorized_top_k/top_15_categorical_accuracy: 0.8358 - factorized_top_k/top_25_categorical_accuracy: 0.8747 - loss: 1973.8023 - regularization_loss: 0.0000e+00 - total_loss: 1973.8023 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.5911 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.5911 - lr: 2.7994e-04\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6483 - factorized_top_k/top_5_categorical_accuracy: 0.7262 - factorized_top_k/top_10_categorical_accuracy: 0.8030 - factorized_top_k/top_15_categorical_accuracy: 0.8362 - factorized_top_k/top_25_categorical_accuracy: 0.8748 - loss: 1973.4694 - regularization_loss: 0.0000e+00 - total_loss: 1973.4694 - val_factorized_top_k/top_3_categorical_accuracy: 0.2720 - val_factorized_top_k/top_5_categorical_accuracy: 0.3581 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.6016 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6016 - lr: 2.7994e-04\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6486 - factorized_top_k/top_5_categorical_accuracy: 0.7254 - factorized_top_k/top_10_categorical_accuracy: 0.8031 - factorized_top_k/top_15_categorical_accuracy: 0.8359 - factorized_top_k/top_25_categorical_accuracy: 0.8749 - loss: 1973.4320 - regularization_loss: 0.0000e+00 - total_loss: 1973.4320 - val_factorized_top_k/top_3_categorical_accuracy: 0.2720 - val_factorized_top_k/top_5_categorical_accuracy: 0.3564 - val_factorized_top_k/top_10_categorical_accuracy: 0.4826 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6654 - val_loss: 2217.6125 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6125 - lr: 2.7994e-04\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6474 - factorized_top_k/top_5_categorical_accuracy: 0.7252 - factorized_top_k/top_10_categorical_accuracy: 0.8030 - factorized_top_k/top_15_categorical_accuracy: 0.8359 - factorized_top_k/top_25_categorical_accuracy: 0.8750 - loss: 1972.7775 - regularization_loss: 0.0000e+00 - total_loss: 1972.7775 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.6228 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6228 - lr: 2.7994e-04\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6485 - factorized_top_k/top_5_categorical_accuracy: 0.7260 - factorized_top_k/top_10_categorical_accuracy: 0.8030 - factorized_top_k/top_15_categorical_accuracy: 0.8359 - factorized_top_k/top_25_categorical_accuracy: 0.8751 - loss: 1973.0173 - regularization_loss: 0.0000e+00 - total_loss: 1973.0173 - val_factorized_top_k/top_3_categorical_accuracy: 0.2717 - val_factorized_top_k/top_5_categorical_accuracy: 0.3621 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5624 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.6335 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6335 - lr: 2.7994e-04\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6486 - factorized_top_k/top_5_categorical_accuracy: 0.7256 - factorized_top_k/top_10_categorical_accuracy: 0.8034 - factorized_top_k/top_15_categorical_accuracy: 0.8360 - factorized_top_k/top_25_categorical_accuracy: 0.8751 - loss: 1972.6123 - regularization_loss: 0.0000e+00 - total_loss: 1972.6123 - val_factorized_top_k/top_3_categorical_accuracy: 0.2723 - val_factorized_top_k/top_5_categorical_accuracy: 0.3570 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6620 - val_loss: 2217.6401 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6401 - lr: 1.6796e-04\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6483 - factorized_top_k/top_5_categorical_accuracy: 0.7254 - factorized_top_k/top_10_categorical_accuracy: 0.8032 - factorized_top_k/top_15_categorical_accuracy: 0.8361 - factorized_top_k/top_25_categorical_accuracy: 0.8751 - loss: 1972.5454 - regularization_loss: 0.0000e+00 - total_loss: 1972.5454 - val_factorized_top_k/top_3_categorical_accuracy: 0.2709 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4798 - val_factorized_top_k/top_15_categorical_accuracy: 0.5618 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.6465 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6465 - lr: 1.6796e-04\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 3s 48ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6495 - factorized_top_k/top_5_categorical_accuracy: 0.7257 - factorized_top_k/top_10_categorical_accuracy: 0.8032 - factorized_top_k/top_15_categorical_accuracy: 0.8361 - factorized_top_k/top_25_categorical_accuracy: 0.8751 - loss: 1972.6512 - regularization_loss: 0.0000e+00 - total_loss: 1972.6512 - val_factorized_top_k/top_3_categorical_accuracy: 0.2720 - val_factorized_top_k/top_5_categorical_accuracy: 0.3610 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.6528 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6528 - lr: 1.6796e-04\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6493 - factorized_top_k/top_5_categorical_accuracy: 0.7262 - factorized_top_k/top_10_categorical_accuracy: 0.8031 - factorized_top_k/top_15_categorical_accuracy: 0.8361 - factorized_top_k/top_25_categorical_accuracy: 0.8752 - loss: 1972.8570 - regularization_loss: 0.0000e+00 - total_loss: 1972.8570 - val_factorized_top_k/top_3_categorical_accuracy: 0.2735 - val_factorized_top_k/top_5_categorical_accuracy: 0.3618 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.6592 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6592 - lr: 1.6796e-04\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6491 - factorized_top_k/top_5_categorical_accuracy: 0.7261 - factorized_top_k/top_10_categorical_accuracy: 0.8033 - factorized_top_k/top_15_categorical_accuracy: 0.8362 - factorized_top_k/top_25_categorical_accuracy: 0.8751 - loss: 1972.0641 - regularization_loss: 0.0000e+00 - total_loss: 1972.0641 - val_factorized_top_k/top_3_categorical_accuracy: 0.2697 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.6655 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6655 - lr: 1.6796e-04\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6497 - factorized_top_k/top_5_categorical_accuracy: 0.7263 - factorized_top_k/top_10_categorical_accuracy: 0.8035 - factorized_top_k/top_15_categorical_accuracy: 0.8360 - factorized_top_k/top_25_categorical_accuracy: 0.8751 - loss: 1972.0771 - regularization_loss: 0.0000e+00 - total_loss: 1972.0771 - val_factorized_top_k/top_3_categorical_accuracy: 0.2689 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.6711 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6711 - lr: 1.6796e-04\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6494 - factorized_top_k/top_5_categorical_accuracy: 0.7260 - factorized_top_k/top_10_categorical_accuracy: 0.8033 - factorized_top_k/top_15_categorical_accuracy: 0.8361 - factorized_top_k/top_25_categorical_accuracy: 0.8752 - loss: 1972.1612 - regularization_loss: 0.0000e+00 - total_loss: 1972.1612 - val_factorized_top_k/top_3_categorical_accuracy: 0.2694 - val_factorized_top_k/top_5_categorical_accuracy: 0.3587 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.6780 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6780 - lr: 1.6796e-04\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6489 - factorized_top_k/top_5_categorical_accuracy: 0.7262 - factorized_top_k/top_10_categorical_accuracy: 0.8035 - factorized_top_k/top_15_categorical_accuracy: 0.8363 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1971.5829 - regularization_loss: 0.0000e+00 - total_loss: 1971.5829 - val_factorized_top_k/top_3_categorical_accuracy: 0.2726 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4832 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.6836 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6836 - lr: 1.6796e-04\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6503 - factorized_top_k/top_5_categorical_accuracy: 0.7264 - factorized_top_k/top_10_categorical_accuracy: 0.8034 - factorized_top_k/top_15_categorical_accuracy: 0.8363 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1972.2320 - regularization_loss: 0.0000e+00 - total_loss: 1972.2320 - val_factorized_top_k/top_3_categorical_accuracy: 0.2732 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4801 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.6895 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6895 - lr: 1.6796e-04\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6497 - factorized_top_k/top_5_categorical_accuracy: 0.7268 - factorized_top_k/top_10_categorical_accuracy: 0.8034 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8752 - loss: 1971.6930 - regularization_loss: 0.0000e+00 - total_loss: 1971.6930 - val_factorized_top_k/top_3_categorical_accuracy: 0.2697 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6646 - val_loss: 2217.6929 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6929 - lr: 1.0078e-04\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6493 - factorized_top_k/top_5_categorical_accuracy: 0.7266 - factorized_top_k/top_10_categorical_accuracy: 0.8036 - factorized_top_k/top_15_categorical_accuracy: 0.8362 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1971.7572 - regularization_loss: 0.0000e+00 - total_loss: 1971.7572 - val_factorized_top_k/top_3_categorical_accuracy: 0.2712 - val_factorized_top_k/top_5_categorical_accuracy: 0.3598 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.6965 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.6965 - lr: 1.0078e-04\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6500 - factorized_top_k/top_5_categorical_accuracy: 0.7271 - factorized_top_k/top_10_categorical_accuracy: 0.8034 - factorized_top_k/top_15_categorical_accuracy: 0.8363 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.6894 - regularization_loss: 0.0000e+00 - total_loss: 1970.6894 - val_factorized_top_k/top_3_categorical_accuracy: 0.2674 - val_factorized_top_k/top_5_categorical_accuracy: 0.3575 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7004 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7004 - lr: 1.0078e-04\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6502 - factorized_top_k/top_5_categorical_accuracy: 0.7269 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8363 - factorized_top_k/top_25_categorical_accuracy: 0.8751 - loss: 1971.5473 - regularization_loss: 0.0000e+00 - total_loss: 1971.5473 - val_factorized_top_k/top_3_categorical_accuracy: 0.2680 - val_factorized_top_k/top_5_categorical_accuracy: 0.3572 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5624 - val_factorized_top_k/top_25_categorical_accuracy: 0.6646 - val_loss: 2217.7039 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7039 - lr: 1.0078e-04\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 3s 48ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6490 - factorized_top_k/top_5_categorical_accuracy: 0.7264 - factorized_top_k/top_10_categorical_accuracy: 0.8036 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8752 - loss: 1970.9653 - regularization_loss: 0.0000e+00 - total_loss: 1970.9653 - val_factorized_top_k/top_3_categorical_accuracy: 0.2749 - val_factorized_top_k/top_5_categorical_accuracy: 0.3610 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7073 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7073 - lr: 1.0078e-04\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6500 - factorized_top_k/top_5_categorical_accuracy: 0.7269 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8363 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.6832 - regularization_loss: 0.0000e+00 - total_loss: 1970.6832 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3587 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7109 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7109 - lr: 1.0078e-04\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6499 - factorized_top_k/top_5_categorical_accuracy: 0.7266 - factorized_top_k/top_10_categorical_accuracy: 0.8034 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.8380 - regularization_loss: 0.0000e+00 - total_loss: 1970.8380 - val_factorized_top_k/top_3_categorical_accuracy: 0.2706 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4832 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.7139 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7139 - lr: 1.0078e-04\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6494 - factorized_top_k/top_5_categorical_accuracy: 0.7269 - factorized_top_k/top_10_categorical_accuracy: 0.8035 - factorized_top_k/top_15_categorical_accuracy: 0.8365 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.4533 - regularization_loss: 0.0000e+00 - total_loss: 1970.4533 - val_factorized_top_k/top_3_categorical_accuracy: 0.2720 - val_factorized_top_k/top_5_categorical_accuracy: 0.3621 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7178 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7178 - lr: 1.0078e-04\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6493 - factorized_top_k/top_5_categorical_accuracy: 0.7270 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8363 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1969.8295 - regularization_loss: 0.0000e+00 - total_loss: 1969.8295 - val_factorized_top_k/top_3_categorical_accuracy: 0.2723 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7212 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7212 - lr: 1.0078e-04\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6505 - factorized_top_k/top_5_categorical_accuracy: 0.7270 - factorized_top_k/top_10_categorical_accuracy: 0.8034 - factorized_top_k/top_15_categorical_accuracy: 0.8365 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.2603 - regularization_loss: 0.0000e+00 - total_loss: 1970.2603 - val_factorized_top_k/top_3_categorical_accuracy: 0.2703 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7229 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7229 - lr: 6.0466e-05\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6509 - factorized_top_k/top_5_categorical_accuracy: 0.7268 - factorized_top_k/top_10_categorical_accuracy: 0.8036 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.1720 - regularization_loss: 0.0000e+00 - total_loss: 1970.1720 - val_factorized_top_k/top_3_categorical_accuracy: 0.2683 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.7251 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7251 - lr: 6.0466e-05\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6501 - factorized_top_k/top_5_categorical_accuracy: 0.7276 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.6299 - regularization_loss: 0.0000e+00 - total_loss: 1970.6299 - val_factorized_top_k/top_3_categorical_accuracy: 0.2697 - val_factorized_top_k/top_5_categorical_accuracy: 0.3618 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7271 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7271 - lr: 6.0466e-05\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6504 - factorized_top_k/top_5_categorical_accuracy: 0.7269 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8363 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1971.3169 - regularization_loss: 0.0000e+00 - total_loss: 1971.3169 - val_factorized_top_k/top_3_categorical_accuracy: 0.2740 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7295 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7295 - lr: 6.0466e-05\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6495 - factorized_top_k/top_5_categorical_accuracy: 0.7265 - factorized_top_k/top_10_categorical_accuracy: 0.8033 - factorized_top_k/top_15_categorical_accuracy: 0.8365 - factorized_top_k/top_25_categorical_accuracy: 0.8752 - loss: 1969.8511 - regularization_loss: 0.0000e+00 - total_loss: 1969.8511 - val_factorized_top_k/top_3_categorical_accuracy: 0.2735 - val_factorized_top_k/top_5_categorical_accuracy: 0.3627 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6614 - val_loss: 2217.7312 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7312 - lr: 6.0466e-05\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 3s 47ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6502 - factorized_top_k/top_5_categorical_accuracy: 0.7262 - factorized_top_k/top_10_categorical_accuracy: 0.8038 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.3580 - regularization_loss: 0.0000e+00 - total_loss: 1970.3580 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7334 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7334 - lr: 6.0466e-05\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6505 - factorized_top_k/top_5_categorical_accuracy: 0.7267 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8362 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.6019 - regularization_loss: 0.0000e+00 - total_loss: 1970.6019 - val_factorized_top_k/top_3_categorical_accuracy: 0.2689 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7354 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7354 - lr: 6.0466e-05\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6505 - factorized_top_k/top_5_categorical_accuracy: 0.7267 - factorized_top_k/top_10_categorical_accuracy: 0.8038 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1971.0658 - regularization_loss: 0.0000e+00 - total_loss: 1971.0658 - val_factorized_top_k/top_3_categorical_accuracy: 0.2735 - val_factorized_top_k/top_5_categorical_accuracy: 0.3636 - val_factorized_top_k/top_10_categorical_accuracy: 0.4829 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7378 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7378 - lr: 6.0466e-05\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6500 - factorized_top_k/top_5_categorical_accuracy: 0.7267 - factorized_top_k/top_10_categorical_accuracy: 0.8041 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.7666 - regularization_loss: 0.0000e+00 - total_loss: 1970.7666 - val_factorized_top_k/top_3_categorical_accuracy: 0.2703 - val_factorized_top_k/top_5_categorical_accuracy: 0.3558 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.7400 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7400 - lr: 6.0466e-05\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6511 - factorized_top_k/top_5_categorical_accuracy: 0.7267 - factorized_top_k/top_10_categorical_accuracy: 0.8040 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8752 - loss: 1970.1868 - regularization_loss: 0.0000e+00 - total_loss: 1970.1868 - val_factorized_top_k/top_3_categorical_accuracy: 0.2686 - val_factorized_top_k/top_5_categorical_accuracy: 0.3581 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5653 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7410 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7410 - lr: 3.6280e-05\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 3s 46ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6509 - factorized_top_k/top_5_categorical_accuracy: 0.7271 - factorized_top_k/top_10_categorical_accuracy: 0.8036 - factorized_top_k/top_15_categorical_accuracy: 0.8365 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.0556 - regularization_loss: 0.0000e+00 - total_loss: 1970.0556 - val_factorized_top_k/top_3_categorical_accuracy: 0.2709 - val_factorized_top_k/top_5_categorical_accuracy: 0.3572 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7422 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7422 - lr: 3.6280e-05\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 4s 71ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6510 - factorized_top_k/top_5_categorical_accuracy: 0.7271 - factorized_top_k/top_10_categorical_accuracy: 0.8039 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1969.9351 - regularization_loss: 0.0000e+00 - total_loss: 1969.9351 - val_factorized_top_k/top_3_categorical_accuracy: 0.2717 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4806 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7432 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7432 - lr: 3.6280e-05\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 4s 56ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6512 - factorized_top_k/top_5_categorical_accuracy: 0.7268 - factorized_top_k/top_10_categorical_accuracy: 0.8038 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8752 - loss: 1970.5176 - regularization_loss: 0.0000e+00 - total_loss: 1970.5176 - val_factorized_top_k/top_3_categorical_accuracy: 0.2671 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4826 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7446 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7446 - lr: 3.6280e-05\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6513 - factorized_top_k/top_5_categorical_accuracy: 0.7274 - factorized_top_k/top_10_categorical_accuracy: 0.8039 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1969.8628 - regularization_loss: 0.0000e+00 - total_loss: 1969.8628 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3575 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7456 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7456 - lr: 3.6280e-05\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6515 - factorized_top_k/top_5_categorical_accuracy: 0.7273 - factorized_top_k/top_10_categorical_accuracy: 0.8039 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1969.5999 - regularization_loss: 0.0000e+00 - total_loss: 1969.5999 - val_factorized_top_k/top_3_categorical_accuracy: 0.2712 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6648 - val_loss: 2217.7468 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7468 - lr: 3.6280e-05\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6513 - factorized_top_k/top_5_categorical_accuracy: 0.7267 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8365 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1969.6046 - regularization_loss: 0.0000e+00 - total_loss: 1969.6046 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4801 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7483 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7483 - lr: 3.6280e-05\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6507 - factorized_top_k/top_5_categorical_accuracy: 0.7271 - factorized_top_k/top_10_categorical_accuracy: 0.8038 - factorized_top_k/top_15_categorical_accuracy: 0.8367 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.0109 - regularization_loss: 0.0000e+00 - total_loss: 1970.0109 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3587 - val_factorized_top_k/top_10_categorical_accuracy: 0.4792 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.7493 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7493 - lr: 3.6280e-05\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6511 - factorized_top_k/top_5_categorical_accuracy: 0.7269 - factorized_top_k/top_10_categorical_accuracy: 0.8038 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1970.3842 - regularization_loss: 0.0000e+00 - total_loss: 1970.3842 - val_factorized_top_k/top_3_categorical_accuracy: 0.2717 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4801 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7502 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7502 - lr: 3.6280e-05\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6515 - factorized_top_k/top_5_categorical_accuracy: 0.7281 - factorized_top_k/top_10_categorical_accuracy: 0.8040 - factorized_top_k/top_15_categorical_accuracy: 0.8368 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1969.5886 - regularization_loss: 0.0000e+00 - total_loss: 1969.5886 - val_factorized_top_k/top_3_categorical_accuracy: 0.2712 - val_factorized_top_k/top_5_categorical_accuracy: 0.3572 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7507 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7507 - lr: 2.1768e-05\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6523 - factorized_top_k/top_5_categorical_accuracy: 0.7276 - factorized_top_k/top_10_categorical_accuracy: 0.8040 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.3493 - regularization_loss: 0.0000e+00 - total_loss: 1970.3493 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3567 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7515 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7515 - lr: 2.1768e-05\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6525 - factorized_top_k/top_5_categorical_accuracy: 0.7281 - factorized_top_k/top_10_categorical_accuracy: 0.8039 - factorized_top_k/top_15_categorical_accuracy: 0.8367 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1969.7421 - regularization_loss: 0.0000e+00 - total_loss: 1969.7421 - val_factorized_top_k/top_3_categorical_accuracy: 0.2723 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7524 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7524 - lr: 2.1768e-05\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6522 - factorized_top_k/top_5_categorical_accuracy: 0.7277 - factorized_top_k/top_10_categorical_accuracy: 0.8037 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.3226 - regularization_loss: 0.0000e+00 - total_loss: 1970.3226 - val_factorized_top_k/top_3_categorical_accuracy: 0.2694 - val_factorized_top_k/top_5_categorical_accuracy: 0.3575 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7529 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7529 - lr: 2.1768e-05\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6530 - factorized_top_k/top_5_categorical_accuracy: 0.7277 - factorized_top_k/top_10_categorical_accuracy: 0.8042 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.1014 - regularization_loss: 0.0000e+00 - total_loss: 1970.1014 - val_factorized_top_k/top_3_categorical_accuracy: 0.2746 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7534 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7534 - lr: 2.1768e-05\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6523 - factorized_top_k/top_5_categorical_accuracy: 0.7277 - factorized_top_k/top_10_categorical_accuracy: 0.8040 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1969.9908 - regularization_loss: 0.0000e+00 - total_loss: 1969.9908 - val_factorized_top_k/top_3_categorical_accuracy: 0.2689 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7544 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7544 - lr: 2.1768e-05\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6525 - factorized_top_k/top_5_categorical_accuracy: 0.7275 - factorized_top_k/top_10_categorical_accuracy: 0.8039 - factorized_top_k/top_15_categorical_accuracy: 0.8364 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.3065 - regularization_loss: 0.0000e+00 - total_loss: 1970.3065 - val_factorized_top_k/top_3_categorical_accuracy: 0.2689 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6617 - val_loss: 2217.7549 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7549 - lr: 2.1768e-05\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6524 - factorized_top_k/top_5_categorical_accuracy: 0.7275 - factorized_top_k/top_10_categorical_accuracy: 0.8041 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1970.1941 - regularization_loss: 0.0000e+00 - total_loss: 1970.1941 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7556 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7556 - lr: 2.1768e-05\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6529 - factorized_top_k/top_5_categorical_accuracy: 0.7280 - factorized_top_k/top_10_categorical_accuracy: 0.8040 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.1303 - regularization_loss: 0.0000e+00 - total_loss: 1970.1303 - val_factorized_top_k/top_3_categorical_accuracy: 0.2752 - val_factorized_top_k/top_5_categorical_accuracy: 0.3610 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6623 - val_loss: 2217.7566 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7566 - lr: 2.1768e-05\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6564 - factorized_top_k/top_5_categorical_accuracy: 0.7289 - factorized_top_k/top_10_categorical_accuracy: 0.8041 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1969.7982 - regularization_loss: 0.0000e+00 - total_loss: 1969.7982 - val_factorized_top_k/top_3_categorical_accuracy: 0.2737 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7566 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7566 - lr: 1.3061e-05\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6546 - factorized_top_k/top_5_categorical_accuracy: 0.7288 - factorized_top_k/top_10_categorical_accuracy: 0.8040 - factorized_top_k/top_15_categorical_accuracy: 0.8368 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1969.4522 - regularization_loss: 0.0000e+00 - total_loss: 1969.4522 - val_factorized_top_k/top_3_categorical_accuracy: 0.2683 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7571 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7571 - lr: 1.3061e-05\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6560 - factorized_top_k/top_5_categorical_accuracy: 0.7292 - factorized_top_k/top_10_categorical_accuracy: 0.8041 - factorized_top_k/top_15_categorical_accuracy: 0.8368 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1969.9192 - regularization_loss: 0.0000e+00 - total_loss: 1969.9192 - val_factorized_top_k/top_3_categorical_accuracy: 0.2743 - val_factorized_top_k/top_5_categorical_accuracy: 0.3598 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.7573 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7573 - lr: 1.3061e-05\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6556 - factorized_top_k/top_5_categorical_accuracy: 0.7293 - factorized_top_k/top_10_categorical_accuracy: 0.8043 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8754 - loss: 1970.3224 - regularization_loss: 0.0000e+00 - total_loss: 1970.3224 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.7578 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7578 - lr: 1.3061e-05\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6558 - factorized_top_k/top_5_categorical_accuracy: 0.7292 - factorized_top_k/top_10_categorical_accuracy: 0.8041 - factorized_top_k/top_15_categorical_accuracy: 0.8367 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1970.1603 - regularization_loss: 0.0000e+00 - total_loss: 1970.1603 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7583 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7583 - lr: 1.3061e-05\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6549 - factorized_top_k/top_5_categorical_accuracy: 0.7287 - factorized_top_k/top_10_categorical_accuracy: 0.8042 - factorized_top_k/top_15_categorical_accuracy: 0.8367 - factorized_top_k/top_25_categorical_accuracy: 0.8756 - loss: 1969.2021 - regularization_loss: 0.0000e+00 - total_loss: 1969.2021 - val_factorized_top_k/top_3_categorical_accuracy: 0.2706 - val_factorized_top_k/top_5_categorical_accuracy: 0.3615 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7585 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7585 - lr: 1.3061e-05\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6552 - factorized_top_k/top_5_categorical_accuracy: 0.7289 - factorized_top_k/top_10_categorical_accuracy: 0.8041 - factorized_top_k/top_15_categorical_accuracy: 0.8369 - factorized_top_k/top_25_categorical_accuracy: 0.8753 - loss: 1970.4680 - regularization_loss: 0.0000e+00 - total_loss: 1970.4680 - val_factorized_top_k/top_3_categorical_accuracy: 0.2723 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4829 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7588 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7588 - lr: 1.3061e-05\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6557 - factorized_top_k/top_5_categorical_accuracy: 0.7300 - factorized_top_k/top_10_categorical_accuracy: 0.8039 - factorized_top_k/top_15_categorical_accuracy: 0.8366 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1969.6786 - regularization_loss: 0.0000e+00 - total_loss: 1969.6786 - val_factorized_top_k/top_3_categorical_accuracy: 0.2680 - val_factorized_top_k/top_5_categorical_accuracy: 0.3581 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5618 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7593 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7593 - lr: 1.3061e-05\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6552 - factorized_top_k/top_5_categorical_accuracy: 0.7292 - factorized_top_k/top_10_categorical_accuracy: 0.8042 - factorized_top_k/top_15_categorical_accuracy: 0.8365 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1970.6037 - regularization_loss: 0.0000e+00 - total_loss: 1970.6037 - val_factorized_top_k/top_3_categorical_accuracy: 0.2694 - val_factorized_top_k/top_5_categorical_accuracy: 0.3572 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7598 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7598 - lr: 1.3061e-05\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6622 - factorized_top_k/top_5_categorical_accuracy: 0.7308 - factorized_top_k/top_10_categorical_accuracy: 0.8048 - factorized_top_k/top_15_categorical_accuracy: 0.8373 - factorized_top_k/top_25_categorical_accuracy: 0.8756 - loss: 1969.7569 - regularization_loss: 0.0000e+00 - total_loss: 1969.7569 - val_factorized_top_k/top_3_categorical_accuracy: 0.2657 - val_factorized_top_k/top_5_categorical_accuracy: 0.3564 - val_factorized_top_k/top_10_categorical_accuracy: 0.4801 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7600 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7600 - lr: 7.8364e-06\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6606 - factorized_top_k/top_5_categorical_accuracy: 0.7319 - factorized_top_k/top_10_categorical_accuracy: 0.8048 - factorized_top_k/top_15_categorical_accuracy: 0.8369 - factorized_top_k/top_25_categorical_accuracy: 0.8757 - loss: 1969.3890 - regularization_loss: 0.0000e+00 - total_loss: 1969.3890 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7603 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7603 - lr: 7.8364e-06\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6617 - factorized_top_k/top_5_categorical_accuracy: 0.7312 - factorized_top_k/top_10_categorical_accuracy: 0.8046 - factorized_top_k/top_15_categorical_accuracy: 0.8373 - factorized_top_k/top_25_categorical_accuracy: 0.8756 - loss: 1969.7653 - regularization_loss: 0.0000e+00 - total_loss: 1969.7653 - val_factorized_top_k/top_3_categorical_accuracy: 0.2712 - val_factorized_top_k/top_5_categorical_accuracy: 0.3615 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.7603 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7603 - lr: 7.8364e-06\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6619 - factorized_top_k/top_5_categorical_accuracy: 0.7308 - factorized_top_k/top_10_categorical_accuracy: 0.8043 - factorized_top_k/top_15_categorical_accuracy: 0.8371 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1969.5334 - regularization_loss: 0.0000e+00 - total_loss: 1969.5334 - val_factorized_top_k/top_3_categorical_accuracy: 0.2677 - val_factorized_top_k/top_5_categorical_accuracy: 0.3570 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7607 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7607 - lr: 7.8364e-06\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6615 - factorized_top_k/top_5_categorical_accuracy: 0.7313 - factorized_top_k/top_10_categorical_accuracy: 0.8054 - factorized_top_k/top_15_categorical_accuracy: 0.8371 - factorized_top_k/top_25_categorical_accuracy: 0.8756 - loss: 1969.6266 - regularization_loss: 0.0000e+00 - total_loss: 1969.6266 - val_factorized_top_k/top_3_categorical_accuracy: 0.2683 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7607 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7607 - lr: 7.8364e-06\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6624 - factorized_top_k/top_5_categorical_accuracy: 0.7313 - factorized_top_k/top_10_categorical_accuracy: 0.8051 - factorized_top_k/top_15_categorical_accuracy: 0.8370 - factorized_top_k/top_25_categorical_accuracy: 0.8757 - loss: 1970.2224 - regularization_loss: 0.0000e+00 - total_loss: 1970.2224 - val_factorized_top_k/top_3_categorical_accuracy: 0.2706 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7612 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7612 - lr: 7.8364e-06\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6610 - factorized_top_k/top_5_categorical_accuracy: 0.7319 - factorized_top_k/top_10_categorical_accuracy: 0.8051 - factorized_top_k/top_15_categorical_accuracy: 0.8371 - factorized_top_k/top_25_categorical_accuracy: 0.8757 - loss: 1969.7486 - regularization_loss: 0.0000e+00 - total_loss: 1969.7486 - val_factorized_top_k/top_3_categorical_accuracy: 0.2694 - val_factorized_top_k/top_5_categorical_accuracy: 0.3581 - val_factorized_top_k/top_10_categorical_accuracy: 0.4806 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7612 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7612 - lr: 7.8364e-06\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6607 - factorized_top_k/top_5_categorical_accuracy: 0.7307 - factorized_top_k/top_10_categorical_accuracy: 0.8047 - factorized_top_k/top_15_categorical_accuracy: 0.8369 - factorized_top_k/top_25_categorical_accuracy: 0.8755 - loss: 1969.7269 - regularization_loss: 0.0000e+00 - total_loss: 1969.7269 - val_factorized_top_k/top_3_categorical_accuracy: 0.2692 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7617 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7617 - lr: 7.8364e-06\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6617 - factorized_top_k/top_5_categorical_accuracy: 0.7314 - factorized_top_k/top_10_categorical_accuracy: 0.8047 - factorized_top_k/top_15_categorical_accuracy: 0.8368 - factorized_top_k/top_25_categorical_accuracy: 0.8758 - loss: 1969.8982 - regularization_loss: 0.0000e+00 - total_loss: 1969.8982 - val_factorized_top_k/top_3_categorical_accuracy: 0.2717 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4826 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7617 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7617 - lr: 7.8364e-06\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6682 - factorized_top_k/top_5_categorical_accuracy: 0.7350 - factorized_top_k/top_10_categorical_accuracy: 0.8059 - factorized_top_k/top_15_categorical_accuracy: 0.8375 - factorized_top_k/top_25_categorical_accuracy: 0.8761 - loss: 1969.5534 - regularization_loss: 0.0000e+00 - total_loss: 1969.5534 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7620 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7620 - lr: 4.7018e-06\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6696 - factorized_top_k/top_5_categorical_accuracy: 0.7347 - factorized_top_k/top_10_categorical_accuracy: 0.8059 - factorized_top_k/top_15_categorical_accuracy: 0.8376 - factorized_top_k/top_25_categorical_accuracy: 0.8759 - loss: 1969.5170 - regularization_loss: 0.0000e+00 - total_loss: 1969.5170 - val_factorized_top_k/top_3_categorical_accuracy: 0.2694 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7620 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7620 - lr: 4.7018e-06\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 3s 42ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6694 - factorized_top_k/top_5_categorical_accuracy: 0.7344 - factorized_top_k/top_10_categorical_accuracy: 0.8058 - factorized_top_k/top_15_categorical_accuracy: 0.8376 - factorized_top_k/top_25_categorical_accuracy: 0.8760 - loss: 1969.4833 - regularization_loss: 0.0000e+00 - total_loss: 1969.4833 - val_factorized_top_k/top_3_categorical_accuracy: 0.2717 - val_factorized_top_k/top_5_categorical_accuracy: 0.3590 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7620 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7620 - lr: 4.7018e-06\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6693 - factorized_top_k/top_5_categorical_accuracy: 0.7346 - factorized_top_k/top_10_categorical_accuracy: 0.8060 - factorized_top_k/top_15_categorical_accuracy: 0.8376 - factorized_top_k/top_25_categorical_accuracy: 0.8760 - loss: 1969.8737 - regularization_loss: 0.0000e+00 - total_loss: 1969.8737 - val_factorized_top_k/top_3_categorical_accuracy: 0.2714 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5624 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7622 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7622 - lr: 4.7018e-06\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6693 - factorized_top_k/top_5_categorical_accuracy: 0.7355 - factorized_top_k/top_10_categorical_accuracy: 0.8055 - factorized_top_k/top_15_categorical_accuracy: 0.8376 - factorized_top_k/top_25_categorical_accuracy: 0.8760 - loss: 1970.3421 - regularization_loss: 0.0000e+00 - total_loss: 1970.3421 - val_factorized_top_k/top_3_categorical_accuracy: 0.2680 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.7622 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7622 - lr: 4.7018e-06\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6693 - factorized_top_k/top_5_categorical_accuracy: 0.7349 - factorized_top_k/top_10_categorical_accuracy: 0.8063 - factorized_top_k/top_15_categorical_accuracy: 0.8379 - factorized_top_k/top_25_categorical_accuracy: 0.8758 - loss: 1969.6530 - regularization_loss: 0.0000e+00 - total_loss: 1969.6530 - val_factorized_top_k/top_3_categorical_accuracy: 0.2646 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.7625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7625 - lr: 4.7018e-06\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6694 - factorized_top_k/top_5_categorical_accuracy: 0.7351 - factorized_top_k/top_10_categorical_accuracy: 0.8059 - factorized_top_k/top_15_categorical_accuracy: 0.8378 - factorized_top_k/top_25_categorical_accuracy: 0.8759 - loss: 1969.5300 - regularization_loss: 0.0000e+00 - total_loss: 1969.5300 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3627 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7625 - lr: 4.7018e-06\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6697 - factorized_top_k/top_5_categorical_accuracy: 0.7346 - factorized_top_k/top_10_categorical_accuracy: 0.8062 - factorized_top_k/top_15_categorical_accuracy: 0.8376 - factorized_top_k/top_25_categorical_accuracy: 0.8757 - loss: 1969.6729 - regularization_loss: 0.0000e+00 - total_loss: 1969.6729 - val_factorized_top_k/top_3_categorical_accuracy: 0.2692 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7625 - lr: 4.7018e-06\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6694 - factorized_top_k/top_5_categorical_accuracy: 0.7351 - factorized_top_k/top_10_categorical_accuracy: 0.8059 - factorized_top_k/top_15_categorical_accuracy: 0.8376 - factorized_top_k/top_25_categorical_accuracy: 0.8758 - loss: 1969.7067 - regularization_loss: 0.0000e+00 - total_loss: 1969.7067 - val_factorized_top_k/top_3_categorical_accuracy: 0.2746 - val_factorized_top_k/top_5_categorical_accuracy: 0.3633 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5630 - val_factorized_top_k/top_25_categorical_accuracy: 0.6646 - val_loss: 2217.7625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7625 - lr: 4.7018e-06\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 5s 72ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6777 - factorized_top_k/top_5_categorical_accuracy: 0.7388 - factorized_top_k/top_10_categorical_accuracy: 0.8071 - factorized_top_k/top_15_categorical_accuracy: 0.8390 - factorized_top_k/top_25_categorical_accuracy: 0.8765 - loss: 1970.0422 - regularization_loss: 0.0000e+00 - total_loss: 1970.0422 - val_factorized_top_k/top_3_categorical_accuracy: 0.2686 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4806 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7627 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7627 - lr: 2.8211e-06\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 3s 51ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6765 - factorized_top_k/top_5_categorical_accuracy: 0.7392 - factorized_top_k/top_10_categorical_accuracy: 0.8070 - factorized_top_k/top_15_categorical_accuracy: 0.8388 - factorized_top_k/top_25_categorical_accuracy: 0.8764 - loss: 1969.5801 - regularization_loss: 0.0000e+00 - total_loss: 1969.5801 - val_factorized_top_k/top_3_categorical_accuracy: 0.2737 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5650 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7625 - lr: 2.8211e-06\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6759 - factorized_top_k/top_5_categorical_accuracy: 0.7390 - factorized_top_k/top_10_categorical_accuracy: 0.8078 - factorized_top_k/top_15_categorical_accuracy: 0.8392 - factorized_top_k/top_25_categorical_accuracy: 0.8763 - loss: 1969.8699 - regularization_loss: 0.0000e+00 - total_loss: 1969.8699 - val_factorized_top_k/top_3_categorical_accuracy: 0.2732 - val_factorized_top_k/top_5_categorical_accuracy: 0.3615 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7627 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7627 - lr: 2.8211e-06\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6768 - factorized_top_k/top_5_categorical_accuracy: 0.7392 - factorized_top_k/top_10_categorical_accuracy: 0.8077 - factorized_top_k/top_15_categorical_accuracy: 0.8387 - factorized_top_k/top_25_categorical_accuracy: 0.8765 - loss: 1970.4097 - regularization_loss: 0.0000e+00 - total_loss: 1970.4097 - val_factorized_top_k/top_3_categorical_accuracy: 0.2740 - val_factorized_top_k/top_5_categorical_accuracy: 0.3593 - val_factorized_top_k/top_10_categorical_accuracy: 0.4826 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7627 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7627 - lr: 2.8211e-06\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6768 - factorized_top_k/top_5_categorical_accuracy: 0.7385 - factorized_top_k/top_10_categorical_accuracy: 0.8074 - factorized_top_k/top_15_categorical_accuracy: 0.8388 - factorized_top_k/top_25_categorical_accuracy: 0.8765 - loss: 1969.5589 - regularization_loss: 0.0000e+00 - total_loss: 1969.5589 - val_factorized_top_k/top_3_categorical_accuracy: 0.2694 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4818 - val_factorized_top_k/top_15_categorical_accuracy: 0.5636 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7627 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7627 - lr: 2.8211e-06\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6760 - factorized_top_k/top_5_categorical_accuracy: 0.7386 - factorized_top_k/top_10_categorical_accuracy: 0.8076 - factorized_top_k/top_15_categorical_accuracy: 0.8390 - factorized_top_k/top_25_categorical_accuracy: 0.8763 - loss: 1969.5571 - regularization_loss: 0.0000e+00 - total_loss: 1969.5571 - val_factorized_top_k/top_3_categorical_accuracy: 0.2720 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7627 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7627 - lr: 2.8211e-06\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6765 - factorized_top_k/top_5_categorical_accuracy: 0.7390 - factorized_top_k/top_10_categorical_accuracy: 0.8071 - factorized_top_k/top_15_categorical_accuracy: 0.8388 - factorized_top_k/top_25_categorical_accuracy: 0.8763 - loss: 1969.5926 - regularization_loss: 0.0000e+00 - total_loss: 1969.5926 - val_factorized_top_k/top_3_categorical_accuracy: 0.2740 - val_factorized_top_k/top_5_categorical_accuracy: 0.3615 - val_factorized_top_k/top_10_categorical_accuracy: 0.4806 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7627 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7627 - lr: 2.8211e-06\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6770 - factorized_top_k/top_5_categorical_accuracy: 0.7396 - factorized_top_k/top_10_categorical_accuracy: 0.8074 - factorized_top_k/top_15_categorical_accuracy: 0.8387 - factorized_top_k/top_25_categorical_accuracy: 0.8763 - loss: 1970.2518 - regularization_loss: 0.0000e+00 - total_loss: 1970.2518 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3630 - val_factorized_top_k/top_10_categorical_accuracy: 0.4812 - val_factorized_top_k/top_15_categorical_accuracy: 0.5633 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7629 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7629 - lr: 2.8211e-06\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6770 - factorized_top_k/top_5_categorical_accuracy: 0.7391 - factorized_top_k/top_10_categorical_accuracy: 0.8073 - factorized_top_k/top_15_categorical_accuracy: 0.8389 - factorized_top_k/top_25_categorical_accuracy: 0.8766 - loss: 1969.9809 - regularization_loss: 0.0000e+00 - total_loss: 1969.9809 - val_factorized_top_k/top_3_categorical_accuracy: 0.2654 - val_factorized_top_k/top_5_categorical_accuracy: 0.3578 - val_factorized_top_k/top_10_categorical_accuracy: 0.4795 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7627 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7627 - lr: 2.8211e-06\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6802 - factorized_top_k/top_5_categorical_accuracy: 0.7412 - factorized_top_k/top_10_categorical_accuracy: 0.8082 - factorized_top_k/top_15_categorical_accuracy: 0.8401 - factorized_top_k/top_25_categorical_accuracy: 0.8771 - loss: 1969.7569 - regularization_loss: 0.0000e+00 - total_loss: 1969.7569 - val_factorized_top_k/top_3_categorical_accuracy: 0.2729 - val_factorized_top_k/top_5_categorical_accuracy: 0.3601 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5647 - val_factorized_top_k/top_25_categorical_accuracy: 0.6643 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6815 - factorized_top_k/top_5_categorical_accuracy: 0.7408 - factorized_top_k/top_10_categorical_accuracy: 0.8082 - factorized_top_k/top_15_categorical_accuracy: 0.8398 - factorized_top_k/top_25_categorical_accuracy: 0.8772 - loss: 1969.3789 - regularization_loss: 0.0000e+00 - total_loss: 1969.3789 - val_factorized_top_k/top_3_categorical_accuracy: 0.2671 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6796 - factorized_top_k/top_5_categorical_accuracy: 0.7407 - factorized_top_k/top_10_categorical_accuracy: 0.8084 - factorized_top_k/top_15_categorical_accuracy: 0.8394 - factorized_top_k/top_25_categorical_accuracy: 0.8773 - loss: 1970.1955 - regularization_loss: 0.0000e+00 - total_loss: 1970.1955 - val_factorized_top_k/top_3_categorical_accuracy: 0.2686 - val_factorized_top_k/top_5_categorical_accuracy: 0.3610 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 3s 44ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6816 - factorized_top_k/top_5_categorical_accuracy: 0.7411 - factorized_top_k/top_10_categorical_accuracy: 0.8083 - factorized_top_k/top_15_categorical_accuracy: 0.8397 - factorized_top_k/top_25_categorical_accuracy: 0.8770 - loss: 1969.9086 - regularization_loss: 0.0000e+00 - total_loss: 1969.9086 - val_factorized_top_k/top_3_categorical_accuracy: 0.2680 - val_factorized_top_k/top_5_categorical_accuracy: 0.3581 - val_factorized_top_k/top_10_categorical_accuracy: 0.4809 - val_factorized_top_k/top_15_categorical_accuracy: 0.5627 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6808 - factorized_top_k/top_5_categorical_accuracy: 0.7409 - factorized_top_k/top_10_categorical_accuracy: 0.8087 - factorized_top_k/top_15_categorical_accuracy: 0.8398 - factorized_top_k/top_25_categorical_accuracy: 0.8771 - loss: 1969.7396 - regularization_loss: 0.0000e+00 - total_loss: 1969.7396 - val_factorized_top_k/top_3_categorical_accuracy: 0.2709 - val_factorized_top_k/top_5_categorical_accuracy: 0.3581 - val_factorized_top_k/top_10_categorical_accuracy: 0.4798 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6637 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6820 - factorized_top_k/top_5_categorical_accuracy: 0.7408 - factorized_top_k/top_10_categorical_accuracy: 0.8081 - factorized_top_k/top_15_categorical_accuracy: 0.8397 - factorized_top_k/top_25_categorical_accuracy: 0.8773 - loss: 1969.9556 - regularization_loss: 0.0000e+00 - total_loss: 1969.9556 - val_factorized_top_k/top_3_categorical_accuracy: 0.2694 - val_factorized_top_k/top_5_categorical_accuracy: 0.3595 - val_factorized_top_k/top_10_categorical_accuracy: 0.4803 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 3s 45ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6816 - factorized_top_k/top_5_categorical_accuracy: 0.7409 - factorized_top_k/top_10_categorical_accuracy: 0.8087 - factorized_top_k/top_15_categorical_accuracy: 0.8401 - factorized_top_k/top_25_categorical_accuracy: 0.8769 - loss: 1969.4371 - regularization_loss: 0.0000e+00 - total_loss: 1969.4371 - val_factorized_top_k/top_3_categorical_accuracy: 0.2717 - val_factorized_top_k/top_5_categorical_accuracy: 0.3604 - val_factorized_top_k/top_10_categorical_accuracy: 0.4824 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6634 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6814 - factorized_top_k/top_5_categorical_accuracy: 0.7408 - factorized_top_k/top_10_categorical_accuracy: 0.8085 - factorized_top_k/top_15_categorical_accuracy: 0.8400 - factorized_top_k/top_25_categorical_accuracy: 0.8769 - loss: 1970.6315 - regularization_loss: 0.0000e+00 - total_loss: 1970.6315 - val_factorized_top_k/top_3_categorical_accuracy: 0.2697 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5644 - val_factorized_top_k/top_25_categorical_accuracy: 0.6628 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6802 - factorized_top_k/top_5_categorical_accuracy: 0.7410 - factorized_top_k/top_10_categorical_accuracy: 0.8085 - factorized_top_k/top_15_categorical_accuracy: 0.8398 - factorized_top_k/top_25_categorical_accuracy: 0.8770 - loss: 1969.8214 - regularization_loss: 0.0000e+00 - total_loss: 1969.8214 - val_factorized_top_k/top_3_categorical_accuracy: 0.2700 - val_factorized_top_k/top_5_categorical_accuracy: 0.3584 - val_factorized_top_k/top_10_categorical_accuracy: 0.4815 - val_factorized_top_k/top_15_categorical_accuracy: 0.5641 - val_factorized_top_k/top_25_categorical_accuracy: 0.6631 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.6927e-06\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6854 - factorized_top_k/top_5_categorical_accuracy: 0.7425 - factorized_top_k/top_10_categorical_accuracy: 0.8086 - factorized_top_k/top_15_categorical_accuracy: 0.8401 - factorized_top_k/top_25_categorical_accuracy: 0.8774 - loss: 1969.5129 - regularization_loss: 0.0000e+00 - total_loss: 1969.5129 - val_factorized_top_k/top_3_categorical_accuracy: 0.2697 - val_factorized_top_k/top_5_categorical_accuracy: 0.3607 - val_factorized_top_k/top_10_categorical_accuracy: 0.4821 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6640 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.0156e-06\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 3s 43ms/step - factorized_top_k/top_3_categorical_accuracy: 0.6848 - factorized_top_k/top_5_categorical_accuracy: 0.7422 - factorized_top_k/top_10_categorical_accuracy: 0.8086 - factorized_top_k/top_15_categorical_accuracy: 0.8404 - factorized_top_k/top_25_categorical_accuracy: 0.8775 - loss: 1969.4257 - regularization_loss: 0.0000e+00 - total_loss: 1969.4257 - val_factorized_top_k/top_3_categorical_accuracy: 0.2706 - val_factorized_top_k/top_5_categorical_accuracy: 0.3621 - val_factorized_top_k/top_10_categorical_accuracy: 0.4801 - val_factorized_top_k/top_15_categorical_accuracy: 0.5638 - val_factorized_top_k/top_25_categorical_accuracy: 0.6626 - val_loss: 2217.7632 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.7632 - lr: 1.0156e-06\n"
     ]
    }
   ],
   "source": [
    "data = model.fi>Lt(cached_train,\n",
    "          validation_data=cached_test,\n",
    "          epochs=200,\n",
    "          verbose=1, \n",
    "          workers=3,\n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[model_checkpoint_callback, \n",
    "                     reduce_lr]\n",
    "\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c91798a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4adc701550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"new_amazon_check_points/best_check_point_25k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40d04cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 40ms/step - factorized_top_k/top_3_categorical_accuracy: 0.2422 - factorized_top_k/top_5_categorical_accuracy: 0.3549 - factorized_top_k/top_10_categorical_accuracy: 0.4878 - factorized_top_k/top_15_categorical_accuracy: 0.5727 - factorized_top_k/top_25_categorical_accuracy: 0.6714 - loss: 2763.7692 - regularization_loss: 0.0000e+00 - total_loss: 2763.7692\n"
     ]
    }
   ],
   "source": [
    "result_summary = model.evaluate(cached_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "215d3fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.24218077957630157,\n",
       " 5: 0.3549497723579407,\n",
       " 10: 0.4878048896789551,\n",
       " 15: 0.5727403163909912,\n",
       " 25: 0.6714490652084351}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{val:result_summary[idx] for idx, val in enumerate([3, 5, 10,15, 25]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ee8552d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_3_categorical_accuracy': [0.08253633975982666,\n",
       "  0.10118592530488968,\n",
       "  0.10402321070432663,\n",
       "  0.10542590916156769,\n",
       "  0.10663733631372452,\n",
       "  0.109251469373703,\n",
       "  0.11667941510677338,\n",
       "  0.12621141970157623,\n",
       "  0.13402193784713745,\n",
       "  0.1408441662788391,\n",
       "  0.1502486616373062,\n",
       "  0.15876051783561707,\n",
       "  0.1692807972431183,\n",
       "  0.18187324702739716,\n",
       "  0.19857816398143768,\n",
       "  0.21557000279426575,\n",
       "  0.2317010909318924,\n",
       "  0.24926677346229553,\n",
       "  0.26919153332710266,\n",
       "  0.2866934537887573,\n",
       "  0.3071601688861847,\n",
       "  0.32303622364997864,\n",
       "  0.3393267095088959,\n",
       "  0.35421448945999146,\n",
       "  0.36597806215286255,\n",
       "  0.3786342740058899,\n",
       "  0.3910035789012909,\n",
       "  0.4014919698238373,\n",
       "  0.41510456800460815,\n",
       "  0.42654934525489807,\n",
       "  0.4374203085899353,\n",
       "  0.44797244668006897,\n",
       "  0.45887529850006104,\n",
       "  0.46945932507514954,\n",
       "  0.4814460575580597,\n",
       "  0.49199822545051575,\n",
       "  0.5022315979003906,\n",
       "  0.5131981372833252,\n",
       "  0.5230489373207092,\n",
       "  0.5307638645172119,\n",
       "  0.5387656092643738,\n",
       "  0.547596275806427,\n",
       "  0.5551517605781555,\n",
       "  0.562292754650116,\n",
       "  0.5697207450866699,\n",
       "  0.5778500437736511,\n",
       "  0.581962525844574,\n",
       "  0.5862343907356262,\n",
       "  0.5893904566764832,\n",
       "  0.5928653478622437,\n",
       "  0.5975516438484192,\n",
       "  0.6008989810943604,\n",
       "  0.6048839688301086,\n",
       "  0.608900785446167,\n",
       "  0.6121206283569336,\n",
       "  0.6137464642524719,\n",
       "  0.6156592965126038,\n",
       "  0.6174764037132263,\n",
       "  0.6191022992134094,\n",
       "  0.6207919120788574,\n",
       "  0.6235335469245911,\n",
       "  0.6240435838699341,\n",
       "  0.6273272037506104,\n",
       "  0.6281560659408569,\n",
       "  0.630068838596344,\n",
       "  0.6296225190162659,\n",
       "  0.6311846375465393,\n",
       "  0.632938027381897,\n",
       "  0.6329699158668518,\n",
       "  0.6343088746070862,\n",
       "  0.6354246139526367,\n",
       "  0.6360622048377991,\n",
       "  0.6377837061882019,\n",
       "  0.6380706429481506,\n",
       "  0.6383894681930542,\n",
       "  0.6391226649284363,\n",
       "  0.6398240327835083,\n",
       "  0.6403340697288513,\n",
       "  0.6408122777938843,\n",
       "  0.6417686939239502,\n",
       "  0.642310619354248,\n",
       "  0.6428526043891907,\n",
       "  0.6432989239692688,\n",
       "  0.6433945298194885,\n",
       "  0.6438408493995667,\n",
       "  0.6445422172546387,\n",
       "  0.6446059942245483,\n",
       "  0.644956648349762,\n",
       "  0.6459767818450928,\n",
       "  0.6461043357849121,\n",
       "  0.6461999416351318,\n",
       "  0.64664626121521,\n",
       "  0.6460724472999573,\n",
       "  0.6472200751304626,\n",
       "  0.6469650864601135,\n",
       "  0.6464231014251709,\n",
       "  0.6461361646652222,\n",
       "  0.6471882462501526,\n",
       "  0.6472838521003723,\n",
       "  0.6472519636154175,\n",
       "  0.6477939486503601,\n",
       "  0.6479533314704895,\n",
       "  0.6479214429855347,\n",
       "  0.6479214429855347,\n",
       "  0.648335874080658,\n",
       "  0.648559033870697,\n",
       "  0.6474113464355469,\n",
       "  0.6485271453857422,\n",
       "  0.6485909223556519,\n",
       "  0.648335874080658,\n",
       "  0.6495154500007629,\n",
       "  0.6492922902107239,\n",
       "  0.6490691304206848,\n",
       "  0.6496748328208923,\n",
       "  0.6493878960609436,\n",
       "  0.6489096879959106,\n",
       "  0.6503443121910095,\n",
       "  0.6497067213058472,\n",
       "  0.649260401725769,\n",
       "  0.6499935984611511,\n",
       "  0.6502167582511902,\n",
       "  0.64903724193573,\n",
       "  0.650025486946106,\n",
       "  0.6498661041259766,\n",
       "  0.6493878960609436,\n",
       "  0.6493241786956787,\n",
       "  0.6505036950111389,\n",
       "  0.6508543491363525,\n",
       "  0.6500573754310608,\n",
       "  0.6503762006759644,\n",
       "  0.6495154500007629,\n",
       "  0.650248646736145,\n",
       "  0.6504718065261841,\n",
       "  0.6505036950111389,\n",
       "  0.650025486946106,\n",
       "  0.6511093974113464,\n",
       "  0.6508862376213074,\n",
       "  0.6510137915611267,\n",
       "  0.6511731743812561,\n",
       "  0.6513006687164307,\n",
       "  0.6514919400215149,\n",
       "  0.6513006687164307,\n",
       "  0.6506949663162231,\n",
       "  0.6510775089263916,\n",
       "  0.6515238285064697,\n",
       "  0.6523208618164062,\n",
       "  0.6525440216064453,\n",
       "  0.6521933078765869,\n",
       "  0.6530221700668335,\n",
       "  0.6522889733314514,\n",
       "  0.6525440216064453,\n",
       "  0.6523526906967163,\n",
       "  0.6528627872467041,\n",
       "  0.6563695669174194,\n",
       "  0.6545842885971069,\n",
       "  0.6559551358222961,\n",
       "  0.6556363105773926,\n",
       "  0.6558275818824768,\n",
       "  0.6548712253570557,\n",
       "  0.6551899909973145,\n",
       "  0.6556681990623474,\n",
       "  0.6552218794822693,\n",
       "  0.6621716618537903,\n",
       "  0.6606414318084717,\n",
       "  0.6616934537887573,\n",
       "  0.6619485020637512,\n",
       "  0.6615021824836731,\n",
       "  0.6624266505241394,\n",
       "  0.6609601974487305,\n",
       "  0.6606733202934265,\n",
       "  0.6616934537887573,\n",
       "  0.6681650280952454,\n",
       "  0.6695995926856995,\n",
       "  0.6693764328956604,\n",
       "  0.6693445444107056,\n",
       "  0.6692807674407959,\n",
       "  0.6693445444107056,\n",
       "  0.6694083213806152,\n",
       "  0.669727087020874,\n",
       "  0.6694083213806152,\n",
       "  0.677665114402771,\n",
       "  0.6764855980873108,\n",
       "  0.6759436130523682,\n",
       "  0.6767725348472595,\n",
       "  0.6768362522125244,\n",
       "  0.6760392785072327,\n",
       "  0.6765174865722656,\n",
       "  0.6770275235176086,\n",
       "  0.6769956350326538,\n",
       "  0.6802154779434204,\n",
       "  0.6814588308334351,\n",
       "  0.6795778870582581,\n",
       "  0.6816182136535645,\n",
       "  0.6808212399482727,\n",
       "  0.6820326447486877,\n",
       "  0.6816182136535645,\n",
       "  0.6813631653785706,\n",
       "  0.6801836490631104,\n",
       "  0.6854437589645386,\n",
       "  0.6847742795944214],\n",
       " 'factorized_top_k/top_5_categorical_accuracy': [0.13622163236141205,\n",
       "  0.1649770438671112,\n",
       "  0.16959959268569946,\n",
       "  0.17313823103904724,\n",
       "  0.18333971500396729,\n",
       "  0.18942871689796448,\n",
       "  0.19060826301574707,\n",
       "  0.1972392201423645,\n",
       "  0.20597423613071442,\n",
       "  0.21767406165599823,\n",
       "  0.2293419986963272,\n",
       "  0.24065926671028137,\n",
       "  0.25688600540161133,\n",
       "  0.2734315097332001,\n",
       "  0.2927824556827545,\n",
       "  0.31254783272743225,\n",
       "  0.331835001707077,\n",
       "  0.34809359908103943,\n",
       "  0.3644797205924988,\n",
       "  0.3787936866283417,\n",
       "  0.3936495780944824,\n",
       "  0.4058275818824768,\n",
       "  0.420205295085907,\n",
       "  0.43305277824401855,\n",
       "  0.44797244668006897,\n",
       "  0.46133002638816833,\n",
       "  0.4754526913166046,\n",
       "  0.4872162640094757,\n",
       "  0.4974496364593506,\n",
       "  0.5087987780570984,\n",
       "  0.5196697115898132,\n",
       "  0.5315927267074585,\n",
       "  0.5418898463249207,\n",
       "  0.5529839396476746,\n",
       "  0.5643011927604675,\n",
       "  0.5744070410728455,\n",
       "  0.5837477445602417,\n",
       "  0.592323362827301,\n",
       "  0.600261390209198,\n",
       "  0.6076256036758423,\n",
       "  0.6154679656028748,\n",
       "  0.6224177479743958,\n",
       "  0.6316947340965271,\n",
       "  0.6384850740432739,\n",
       "  0.6462637186050415,\n",
       "  0.6523526906967163,\n",
       "  0.6564651727676392,\n",
       "  0.6610239744186401,\n",
       "  0.665614664554596,\n",
       "  0.6692489385604858,\n",
       "  0.6732657551765442,\n",
       "  0.6764218211174011,\n",
       "  0.6798967123031616,\n",
       "  0.6843917369842529,\n",
       "  0.6877709627151489,\n",
       "  0.6900663375854492,\n",
       "  0.6927441954612732,\n",
       "  0.6942106485366821,\n",
       "  0.6968885660171509,\n",
       "  0.6987694501876831,\n",
       "  0.7008097171783447,\n",
       "  0.7031688094139099,\n",
       "  0.7055597901344299,\n",
       "  0.7068030834197998,\n",
       "  0.7087159156799316,\n",
       "  0.7095447778701782,\n",
       "  0.7107561826705933,\n",
       "  0.7114256620407104,\n",
       "  0.7125733494758606,\n",
       "  0.7133703231811523,\n",
       "  0.7140398025512695,\n",
       "  0.7158887982368469,\n",
       "  0.7163670063018799,\n",
       "  0.7169727087020874,\n",
       "  0.7170045971870422,\n",
       "  0.7175465226173401,\n",
       "  0.7183753848075867,\n",
       "  0.719491183757782,\n",
       "  0.7200331687927246,\n",
       "  0.7203200459480286,\n",
       "  0.7207982540130615,\n",
       "  0.7207663655281067,\n",
       "  0.7213402390480042,\n",
       "  0.7214358448982239,\n",
       "  0.7220734357833862,\n",
       "  0.7220734357833862,\n",
       "  0.7224241495132446,\n",
       "  0.7229022979736328,\n",
       "  0.7232211232185364,\n",
       "  0.7232530117034912,\n",
       "  0.7234761714935303,\n",
       "  0.7236355543136597,\n",
       "  0.724049985408783,\n",
       "  0.7241137623786926,\n",
       "  0.7241774797439575,\n",
       "  0.7246875762939453,\n",
       "  0.7250064015388489,\n",
       "  0.7249426245689392,\n",
       "  0.724974513053894,\n",
       "  0.7249107360839844,\n",
       "  0.7251657843589783,\n",
       "  0.7249426245689392,\n",
       "  0.7258033752441406,\n",
       "  0.7256121039390564,\n",
       "  0.7261859178543091,\n",
       "  0.7253570556640625,\n",
       "  0.7252295613288879,\n",
       "  0.7260265350341797,\n",
       "  0.7256439924240112,\n",
       "  0.7253889441490173,\n",
       "  0.7257077097892761,\n",
       "  0.7262178063392639,\n",
       "  0.7260903120040894,\n",
       "  0.7263453006744385,\n",
       "  0.7259946465492249,\n",
       "  0.7261859178543091,\n",
       "  0.726440966129303,\n",
       "  0.7267597317695618,\n",
       "  0.7266003489494324,\n",
       "  0.727142333984375,\n",
       "  0.7268553972244263,\n",
       "  0.7263771891593933,\n",
       "  0.7268553972244263,\n",
       "  0.7266322374343872,\n",
       "  0.7269191741943359,\n",
       "  0.7269828915596008,\n",
       "  0.7270466685295105,\n",
       "  0.7267916202545166,\n",
       "  0.7275567650794983,\n",
       "  0.7268553972244263,\n",
       "  0.7264728546142578,\n",
       "  0.7262496948242188,\n",
       "  0.7267279028892517,\n",
       "  0.7266960144042969,\n",
       "  0.726664125919342,\n",
       "  0.7266960144042969,\n",
       "  0.7271104454994202,\n",
       "  0.727142333984375,\n",
       "  0.7268235087394714,\n",
       "  0.7273654937744141,\n",
       "  0.7273336052894592,\n",
       "  0.7266960144042969,\n",
       "  0.7271104454994202,\n",
       "  0.7269191741943359,\n",
       "  0.7280668020248413,\n",
       "  0.7275886535644531,\n",
       "  0.7280668020248413,\n",
       "  0.727652370929718,\n",
       "  0.727652370929718,\n",
       "  0.7277480363845825,\n",
       "  0.7275248765945435,\n",
       "  0.7274610996246338,\n",
       "  0.7280030846595764,\n",
       "  0.7288638353347778,\n",
       "  0.7288000583648682,\n",
       "  0.7291507124900818,\n",
       "  0.7292782664299011,\n",
       "  0.7292144894599915,\n",
       "  0.7287043929100037,\n",
       "  0.7288638353347778,\n",
       "  0.7299795746803284,\n",
       "  0.7292463779449463,\n",
       "  0.7308403253555298,\n",
       "  0.7318605184555054,\n",
       "  0.731222927570343,\n",
       "  0.7308403253555298,\n",
       "  0.7312547564506531,\n",
       "  0.7312866449356079,\n",
       "  0.7318923473358154,\n",
       "  0.7307128310203552,\n",
       "  0.7314141988754272,\n",
       "  0.7350484728813171,\n",
       "  0.7346659302711487,\n",
       "  0.7344427704811096,\n",
       "  0.7346340417861938,\n",
       "  0.7355266809463501,\n",
       "  0.734889030456543,\n",
       "  0.735080361366272,\n",
       "  0.7346340417861938,\n",
       "  0.7351440787315369,\n",
       "  0.7388102412223816,\n",
       "  0.7392246723175049,\n",
       "  0.7390015125274658,\n",
       "  0.73919278383255,\n",
       "  0.738459587097168,\n",
       "  0.7385870814323425,\n",
       "  0.7390334010124207,\n",
       "  0.7395753860473633,\n",
       "  0.7390652894973755,\n",
       "  0.7412012219429016,\n",
       "  0.7408186793327332,\n",
       "  0.7406592965126038,\n",
       "  0.741073727607727,\n",
       "  0.740850567817688,\n",
       "  0.7407549023628235,\n",
       "  0.7409461736679077,\n",
       "  0.7407867908477783,\n",
       "  0.7410418391227722,\n",
       "  0.7425082921981812,\n",
       "  0.7421576380729675],\n",
       " 'factorized_top_k/top_10_categorical_accuracy': [0.21486864984035492,\n",
       "  0.26555725932121277,\n",
       "  0.2810826301574707,\n",
       "  0.2862471342086792,\n",
       "  0.2871716320514679,\n",
       "  0.2898176610469818,\n",
       "  0.2956516146659851,\n",
       "  0.3048010766506195,\n",
       "  0.31882810592651367,\n",
       "  0.33699947595596313,\n",
       "  0.35386380553245544,\n",
       "  0.37098315358161926,\n",
       "  0.3914180099964142,\n",
       "  0.4125223159790039,\n",
       "  0.42839837074279785,\n",
       "  0.4433498978614807,\n",
       "  0.45760011672973633,\n",
       "  0.4728066921234131,\n",
       "  0.4865149259567261,\n",
       "  0.49961745738983154,\n",
       "  0.5119548439979553,\n",
       "  0.524738609790802,\n",
       "  0.536757230758667,\n",
       "  0.5500191450119019,\n",
       "  0.5619421005249023,\n",
       "  0.5746939778327942,\n",
       "  0.5888803601264954,\n",
       "  0.6001657843589783,\n",
       "  0.6109092235565186,\n",
       "  0.6230553388595581,\n",
       "  0.6343407034873962,\n",
       "  0.643968403339386,\n",
       "  0.6529265642166138,\n",
       "  0.6608327031135559,\n",
       "  0.6691213846206665,\n",
       "  0.6765812039375305,\n",
       "  0.6844555139541626,\n",
       "  0.6914690136909485,\n",
       "  0.7002040147781372,\n",
       "  0.70795077085495,\n",
       "  0.7154424786567688,\n",
       "  0.7229022979736328,\n",
       "  0.7298520803451538,\n",
       "  0.7370887398719788,\n",
       "  0.7432096600532532,\n",
       "  0.7488204836845398,\n",
       "  0.7520084381103516,\n",
       "  0.7551963925361633,\n",
       "  0.7586712837219238,\n",
       "  0.7618911266326904,\n",
       "  0.7647602558135986,\n",
       "  0.7681076526641846,\n",
       "  0.7709448933601379,\n",
       "  0.7738778591156006,\n",
       "  0.7769701480865479,\n",
       "  0.778596043586731,\n",
       "  0.7800624966621399,\n",
       "  0.7825171947479248,\n",
       "  0.7834736108779907,\n",
       "  0.7850675582885742,\n",
       "  0.7861196398735046,\n",
       "  0.7878092527389526,\n",
       "  0.7894988656044006,\n",
       "  0.7908696532249451,\n",
       "  0.7916347980499268,\n",
       "  0.7926230430603027,\n",
       "  0.7934200167655945,\n",
       "  0.7936113476753235,\n",
       "  0.7945677042007446,\n",
       "  0.7952371835708618,\n",
       "  0.7960022687911987,\n",
       "  0.7970224618911743,\n",
       "  0.7972137331962585,\n",
       "  0.7978194355964661,\n",
       "  0.7981382012367249,\n",
       "  0.7986801862716675,\n",
       "  0.798807680606842,\n",
       "  0.7989352345466614,\n",
       "  0.7989033460617065,\n",
       "  0.7993177771568298,\n",
       "  0.7999234795570374,\n",
       "  0.8002104163169861,\n",
       "  0.8005610704421997,\n",
       "  0.8006248474121094,\n",
       "  0.8007523417472839,\n",
       "  0.8011030554771423,\n",
       "  0.8012624382972717,\n",
       "  0.8012624382972717,\n",
       "  0.8015812039375305,\n",
       "  0.8017725348472595,\n",
       "  0.8018681406974792,\n",
       "  0.8019638061523438,\n",
       "  0.8022187948226929,\n",
       "  0.8024101257324219,\n",
       "  0.8022187948226929,\n",
       "  0.8024101257324219,\n",
       "  0.8025376200675964,\n",
       "  0.802665114402771,\n",
       "  0.8027926683425903,\n",
       "  0.8027288913726807,\n",
       "  0.8030477166175842,\n",
       "  0.803143322467804,\n",
       "  0.8027926683425903,\n",
       "  0.8028882741928101,\n",
       "  0.8029839396476746,\n",
       "  0.8030795454978943,\n",
       "  0.8029520511627197,\n",
       "  0.8030477166175842,\n",
       "  0.803366482257843,\n",
       "  0.8032389879226685,\n",
       "  0.8032389879226685,\n",
       "  0.803143322467804,\n",
       "  0.8032708764076233,\n",
       "  0.8034940361976624,\n",
       "  0.8033027052879333,\n",
       "  0.8035258650779724,\n",
       "  0.803366482257843,\n",
       "  0.8034302592277527,\n",
       "  0.8035577535629272,\n",
       "  0.8033983707427979,\n",
       "  0.8037171363830566,\n",
       "  0.8035896420478821,\n",
       "  0.8036534190177917,\n",
       "  0.803366482257843,\n",
       "  0.8034621477127075,\n",
       "  0.8037490248680115,\n",
       "  0.8033983707427979,\n",
       "  0.8035577535629272,\n",
       "  0.8036853075027466,\n",
       "  0.8037490248680115,\n",
       "  0.8032708764076233,\n",
       "  0.8037809133529663,\n",
       "  0.8036853075027466,\n",
       "  0.803844690322876,\n",
       "  0.804067850112915,\n",
       "  0.8040359616279602,\n",
       "  0.8035896420478821,\n",
       "  0.8038765788078308,\n",
       "  0.8037809133529663,\n",
       "  0.8039402961730957,\n",
       "  0.8039402961730957,\n",
       "  0.8037171363830566,\n",
       "  0.8038128018379211,\n",
       "  0.8037809133529663,\n",
       "  0.8040359616279602,\n",
       "  0.8039721846580505,\n",
       "  0.8038765788078308,\n",
       "  0.8037171363830566,\n",
       "  0.8041634559631348,\n",
       "  0.8040359616279602,\n",
       "  0.8039084672927856,\n",
       "  0.8040997385978699,\n",
       "  0.8040359616279602,\n",
       "  0.8041316270828247,\n",
       "  0.8039721846580505,\n",
       "  0.804067850112915,\n",
       "  0.8043228983879089,\n",
       "  0.8040997385978699,\n",
       "  0.8041953444480896,\n",
       "  0.804067850112915,\n",
       "  0.8039084672927856,\n",
       "  0.8042272329330444,\n",
       "  0.804832935333252,\n",
       "  0.8048010468482971,\n",
       "  0.8046097755432129,\n",
       "  0.8042591214179993,\n",
       "  0.8053749203681946,\n",
       "  0.8051198720932007,\n",
       "  0.805056095123291,\n",
       "  0.8046735525131226,\n",
       "  0.8047054409980774,\n",
       "  0.8058849573135376,\n",
       "  0.8059168457984924,\n",
       "  0.805757462978363,\n",
       "  0.8059806227684021,\n",
       "  0.8055024147033691,\n",
       "  0.8062993884086609,\n",
       "  0.8059168457984924,\n",
       "  0.8061718940734863,\n",
       "  0.8059487342834473,\n",
       "  0.8070964217185974,\n",
       "  0.8070007562637329,\n",
       "  0.8077659010887146,\n",
       "  0.8076702356338501,\n",
       "  0.8074151873588562,\n",
       "  0.8076064586639404,\n",
       "  0.8070645332336426,\n",
       "  0.8073832988739014,\n",
       "  0.8072876930236816,\n",
       "  0.808212161064148,\n",
       "  0.8082440495491028,\n",
       "  0.808435320854187,\n",
       "  0.8082759380340576,\n",
       "  0.8086584806442261,\n",
       "  0.8081165552139282,\n",
       "  0.8086584806442261,\n",
       "  0.8084672093391418,\n",
       "  0.8084990978240967,\n",
       "  0.808626651763916,\n",
       "  0.8085628747940063],\n",
       " 'factorized_top_k/top_15_categorical_accuracy': [0.27426040172576904,\n",
       "  0.33320581912994385,\n",
       "  0.34694594144821167,\n",
       "  0.3516322374343872,\n",
       "  0.3573068082332611,\n",
       "  0.3641609251499176,\n",
       "  0.37487247586250305,\n",
       "  0.3879750072956085,\n",
       "  0.4034366309642792,\n",
       "  0.4192807972431183,\n",
       "  0.43805789947509766,\n",
       "  0.4584927260875702,\n",
       "  0.4779711663722992,\n",
       "  0.4941660165786743,\n",
       "  0.5072685480117798,\n",
       "  0.5198609828948975,\n",
       "  0.5330591797828674,\n",
       "  0.5457791090011597,\n",
       "  0.5595192313194275,\n",
       "  0.5737694501876831,\n",
       "  0.5857561826705933,\n",
       "  0.5990818738937378,\n",
       "  0.6126307249069214,\n",
       "  0.6260201334953308,\n",
       "  0.6377518773078918,\n",
       "  0.6491328477859497,\n",
       "  0.6596212983131409,\n",
       "  0.6701734066009521,\n",
       "  0.680056095123291,\n",
       "  0.6890461444854736,\n",
       "  0.6989926099777222,\n",
       "  0.7066118121147156,\n",
       "  0.7148367762565613,\n",
       "  0.7228066921234131,\n",
       "  0.7313185334205627,\n",
       "  0.7384276986122131,\n",
       "  0.7448036074638367,\n",
       "  0.7520721554756165,\n",
       "  0.7587987780570984,\n",
       "  0.7646327614784241,\n",
       "  0.7696697115898132,\n",
       "  0.775726854801178,\n",
       "  0.7818477153778076,\n",
       "  0.7871716618537903,\n",
       "  0.7926549315452576,\n",
       "  0.7978832125663757,\n",
       "  0.8009436130523682,\n",
       "  0.8041634559631348,\n",
       "  0.8062037825584412,\n",
       "  0.8092004656791687,\n",
       "  0.8115595579147339,\n",
       "  0.813472330570221,\n",
       "  0.8157676458358765,\n",
       "  0.8172978758811951,\n",
       "  0.8192106485366821,\n",
       "  0.8201989531517029,\n",
       "  0.8214422464370728,\n",
       "  0.8227174282073975,\n",
       "  0.8234825134277344,\n",
       "  0.8239288330078125,\n",
       "  0.8247895836830139,\n",
       "  0.8252996802330017,\n",
       "  0.8263517022132874,\n",
       "  0.8270848989486694,\n",
       "  0.8275631070137024,\n",
       "  0.8282644748687744,\n",
       "  0.8287107944488525,\n",
       "  0.8296353220939636,\n",
       "  0.8300497531890869,\n",
       "  0.8304004073143005,\n",
       "  0.8312292695045471,\n",
       "  0.8313249349594116,\n",
       "  0.8320262432098389,\n",
       "  0.832185685634613,\n",
       "  0.8324406743049622,\n",
       "  0.832695722579956,\n",
       "  0.83295077085495,\n",
       "  0.8333652019500732,\n",
       "  0.8335245847702026,\n",
       "  0.8338115215301514,\n",
       "  0.8338115215301514,\n",
       "  0.8339390754699707,\n",
       "  0.8342897295951843,\n",
       "  0.8344810009002686,\n",
       "  0.8344491124153137,\n",
       "  0.834863543510437,\n",
       "  0.8349273204803467,\n",
       "  0.8348316550254822,\n",
       "  0.8350229263305664,\n",
       "  0.8350229263305664,\n",
       "  0.8351504802703857,\n",
       "  0.8353736400604248,\n",
       "  0.8352779746055603,\n",
       "  0.8352142572402954,\n",
       "  0.8352460861206055,\n",
       "  0.8353098630905151,\n",
       "  0.8356924057006836,\n",
       "  0.8355330228805542,\n",
       "  0.8356286883354187,\n",
       "  0.8357242941856384,\n",
       "  0.8357242941856384,\n",
       "  0.8358518481254578,\n",
       "  0.8357880711555481,\n",
       "  0.8358199596405029,\n",
       "  0.8361706137657166,\n",
       "  0.8359474539756775,\n",
       "  0.8359474539756775,\n",
       "  0.8359155654907227,\n",
       "  0.836043119430542,\n",
       "  0.8360750079154968,\n",
       "  0.8360750079154968,\n",
       "  0.8361068367958069,\n",
       "  0.8361706137657166,\n",
       "  0.836043119430542,\n",
       "  0.8361068367958069,\n",
       "  0.8362981677055359,\n",
       "  0.8362981677055359,\n",
       "  0.8363937735557556,\n",
       "  0.8361706137657166,\n",
       "  0.836266279220581,\n",
       "  0.8362981677055359,\n",
       "  0.8363937735557556,\n",
       "  0.8362981677055359,\n",
       "  0.8363618850708008,\n",
       "  0.8364575505256653,\n",
       "  0.8362981677055359,\n",
       "  0.8364575505256653,\n",
       "  0.8365850448608398,\n",
       "  0.8363618850708008,\n",
       "  0.8362981677055359,\n",
       "  0.8364575505256653,\n",
       "  0.8363618850708008,\n",
       "  0.8362343907356262,\n",
       "  0.8363937735557556,\n",
       "  0.8365850448608398,\n",
       "  0.8366169333457947,\n",
       "  0.8364894390106201,\n",
       "  0.836553156375885,\n",
       "  0.8365850448608398,\n",
       "  0.8364256620407104,\n",
       "  0.8363937735557556,\n",
       "  0.8365212678909302,\n",
       "  0.8367444276809692,\n",
       "  0.8365850448608398,\n",
       "  0.8368400931358337,\n",
       "  0.8366169333457947,\n",
       "  0.8367444276809692,\n",
       "  0.8366488218307495,\n",
       "  0.8366488218307495,\n",
       "  0.8366488218307495,\n",
       "  0.8364256620407104,\n",
       "  0.8366488218307495,\n",
       "  0.8366169333457947,\n",
       "  0.8366488218307495,\n",
       "  0.8368082046508789,\n",
       "  0.8368400931358337,\n",
       "  0.8366488218307495,\n",
       "  0.8367125988006592,\n",
       "  0.8367444276809692,\n",
       "  0.8369038701057434,\n",
       "  0.8366488218307495,\n",
       "  0.8365212678909302,\n",
       "  0.837254524230957,\n",
       "  0.8369357585906982,\n",
       "  0.8373183012008667,\n",
       "  0.8370951414108276,\n",
       "  0.8370951414108276,\n",
       "  0.8369675874710083,\n",
       "  0.8370632529258728,\n",
       "  0.8369357585906982,\n",
       "  0.8368082046508789,\n",
       "  0.8375414609909058,\n",
       "  0.8376051783561707,\n",
       "  0.8376370668411255,\n",
       "  0.8375733494758606,\n",
       "  0.8376370668411255,\n",
       "  0.8378602266311646,\n",
       "  0.8377965092658997,\n",
       "  0.8376370668411255,\n",
       "  0.8376370668411255,\n",
       "  0.8390398025512695,\n",
       "  0.8388485312461853,\n",
       "  0.8392310738563538,\n",
       "  0.838720977306366,\n",
       "  0.8388485312461853,\n",
       "  0.8390398025512695,\n",
       "  0.8387847542762756,\n",
       "  0.8386572599411011,\n",
       "  0.8388803601264954,\n",
       "  0.8400918245315552,\n",
       "  0.8397729992866516,\n",
       "  0.839422345161438,\n",
       "  0.8397092819213867,\n",
       "  0.8398367762565613,\n",
       "  0.8397092819213867,\n",
       "  0.8400599360466003,\n",
       "  0.8399642705917358,\n",
       "  0.8398048877716064,\n",
       "  0.8400599360466003,\n",
       "  0.840410590171814],\n",
       " 'factorized_top_k/top_25_categorical_accuracy': [0.37471309304237366,\n",
       "  0.44532644748687744,\n",
       "  0.4541889727115631,\n",
       "  0.4580782949924469,\n",
       "  0.46649453043937683,\n",
       "  0.47946953773498535,\n",
       "  0.4936559498310089,\n",
       "  0.5147283673286438,\n",
       "  0.5294249057769775,\n",
       "  0.5429418683052063,\n",
       "  0.5577659010887146,\n",
       "  0.5736100673675537,\n",
       "  0.5853098630905151,\n",
       "  0.5982211232185364,\n",
       "  0.6131726503372192,\n",
       "  0.6294950246810913,\n",
       "  0.6433626413345337,\n",
       "  0.6570708751678467,\n",
       "  0.6673361659049988,\n",
       "  0.6778563857078552,\n",
       "  0.6898750066757202,\n",
       "  0.7020211815834045,\n",
       "  0.7121270298957825,\n",
       "  0.7208620309829712,\n",
       "  0.7299795746803284,\n",
       "  0.7390334010124207,\n",
       "  0.7479597330093384,\n",
       "  0.7553876638412476,\n",
       "  0.763006865978241,\n",
       "  0.7704348564147949,\n",
       "  0.7775440216064453,\n",
       "  0.7837923765182495,\n",
       "  0.789435088634491,\n",
       "  0.794918417930603,\n",
       "  0.8011667728424072,\n",
       "  0.8067775964736938,\n",
       "  0.8120696544647217,\n",
       "  0.817552924156189,\n",
       "  0.8223667144775391,\n",
       "  0.826415479183197,\n",
       "  0.8302410244941711,\n",
       "  0.8336202502250671,\n",
       "  0.8367125988006592,\n",
       "  0.839900553226471,\n",
       "  0.8427059650421143,\n",
       "  0.8457982540130615,\n",
       "  0.8471372127532959,\n",
       "  0.8491456508636475,\n",
       "  0.8512815833091736,\n",
       "  0.8536725044250488,\n",
       "  0.8547883033752441,\n",
       "  0.8562547564506531,\n",
       "  0.8574981093406677,\n",
       "  0.8588688969612122,\n",
       "  0.8603672385215759,\n",
       "  0.861291766166687,\n",
       "  0.8621844053268433,\n",
       "  0.8630451560020447,\n",
       "  0.863969624042511,\n",
       "  0.8649898171424866,\n",
       "  0.8658186793327332,\n",
       "  0.8663287162780762,\n",
       "  0.8668707013130188,\n",
       "  0.8675720691680908,\n",
       "  0.8682096600532532,\n",
       "  0.868528425693512,\n",
       "  0.8686559796333313,\n",
       "  0.8691979050636292,\n",
       "  0.8698673844337463,\n",
       "  0.87021803855896,\n",
       "  0.8706324696540833,\n",
       "  0.8710787892341614,\n",
       "  0.8713657259941101,\n",
       "  0.8714932203292847,\n",
       "  0.8716526627540588,\n",
       "  0.8718439340591431,\n",
       "  0.872130811214447,\n",
       "  0.8724177479743958,\n",
       "  0.8727046847343445,\n",
       "  0.8729278445243835,\n",
       "  0.8729915618896484,\n",
       "  0.8732147216796875,\n",
       "  0.8734059929847717,\n",
       "  0.8734059929847717,\n",
       "  0.8735016584396362,\n",
       "  0.8735973238945007,\n",
       "  0.8735654354095459,\n",
       "  0.8736291527748108,\n",
       "  0.8737567067146301,\n",
       "  0.8739479780197144,\n",
       "  0.874011754989624,\n",
       "  0.8741711378097534,\n",
       "  0.8742349147796631,\n",
       "  0.8743624091148376,\n",
       "  0.8742667436599731,\n",
       "  0.8743942975997925,\n",
       "  0.8745536804199219,\n",
       "  0.8745536804199219,\n",
       "  0.8746811747550964,\n",
       "  0.8746493458747864,\n",
       "  0.8747130632400513,\n",
       "  0.8747130632400513,\n",
       "  0.8747449517250061,\n",
       "  0.8746811747550964,\n",
       "  0.8748087286949158,\n",
       "  0.8749362230300903,\n",
       "  0.875,\n",
       "  0.8750637769699097,\n",
       "  0.8750956654548645,\n",
       "  0.8750637769699097,\n",
       "  0.8750637769699097,\n",
       "  0.8751912713050842,\n",
       "  0.8750956654548645,\n",
       "  0.8750637769699097,\n",
       "  0.8751912713050842,\n",
       "  0.8753188252449036,\n",
       "  0.8753188252449036,\n",
       "  0.8751593828201294,\n",
       "  0.8752550482749939,\n",
       "  0.8752550482749939,\n",
       "  0.8750956654548645,\n",
       "  0.8751912713050842,\n",
       "  0.8753506541252136,\n",
       "  0.8753188252449036,\n",
       "  0.8754463195800781,\n",
       "  0.8754463195800781,\n",
       "  0.8752869367599487,\n",
       "  0.8752869367599487,\n",
       "  0.8754144310951233,\n",
       "  0.8752869367599487,\n",
       "  0.8751593828201294,\n",
       "  0.8753188252449036,\n",
       "  0.8752869367599487,\n",
       "  0.8753188252449036,\n",
       "  0.8754463195800781,\n",
       "  0.8752231597900391,\n",
       "  0.8752869367599487,\n",
       "  0.8752869367599487,\n",
       "  0.8752231597900391,\n",
       "  0.8752869367599487,\n",
       "  0.8752869367599487,\n",
       "  0.875478208065033,\n",
       "  0.8752550482749939,\n",
       "  0.875478208065033,\n",
       "  0.8753188252449036,\n",
       "  0.8753506541252136,\n",
       "  0.8754463195800781,\n",
       "  0.8754463195800781,\n",
       "  0.8753825426101685,\n",
       "  0.8753825426101685,\n",
       "  0.8753825426101685,\n",
       "  0.8755100965499878,\n",
       "  0.8754144310951233,\n",
       "  0.8753506541252136,\n",
       "  0.8753825426101685,\n",
       "  0.8753506541252136,\n",
       "  0.8754463195800781,\n",
       "  0.8755100965499878,\n",
       "  0.8755738139152527,\n",
       "  0.8753188252449036,\n",
       "  0.8755419254302979,\n",
       "  0.8755419254302979,\n",
       "  0.8756057024002075,\n",
       "  0.875701367855072,\n",
       "  0.8755738139152527,\n",
       "  0.8755419254302979,\n",
       "  0.8756375908851624,\n",
       "  0.8756694793701172,\n",
       "  0.8757332563400269,\n",
       "  0.8755419254302979,\n",
       "  0.8758288621902466,\n",
       "  0.8760520219802856,\n",
       "  0.8758607506752014,\n",
       "  0.8759564161300659,\n",
       "  0.8760201334953308,\n",
       "  0.8759564161300659,\n",
       "  0.8757650852203369,\n",
       "  0.8759245276451111,\n",
       "  0.8757332563400269,\n",
       "  0.8758288621902466,\n",
       "  0.8764983415603638,\n",
       "  0.8764026761054993,\n",
       "  0.8763389587402344,\n",
       "  0.8764983415603638,\n",
       "  0.8765302300453186,\n",
       "  0.8762751817703247,\n",
       "  0.8763070702552795,\n",
       "  0.8763070702552795,\n",
       "  0.8765940070152283,\n",
       "  0.8771040439605713,\n",
       "  0.8772315979003906,\n",
       "  0.8772634267807007,\n",
       "  0.8770402669906616,\n",
       "  0.8770721554756165,\n",
       "  0.8772634267807007,\n",
       "  0.8769446611404419,\n",
       "  0.8769127726554871,\n",
       "  0.8770084381103516,\n",
       "  0.87739098072052,\n",
       "  0.8774547576904297],\n",
       " 'loss': [772.7199096679688,\n",
       "  801.634033203125,\n",
       "  696.4047241210938,\n",
       "  666.6883544921875,\n",
       "  643.400634765625,\n",
       "  649.888671875,\n",
       "  637.8743896484375,\n",
       "  617.0538330078125,\n",
       "  647.0709228515625,\n",
       "  639.3485717773438,\n",
       "  613.4449462890625,\n",
       "  601.459716796875,\n",
       "  599.8446655273438,\n",
       "  594.6412353515625,\n",
       "  587.443359375,\n",
       "  593.1839599609375,\n",
       "  608.0390625,\n",
       "  574.48095703125,\n",
       "  577.839111328125,\n",
       "  575.3815307617188,\n",
       "  542.8900756835938,\n",
       "  553.6618041992188,\n",
       "  539.793212890625,\n",
       "  535.6414794921875,\n",
       "  524.3158569335938,\n",
       "  525.1917114257812,\n",
       "  514.1588745117188,\n",
       "  502.36376953125,\n",
       "  514.1079711914062,\n",
       "  488.025390625,\n",
       "  475.9899597167969,\n",
       "  466.76422119140625,\n",
       "  474.7698974609375,\n",
       "  469.3238525390625,\n",
       "  459.13232421875,\n",
       "  457.8461608886719,\n",
       "  454.4964599609375,\n",
       "  452.957275390625,\n",
       "  441.8081970214844,\n",
       "  435.843505859375,\n",
       "  452.2925720214844,\n",
       "  436.47686767578125,\n",
       "  428.970703125,\n",
       "  396.14080810546875,\n",
       "  421.7718505859375,\n",
       "  419.6373291015625,\n",
       "  398.6756591796875,\n",
       "  412.57720947265625,\n",
       "  396.97540283203125,\n",
       "  411.1368408203125,\n",
       "  389.4910583496094,\n",
       "  413.47515869140625,\n",
       "  390.02423095703125,\n",
       "  411.6114501953125,\n",
       "  394.169921875,\n",
       "  410.1978454589844,\n",
       "  358.56634521484375,\n",
       "  383.7137451171875,\n",
       "  400.3219909667969,\n",
       "  365.00341796875,\n",
       "  389.5062255859375,\n",
       "  368.73388671875,\n",
       "  367.9970703125,\n",
       "  368.17535400390625,\n",
       "  370.4593505859375,\n",
       "  372.06732177734375,\n",
       "  384.2455139160156,\n",
       "  372.259765625,\n",
       "  359.1744384765625,\n",
       "  380.0648193359375,\n",
       "  372.7557067871094,\n",
       "  349.01788330078125,\n",
       "  371.444580078125,\n",
       "  375.68316650390625,\n",
       "  374.1243896484375,\n",
       "  350.265380859375,\n",
       "  372.0696105957031,\n",
       "  353.3694152832031,\n",
       "  369.31414794921875,\n",
       "  385.032958984375,\n",
       "  368.1141357421875,\n",
       "  380.5122375488281,\n",
       "  365.87579345703125,\n",
       "  363.30133056640625,\n",
       "  367.13446044921875,\n",
       "  384.2041015625,\n",
       "  382.40716552734375,\n",
       "  367.26171875,\n",
       "  339.19720458984375,\n",
       "  361.9605712890625,\n",
       "  366.9537353515625,\n",
       "  365.18463134765625,\n",
       "  394.6888122558594,\n",
       "  361.2781982421875,\n",
       "  395.63720703125,\n",
       "  372.66162109375,\n",
       "  386.60992431640625,\n",
       "  371.12921142578125,\n",
       "  374.366455078125,\n",
       "  369.1299133300781,\n",
       "  379.52374267578125,\n",
       "  356.6148681640625,\n",
       "  359.2837829589844,\n",
       "  371.00958251953125,\n",
       "  356.5593566894531,\n",
       "  372.0966796875,\n",
       "  381.59576416015625,\n",
       "  360.78704833984375,\n",
       "  349.61334228515625,\n",
       "  354.513671875,\n",
       "  365.4583740234375,\n",
       "  388.852294921875,\n",
       "  364.3529052734375,\n",
       "  343.46197509765625,\n",
       "  354.11065673828125,\n",
       "  346.3072814941406,\n",
       "  374.67864990234375,\n",
       "  372.1326599121094,\n",
       "  369.31268310546875,\n",
       "  357.83465576171875,\n",
       "  365.9117736816406,\n",
       "  363.88787841796875,\n",
       "  357.8978271484375,\n",
       "  364.71527099609375,\n",
       "  354.88690185546875,\n",
       "  346.99420166015625,\n",
       "  360.36810302734375,\n",
       "  356.4871826171875,\n",
       "  356.28076171875,\n",
       "  361.77130126953125,\n",
       "  364.9739990234375,\n",
       "  349.325927734375,\n",
       "  356.74786376953125,\n",
       "  364.2022705078125,\n",
       "  372.9698791503906,\n",
       "  371.10992431640625,\n",
       "  348.9395446777344,\n",
       "  364.7745361328125,\n",
       "  373.231689453125,\n",
       "  351.11224365234375,\n",
       "  365.93743896484375,\n",
       "  351.25164794921875,\n",
       "  375.0980224609375,\n",
       "  394.149169921875,\n",
       "  355.92779541015625,\n",
       "  372.447265625,\n",
       "  355.06475830078125,\n",
       "  364.0673522949219,\n",
       "  356.29364013671875,\n",
       "  362.432373046875,\n",
       "  384.6083984375,\n",
       "  360.560302734375,\n",
       "  372.10028076171875,\n",
       "  361.43780517578125,\n",
       "  346.7033996582031,\n",
       "  349.90765380859375,\n",
       "  373.65826416015625,\n",
       "  363.11920166015625,\n",
       "  354.40765380859375,\n",
       "  392.8485107421875,\n",
       "  358.35009765625,\n",
       "  381.70013427734375,\n",
       "  363.4780578613281,\n",
       "  359.68817138671875,\n",
       "  366.9095458984375,\n",
       "  373.1626892089844,\n",
       "  356.93853759765625,\n",
       "  362.1209411621094,\n",
       "  369.5688171386719,\n",
       "  370.4132080078125,\n",
       "  355.5500793457031,\n",
       "  356.2340087890625,\n",
       "  342.93975830078125,\n",
       "  358.5252685546875,\n",
       "  358.06695556640625,\n",
       "  382.54046630859375,\n",
       "  373.5330810546875,\n",
       "  355.3658447265625,\n",
       "  352.3656005859375,\n",
       "  351.08697509765625,\n",
       "  364.7021789550781,\n",
       "  345.5113525390625,\n",
       "  374.2226257324219,\n",
       "  370.17205810546875,\n",
       "  355.56231689453125,\n",
       "  367.34521484375,\n",
       "  359.41680908203125,\n",
       "  361.8343200683594,\n",
       "  382.2305908203125,\n",
       "  358.4640808105469,\n",
       "  347.5177917480469,\n",
       "  371.01092529296875,\n",
       "  355.4078674316406,\n",
       "  374.0661315917969,\n",
       "  353.7919921875,\n",
       "  352.6175231933594,\n",
       "  387.80352783203125,\n",
       "  366.7223815917969,\n",
       "  350.6261291503906,\n",
       "  369.99053955078125],\n",
       " 'regularization_loss': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'total_loss': [772.7199096679688,\n",
       "  801.634033203125,\n",
       "  696.4047241210938,\n",
       "  666.6883544921875,\n",
       "  643.400634765625,\n",
       "  649.888671875,\n",
       "  637.8743896484375,\n",
       "  617.0538330078125,\n",
       "  647.0709228515625,\n",
       "  639.3485717773438,\n",
       "  613.4449462890625,\n",
       "  601.459716796875,\n",
       "  599.8446655273438,\n",
       "  594.6412353515625,\n",
       "  587.443359375,\n",
       "  593.1839599609375,\n",
       "  608.0390625,\n",
       "  574.48095703125,\n",
       "  577.839111328125,\n",
       "  575.3815307617188,\n",
       "  542.8900756835938,\n",
       "  553.6618041992188,\n",
       "  539.793212890625,\n",
       "  535.6414794921875,\n",
       "  524.3158569335938,\n",
       "  525.1917114257812,\n",
       "  514.1588745117188,\n",
       "  502.36376953125,\n",
       "  514.1079711914062,\n",
       "  488.025390625,\n",
       "  475.9899597167969,\n",
       "  466.76422119140625,\n",
       "  474.7698974609375,\n",
       "  469.3238525390625,\n",
       "  459.13232421875,\n",
       "  457.8461608886719,\n",
       "  454.4964599609375,\n",
       "  452.957275390625,\n",
       "  441.8081970214844,\n",
       "  435.843505859375,\n",
       "  452.2925720214844,\n",
       "  436.47686767578125,\n",
       "  428.970703125,\n",
       "  396.14080810546875,\n",
       "  421.7718505859375,\n",
       "  419.6373291015625,\n",
       "  398.6756591796875,\n",
       "  412.57720947265625,\n",
       "  396.97540283203125,\n",
       "  411.1368408203125,\n",
       "  389.4910583496094,\n",
       "  413.47515869140625,\n",
       "  390.02423095703125,\n",
       "  411.6114501953125,\n",
       "  394.169921875,\n",
       "  410.1978454589844,\n",
       "  358.56634521484375,\n",
       "  383.7137451171875,\n",
       "  400.3219909667969,\n",
       "  365.00341796875,\n",
       "  389.5062255859375,\n",
       "  368.73388671875,\n",
       "  367.9970703125,\n",
       "  368.17535400390625,\n",
       "  370.4593505859375,\n",
       "  372.06732177734375,\n",
       "  384.2455139160156,\n",
       "  372.259765625,\n",
       "  359.1744384765625,\n",
       "  380.0648193359375,\n",
       "  372.7557067871094,\n",
       "  349.01788330078125,\n",
       "  371.444580078125,\n",
       "  375.68316650390625,\n",
       "  374.1243896484375,\n",
       "  350.265380859375,\n",
       "  372.0696105957031,\n",
       "  353.3694152832031,\n",
       "  369.31414794921875,\n",
       "  385.032958984375,\n",
       "  368.1141357421875,\n",
       "  380.5122375488281,\n",
       "  365.87579345703125,\n",
       "  363.30133056640625,\n",
       "  367.13446044921875,\n",
       "  384.2041015625,\n",
       "  382.40716552734375,\n",
       "  367.26171875,\n",
       "  339.19720458984375,\n",
       "  361.9605712890625,\n",
       "  366.9537353515625,\n",
       "  365.18463134765625,\n",
       "  394.6888122558594,\n",
       "  361.2781982421875,\n",
       "  395.63720703125,\n",
       "  372.66162109375,\n",
       "  386.60992431640625,\n",
       "  371.12921142578125,\n",
       "  374.366455078125,\n",
       "  369.1299133300781,\n",
       "  379.52374267578125,\n",
       "  356.6148681640625,\n",
       "  359.2837829589844,\n",
       "  371.00958251953125,\n",
       "  356.5593566894531,\n",
       "  372.0966796875,\n",
       "  381.59576416015625,\n",
       "  360.78704833984375,\n",
       "  349.61334228515625,\n",
       "  354.513671875,\n",
       "  365.4583740234375,\n",
       "  388.852294921875,\n",
       "  364.3529052734375,\n",
       "  343.46197509765625,\n",
       "  354.11065673828125,\n",
       "  346.3072814941406,\n",
       "  374.67864990234375,\n",
       "  372.1326599121094,\n",
       "  369.31268310546875,\n",
       "  357.83465576171875,\n",
       "  365.9117736816406,\n",
       "  363.88787841796875,\n",
       "  357.8978271484375,\n",
       "  364.71527099609375,\n",
       "  354.88690185546875,\n",
       "  346.99420166015625,\n",
       "  360.36810302734375,\n",
       "  356.4871826171875,\n",
       "  356.28076171875,\n",
       "  361.77130126953125,\n",
       "  364.9739990234375,\n",
       "  349.325927734375,\n",
       "  356.74786376953125,\n",
       "  364.2022705078125,\n",
       "  372.9698791503906,\n",
       "  371.10992431640625,\n",
       "  348.9395446777344,\n",
       "  364.7745361328125,\n",
       "  373.231689453125,\n",
       "  351.11224365234375,\n",
       "  365.93743896484375,\n",
       "  351.25164794921875,\n",
       "  375.0980224609375,\n",
       "  394.149169921875,\n",
       "  355.92779541015625,\n",
       "  372.447265625,\n",
       "  355.06475830078125,\n",
       "  364.0673522949219,\n",
       "  356.29364013671875,\n",
       "  362.432373046875,\n",
       "  384.6083984375,\n",
       "  360.560302734375,\n",
       "  372.10028076171875,\n",
       "  361.43780517578125,\n",
       "  346.7033996582031,\n",
       "  349.90765380859375,\n",
       "  373.65826416015625,\n",
       "  363.11920166015625,\n",
       "  354.40765380859375,\n",
       "  392.8485107421875,\n",
       "  358.35009765625,\n",
       "  381.70013427734375,\n",
       "  363.4780578613281,\n",
       "  359.68817138671875,\n",
       "  366.9095458984375,\n",
       "  373.1626892089844,\n",
       "  356.93853759765625,\n",
       "  362.1209411621094,\n",
       "  369.5688171386719,\n",
       "  370.4132080078125,\n",
       "  355.5500793457031,\n",
       "  356.2340087890625,\n",
       "  342.93975830078125,\n",
       "  358.5252685546875,\n",
       "  358.06695556640625,\n",
       "  382.54046630859375,\n",
       "  373.5330810546875,\n",
       "  355.3658447265625,\n",
       "  352.3656005859375,\n",
       "  351.08697509765625,\n",
       "  364.7021789550781,\n",
       "  345.5113525390625,\n",
       "  374.2226257324219,\n",
       "  370.17205810546875,\n",
       "  355.56231689453125,\n",
       "  367.34521484375,\n",
       "  359.41680908203125,\n",
       "  361.8343200683594,\n",
       "  382.2305908203125,\n",
       "  358.4640808105469,\n",
       "  347.5177917480469,\n",
       "  371.01092529296875,\n",
       "  355.4078674316406,\n",
       "  374.0661315917969,\n",
       "  353.7919921875,\n",
       "  352.6175231933594,\n",
       "  387.80352783203125,\n",
       "  366.7223815917969,\n",
       "  350.6261291503906,\n",
       "  369.99053955078125],\n",
       " 'val_factorized_top_k/top_3_categorical_accuracy': [0.18020085990428925,\n",
       "  0.1902438998222351,\n",
       "  0.1902438998222351,\n",
       "  0.19368723034858704,\n",
       "  0.19827833771705627,\n",
       "  0.19885222613811493,\n",
       "  0.21233859658241272,\n",
       "  0.2100430428981781,\n",
       "  0.21348637342453003,\n",
       "  0.21176470816135406,\n",
       "  0.21549497544765472,\n",
       "  0.21807748079299927,\n",
       "  0.22238163650035858,\n",
       "  0.2226685732603073,\n",
       "  0.22238163650035858,\n",
       "  0.22525107860565186,\n",
       "  0.22639885544776917,\n",
       "  0.2266857922077179,\n",
       "  0.2321377396583557,\n",
       "  0.23271162807941437,\n",
       "  0.23443327844142914,\n",
       "  0.23012912273406982,\n",
       "  0.23156385123729706,\n",
       "  0.2341463416814804,\n",
       "  0.23787660896778107,\n",
       "  0.24074605107307434,\n",
       "  0.23701578378677368,\n",
       "  0.24160689115524292,\n",
       "  0.2393113374710083,\n",
       "  0.23873744904994965,\n",
       "  0.2393113374710083,\n",
       "  0.24361549317836761,\n",
       "  0.2424677163362503,\n",
       "  0.24418938159942627,\n",
       "  0.2444763332605362,\n",
       "  0.24218077957630157,\n",
       "  0.24849353730678558,\n",
       "  0.24619799852371216,\n",
       "  0.25136297941207886,\n",
       "  0.2496413141489029,\n",
       "  0.24906742572784424,\n",
       "  0.24820660054683685,\n",
       "  0.2550932466983795,\n",
       "  0.253084659576416,\n",
       "  0.25882354378700256,\n",
       "  0.2582496404647827,\n",
       "  0.2548063099384308,\n",
       "  0.25566715002059937,\n",
       "  0.2568149268627167,\n",
       "  0.25853657722473145,\n",
       "  0.2593974173069,\n",
       "  0.26370158791542053,\n",
       "  0.2625538110733032,\n",
       "  0.2631276845932007,\n",
       "  0.26169297099113464,\n",
       "  0.26599714159965515,\n",
       "  0.2619799077510834,\n",
       "  0.26398852467536926,\n",
       "  0.26370158791542053,\n",
       "  0.2654232382774353,\n",
       "  0.2614060342311859,\n",
       "  0.2651363015174866,\n",
       "  0.26685795187950134,\n",
       "  0.2685796320438385,\n",
       "  0.2685796320438385,\n",
       "  0.2665710151195526,\n",
       "  0.26571017503738403,\n",
       "  0.2619799077510834,\n",
       "  0.26599714159965515,\n",
       "  0.26284074783325195,\n",
       "  0.26484936475753784,\n",
       "  0.2654232382774353,\n",
       "  0.26571017503738403,\n",
       "  0.26886656880378723,\n",
       "  0.2685796320438385,\n",
       "  0.26800572872161865,\n",
       "  0.26599714159965515,\n",
       "  0.2625538110733032,\n",
       "  0.2665710151195526,\n",
       "  0.2705882489681244,\n",
       "  0.27116212248802185,\n",
       "  0.27116212248802185,\n",
       "  0.26800572872161865,\n",
       "  0.2714490592479706,\n",
       "  0.26800572872161865,\n",
       "  0.2662840783596039,\n",
       "  0.2714490592479706,\n",
       "  0.26915350556373596,\n",
       "  0.27230989933013916,\n",
       "  0.27116212248802185,\n",
       "  0.27230989933013916,\n",
       "  0.2728837728500366,\n",
       "  0.27202296257019043,\n",
       "  0.27317073941230774,\n",
       "  0.26886656880378723,\n",
       "  0.26915350556373596,\n",
       "  0.26886656880378723,\n",
       "  0.2717360258102417,\n",
       "  0.2714490592479706,\n",
       "  0.26829269528388977,\n",
       "  0.27403154969215393,\n",
       "  0.2714490592479706,\n",
       "  0.2728837728500366,\n",
       "  0.2728837728500366,\n",
       "  0.27202296257019043,\n",
       "  0.27202296257019043,\n",
       "  0.27001434564590454,\n",
       "  0.2717360258102417,\n",
       "  0.27230989933013916,\n",
       "  0.2708751857280731,\n",
       "  0.27202296257019043,\n",
       "  0.27345767617225647,\n",
       "  0.2697274088859558,\n",
       "  0.26886656880378723,\n",
       "  0.2694404721260071,\n",
       "  0.2725968360900879,\n",
       "  0.27317073941230774,\n",
       "  0.2697274088859558,\n",
       "  0.27116212248802185,\n",
       "  0.2674318552017212,\n",
       "  0.26800572872161865,\n",
       "  0.2748923897743225,\n",
       "  0.27001434564590454,\n",
       "  0.2705882489681244,\n",
       "  0.27202296257019043,\n",
       "  0.27230989933013916,\n",
       "  0.27030128240585327,\n",
       "  0.26829269528388977,\n",
       "  0.2697274088859558,\n",
       "  0.27403154969215393,\n",
       "  0.27345767617225647,\n",
       "  0.2728837728500366,\n",
       "  0.26886656880378723,\n",
       "  0.27345767617225647,\n",
       "  0.27030128240585327,\n",
       "  0.2685796320438385,\n",
       "  0.2708751857280731,\n",
       "  0.2717360258102417,\n",
       "  0.26714491844177246,\n",
       "  0.27001434564590454,\n",
       "  0.27116212248802185,\n",
       "  0.2728837728500366,\n",
       "  0.27001434564590454,\n",
       "  0.2717360258102417,\n",
       "  0.27116212248802185,\n",
       "  0.2714490592479706,\n",
       "  0.27230989933013916,\n",
       "  0.2694404721260071,\n",
       "  0.2746054530143738,\n",
       "  0.26886656880378723,\n",
       "  0.26886656880378723,\n",
       "  0.2714490592479706,\n",
       "  0.27517932653427124,\n",
       "  0.2737446129322052,\n",
       "  0.26829269528388977,\n",
       "  0.27431851625442505,\n",
       "  0.2714490592479706,\n",
       "  0.27001434564590454,\n",
       "  0.2705882489681244,\n",
       "  0.27230989933013916,\n",
       "  0.26800572872161865,\n",
       "  0.2694404721260071,\n",
       "  0.26571017503738403,\n",
       "  0.2728837728500366,\n",
       "  0.27116212248802185,\n",
       "  0.2677187919616699,\n",
       "  0.26829269528388977,\n",
       "  0.2705882489681244,\n",
       "  0.2694404721260071,\n",
       "  0.26915350556373596,\n",
       "  0.2717360258102417,\n",
       "  0.2728837728500366,\n",
       "  0.2694404721260071,\n",
       "  0.2717360258102417,\n",
       "  0.2714490592479706,\n",
       "  0.26800572872161865,\n",
       "  0.2645623981952667,\n",
       "  0.27001434564590454,\n",
       "  0.26915350556373596,\n",
       "  0.2746054530143738,\n",
       "  0.2685796320438385,\n",
       "  0.2737446129322052,\n",
       "  0.27317073941230774,\n",
       "  0.27403154969215393,\n",
       "  0.2694404721260071,\n",
       "  0.27202296257019043,\n",
       "  0.27403154969215393,\n",
       "  0.27001434564590454,\n",
       "  0.2654232382774353,\n",
       "  0.2728837728500366,\n",
       "  0.26714491844177246,\n",
       "  0.2685796320438385,\n",
       "  0.26800572872161865,\n",
       "  0.2708751857280731,\n",
       "  0.2694404721260071,\n",
       "  0.2717360258102417,\n",
       "  0.2697274088859558,\n",
       "  0.27001434564590454,\n",
       "  0.2697274088859558,\n",
       "  0.2705882489681244],\n",
       " 'val_factorized_top_k/top_5_categorical_accuracy': [0.2614060342311859,\n",
       "  0.27632710337638855,\n",
       "  0.2832137644290924,\n",
       "  0.2835007309913635,\n",
       "  0.2769010066986084,\n",
       "  0.27431851625442505,\n",
       "  0.28981348872184753,\n",
       "  0.2938306927680969,\n",
       "  0.29641321301460266,\n",
       "  0.2978479266166687,\n",
       "  0.30588236451148987,\n",
       "  0.30559539794921875,\n",
       "  0.3001434803009033,\n",
       "  0.30530846118927,\n",
       "  0.3050215244293213,\n",
       "  0.3116212487220764,\n",
       "  0.30875179171562195,\n",
       "  0.3144906759262085,\n",
       "  0.3147776126861572,\n",
       "  0.31592538952827454,\n",
       "  0.32137733697891235,\n",
       "  0.3210904002189636,\n",
       "  0.323672890663147,\n",
       "  0.329985648393631,\n",
       "  0.3331420421600342,\n",
       "  0.33486369252204895,\n",
       "  0.3406025767326355,\n",
       "  0.33916786313056946,\n",
       "  0.3377331495285034,\n",
       "  0.3388809263706207,\n",
       "  0.34519368410110474,\n",
       "  0.3503586947917938,\n",
       "  0.34835007786750793,\n",
       "  0.3500717282295227,\n",
       "  0.3509325683116913,\n",
       "  0.3549497723579407,\n",
       "  0.3492109179496765,\n",
       "  0.3529411852359772,\n",
       "  0.3563845157623291,\n",
       "  0.35179340839385986,\n",
       "  0.35380199551582336,\n",
       "  0.35695838928222656,\n",
       "  0.36126255989074707,\n",
       "  0.35781922936439514,\n",
       "  0.3606886565685272,\n",
       "  0.3563845157623291,\n",
       "  0.3604017198085785,\n",
       "  0.3583931028842926,\n",
       "  0.36011478304862976,\n",
       "  0.35781922936439514,\n",
       "  0.36183643341064453,\n",
       "  0.3586800694465637,\n",
       "  0.3592539429664612,\n",
       "  0.3575322926044464,\n",
       "  0.3592539429664612,\n",
       "  0.36126255989074707,\n",
       "  0.35695838928222656,\n",
       "  0.35896700620651245,\n",
       "  0.36126255989074707,\n",
       "  0.36011478304862976,\n",
       "  0.35781922936439514,\n",
       "  0.35896700620651245,\n",
       "  0.3572453260421753,\n",
       "  0.3604017198085785,\n",
       "  0.3606886565685272,\n",
       "  0.3575322926044464,\n",
       "  0.35982784628868103,\n",
       "  0.3592539429664612,\n",
       "  0.3586800694465637,\n",
       "  0.356097549200058,\n",
       "  0.3586800694465637,\n",
       "  0.35781922936439514,\n",
       "  0.36212339997291565,\n",
       "  0.35982784628868103,\n",
       "  0.35896700620651245,\n",
       "  0.3615494966506958,\n",
       "  0.35781922936439514,\n",
       "  0.35896700620651245,\n",
       "  0.3583931028842926,\n",
       "  0.3583931028842926,\n",
       "  0.36011478304862976,\n",
       "  0.3606886565685272,\n",
       "  0.356097549200058,\n",
       "  0.35810616612434387,\n",
       "  0.35781922936439514,\n",
       "  0.35695838928222656,\n",
       "  0.3592539429664612,\n",
       "  0.36011478304862976,\n",
       "  0.3604017198085785,\n",
       "  0.36126255989074707,\n",
       "  0.35695838928222656,\n",
       "  0.3615494966506958,\n",
       "  0.35982784628868103,\n",
       "  0.35982784628868103,\n",
       "  0.3572453260421753,\n",
       "  0.35982784628868103,\n",
       "  0.35781922936439514,\n",
       "  0.35781922936439514,\n",
       "  0.3572453260421753,\n",
       "  0.3604017198085785,\n",
       "  0.35896700620651245,\n",
       "  0.3583931028842926,\n",
       "  0.36011478304862976,\n",
       "  0.3583931028842926,\n",
       "  0.35810616612434387,\n",
       "  0.3563845157623291,\n",
       "  0.3592539429664612,\n",
       "  0.36212339997291565,\n",
       "  0.35695838928222656,\n",
       "  0.3606886565685272,\n",
       "  0.36097562313079834,\n",
       "  0.36183643341064453,\n",
       "  0.36011478304862976,\n",
       "  0.36011478304862976,\n",
       "  0.3586800694465637,\n",
       "  0.36011478304862976,\n",
       "  0.35896700620651245,\n",
       "  0.3583931028842926,\n",
       "  0.35982784628868103,\n",
       "  0.3575322926044464,\n",
       "  0.3572453260421753,\n",
       "  0.36097562313079834,\n",
       "  0.3586800694465637,\n",
       "  0.3606886565685272,\n",
       "  0.36212339997291565,\n",
       "  0.35896700620651245,\n",
       "  0.35781922936439514,\n",
       "  0.3595408797264099,\n",
       "  0.36183643341064453,\n",
       "  0.36011478304862976,\n",
       "  0.3626972734928131,\n",
       "  0.3606886565685272,\n",
       "  0.36011478304862976,\n",
       "  0.3635581135749817,\n",
       "  0.35581061244010925,\n",
       "  0.35810616612434387,\n",
       "  0.3572453260421753,\n",
       "  0.3604017198085785,\n",
       "  0.35781922936439514,\n",
       "  0.3575322926044464,\n",
       "  0.3606886565685272,\n",
       "  0.3604017198085785,\n",
       "  0.3586800694465637,\n",
       "  0.3606886565685272,\n",
       "  0.3572453260421753,\n",
       "  0.35667145252227783,\n",
       "  0.3592539429664612,\n",
       "  0.3575322926044464,\n",
       "  0.36011478304862976,\n",
       "  0.3595408797264099,\n",
       "  0.36011478304862976,\n",
       "  0.3604017198085785,\n",
       "  0.36097562313079834,\n",
       "  0.36011478304862976,\n",
       "  0.3595408797264099,\n",
       "  0.35982784628868103,\n",
       "  0.35896700620651245,\n",
       "  0.3595408797264099,\n",
       "  0.3615494966506958,\n",
       "  0.35781922936439514,\n",
       "  0.35810616612434387,\n",
       "  0.3572453260421753,\n",
       "  0.3563845157623291,\n",
       "  0.3604017198085785,\n",
       "  0.3615494966506958,\n",
       "  0.35695838928222656,\n",
       "  0.3592539429664612,\n",
       "  0.3583931028842926,\n",
       "  0.35810616612434387,\n",
       "  0.3595408797264099,\n",
       "  0.3583931028842926,\n",
       "  0.3604017198085785,\n",
       "  0.3595408797264099,\n",
       "  0.35896700620651245,\n",
       "  0.3606886565685272,\n",
       "  0.3595408797264099,\n",
       "  0.3604017198085785,\n",
       "  0.3626972734928131,\n",
       "  0.3592539429664612,\n",
       "  0.36327117681503296,\n",
       "  0.35781922936439514,\n",
       "  0.3592539429664612,\n",
       "  0.3615494966506958,\n",
       "  0.3592539429664612,\n",
       "  0.3595408797264099,\n",
       "  0.3606886565685272,\n",
       "  0.3615494966506958,\n",
       "  0.36298421025276184,\n",
       "  0.35781922936439514,\n",
       "  0.36011478304862976,\n",
       "  0.3604017198085785,\n",
       "  0.36097562313079834,\n",
       "  0.35810616612434387,\n",
       "  0.35810616612434387,\n",
       "  0.3595408797264099,\n",
       "  0.3604017198085785,\n",
       "  0.3606886565685272,\n",
       "  0.3583931028842926,\n",
       "  0.3606886565685272,\n",
       "  0.36212339997291565],\n",
       " 'val_factorized_top_k/top_10_categorical_accuracy': [0.3865136206150055,\n",
       "  0.3959827721118927,\n",
       "  0.39942610263824463,\n",
       "  0.40200862288475037,\n",
       "  0.40172165632247925,\n",
       "  0.4014347195625305,\n",
       "  0.44160687923431396,\n",
       "  0.45796269178390503,\n",
       "  0.46456241607666016,\n",
       "  0.47403156757354736,\n",
       "  0.47833573818206787,\n",
       "  0.4774748980998993,\n",
       "  0.48407459259033203,\n",
       "  0.48637014627456665,\n",
       "  0.48550933599472046,\n",
       "  0.4878048896789551,\n",
       "  0.4880918264389038,\n",
       "  0.4880918264389038,\n",
       "  0.4892396032810211,\n",
       "  0.48723098635673523,\n",
       "  0.4880918264389038,\n",
       "  0.48665711283683777,\n",
       "  0.48637014627456665,\n",
       "  0.48550933599472046,\n",
       "  0.48837876319885254,\n",
       "  0.48723098635673523,\n",
       "  0.4869440495967865,\n",
       "  0.48522236943244934,\n",
       "  0.48751792311668396,\n",
       "  0.48637014627456665,\n",
       "  0.48665711283683777,\n",
       "  0.4869440495967865,\n",
       "  0.48637014627456665,\n",
       "  0.48723098635673523,\n",
       "  0.4880918264389038,\n",
       "  0.4878048896789551,\n",
       "  0.48751792311668396,\n",
       "  0.48837876319885254,\n",
       "  0.48637014627456665,\n",
       "  0.48866569995880127,\n",
       "  0.48866569995880127,\n",
       "  0.4878048896789551,\n",
       "  0.4880918264389038,\n",
       "  0.4857962727546692,\n",
       "  0.48723098635673523,\n",
       "  0.4860832095146179,\n",
       "  0.48436155915260315,\n",
       "  0.4880918264389038,\n",
       "  0.48665711283683777,\n",
       "  0.4860832095146179,\n",
       "  0.48637014627456665,\n",
       "  0.4860832095146179,\n",
       "  0.4837876558303833,\n",
       "  0.4857962727546692,\n",
       "  0.48436155915260315,\n",
       "  0.4829268157482147,\n",
       "  0.482639878988266,\n",
       "  0.48436155915260315,\n",
       "  0.48436155915260315,\n",
       "  0.4849354326725006,\n",
       "  0.48350071907043457,\n",
       "  0.4829268157482147,\n",
       "  0.48321378231048584,\n",
       "  0.48350071907043457,\n",
       "  0.48436155915260315,\n",
       "  0.4829268157482147,\n",
       "  0.48321378231048584,\n",
       "  0.48034432530403137,\n",
       "  0.48206600546836853,\n",
       "  0.48350071907043457,\n",
       "  0.48235294222831726,\n",
       "  0.4837876558303833,\n",
       "  0.482639878988266,\n",
       "  0.4817790389060974,\n",
       "  0.4829268157482147,\n",
       "  0.48407459259033203,\n",
       "  0.48120516538619995,\n",
       "  0.48120516538619995,\n",
       "  0.4806312620639801,\n",
       "  0.48321378231048584,\n",
       "  0.48350071907043457,\n",
       "  0.48235294222831726,\n",
       "  0.48120516538619995,\n",
       "  0.4809182286262512,\n",
       "  0.48206600546836853,\n",
       "  0.4806312620639801,\n",
       "  0.48034432530403137,\n",
       "  0.4806312620639801,\n",
       "  0.4817790389060974,\n",
       "  0.48120516538619995,\n",
       "  0.4814921021461487,\n",
       "  0.48034432530403137,\n",
       "  0.4797704517841339,\n",
       "  0.48034432530403137,\n",
       "  0.4797704517841339,\n",
       "  0.4817790389060974,\n",
       "  0.4797704517841339,\n",
       "  0.482639878988266,\n",
       "  0.4817790389060974,\n",
       "  0.48235294222831726,\n",
       "  0.4817790389060974,\n",
       "  0.48206600546836853,\n",
       "  0.4814921021461487,\n",
       "  0.4814921021461487,\n",
       "  0.4817790389060974,\n",
       "  0.482639878988266,\n",
       "  0.48206600546836853,\n",
       "  0.48120516538619995,\n",
       "  0.4809182286262512,\n",
       "  0.4797704517841339,\n",
       "  0.48206600546836853,\n",
       "  0.4809182286262512,\n",
       "  0.4817790389060974,\n",
       "  0.48120516538619995,\n",
       "  0.4809182286262512,\n",
       "  0.48321378231048584,\n",
       "  0.48005738854408264,\n",
       "  0.4814921021461487,\n",
       "  0.48120516538619995,\n",
       "  0.48034432530403137,\n",
       "  0.4817790389060974,\n",
       "  0.4817790389060974,\n",
       "  0.48120516538619995,\n",
       "  0.48321378231048584,\n",
       "  0.48120516538619995,\n",
       "  0.4814921021461487,\n",
       "  0.4814921021461487,\n",
       "  0.4814921021461487,\n",
       "  0.48120516538619995,\n",
       "  0.4809182286262512,\n",
       "  0.4814921021461487,\n",
       "  0.4809182286262512,\n",
       "  0.48235294222831726,\n",
       "  0.4829268157482147,\n",
       "  0.4809182286262512,\n",
       "  0.48235294222831726,\n",
       "  0.48120516538619995,\n",
       "  0.4806312620639801,\n",
       "  0.482639878988266,\n",
       "  0.48235294222831726,\n",
       "  0.4814921021461487,\n",
       "  0.48005738854408264,\n",
       "  0.47919654846191406,\n",
       "  0.48005738854408264,\n",
       "  0.4814921021461487,\n",
       "  0.4809182286262512,\n",
       "  0.4817790389060974,\n",
       "  0.4817790389060974,\n",
       "  0.4809182286262512,\n",
       "  0.48235294222831726,\n",
       "  0.48034432530403137,\n",
       "  0.48120516538619995,\n",
       "  0.48235294222831726,\n",
       "  0.48235294222831726,\n",
       "  0.48120516538619995,\n",
       "  0.4814921021461487,\n",
       "  0.48120516538619995,\n",
       "  0.4814921021461487,\n",
       "  0.48235294222831726,\n",
       "  0.4829268157482147,\n",
       "  0.48120516538619995,\n",
       "  0.4814921021461487,\n",
       "  0.48005738854408264,\n",
       "  0.48120516538619995,\n",
       "  0.4809182286262512,\n",
       "  0.4809182286262512,\n",
       "  0.48206600546836853,\n",
       "  0.48034432530403137,\n",
       "  0.4806312620639801,\n",
       "  0.48120516538619995,\n",
       "  0.482639878988266,\n",
       "  0.48235294222831726,\n",
       "  0.4814921021461487,\n",
       "  0.48206600546836853,\n",
       "  0.48206600546836853,\n",
       "  0.48034432530403137,\n",
       "  0.48235294222831726,\n",
       "  0.48206600546836853,\n",
       "  0.4814921021461487,\n",
       "  0.48034432530403137,\n",
       "  0.4806312620639801,\n",
       "  0.48206600546836853,\n",
       "  0.48034432530403137,\n",
       "  0.482639878988266,\n",
       "  0.4817790389060974,\n",
       "  0.48034432530403137,\n",
       "  0.4806312620639801,\n",
       "  0.48120516538619995,\n",
       "  0.4794835150241852,\n",
       "  0.48235294222831726,\n",
       "  0.4814921021461487,\n",
       "  0.4814921021461487,\n",
       "  0.4809182286262512,\n",
       "  0.4797704517841339,\n",
       "  0.48034432530403137,\n",
       "  0.48235294222831726,\n",
       "  0.4814921021461487,\n",
       "  0.4814921021461487,\n",
       "  0.48206600546836853,\n",
       "  0.48005738854408264],\n",
       " 'val_factorized_top_k/top_15_categorical_accuracy': [0.45796269178390503,\n",
       "  0.46571019291877747,\n",
       "  0.4703013002872467,\n",
       "  0.47690099477767944,\n",
       "  0.4829268157482147,\n",
       "  0.5348637104034424,\n",
       "  0.5383070111274719,\n",
       "  0.5377331376075745,\n",
       "  0.5414634346961975,\n",
       "  0.5463414788246155,\n",
       "  0.5457675457000732,\n",
       "  0.5472022891044617,\n",
       "  0.5472022891044617,\n",
       "  0.5512195229530334,\n",
       "  0.5558106303215027,\n",
       "  0.5563845038414001,\n",
       "  0.5575323104858398,\n",
       "  0.5598278045654297,\n",
       "  0.5621233582496643,\n",
       "  0.5609756112098694,\n",
       "  0.5612625479698181,\n",
       "  0.5609756112098694,\n",
       "  0.5649928450584412,\n",
       "  0.5644189119338989,\n",
       "  0.5655667185783386,\n",
       "  0.568149209022522,\n",
       "  0.5695839524269104,\n",
       "  0.5675753355026245,\n",
       "  0.5690100193023682,\n",
       "  0.5690100193023682,\n",
       "  0.5692970156669617,\n",
       "  0.5687230825424194,\n",
       "  0.568149209022522,\n",
       "  0.5695839524269104,\n",
       "  0.5704447627067566,\n",
       "  0.5727403163909912,\n",
       "  0.5707316994667053,\n",
       "  0.5698708891868591,\n",
       "  0.5701578259468079,\n",
       "  0.5715925097465515,\n",
       "  0.5715925097465515,\n",
       "  0.5733141899108887,\n",
       "  0.5721664428710938,\n",
       "  0.5692970156669617,\n",
       "  0.5692970156669617,\n",
       "  0.5701578259468079,\n",
       "  0.5684361457824707,\n",
       "  0.5692970156669617,\n",
       "  0.5664275288581848,\n",
       "  0.5661405920982361,\n",
       "  0.5652797818183899,\n",
       "  0.5678622722625732,\n",
       "  0.5655667185783386,\n",
       "  0.5652797818183899,\n",
       "  0.5647059082984924,\n",
       "  0.5647059082984924,\n",
       "  0.5675753355026245,\n",
       "  0.5661405920982361,\n",
       "  0.5667144656181335,\n",
       "  0.5672883987426758,\n",
       "  0.5652797818183899,\n",
       "  0.5658536553382874,\n",
       "  0.5649928450584412,\n",
       "  0.5658536553382874,\n",
       "  0.5658536553382874,\n",
       "  0.5649928450584412,\n",
       "  0.5649928450584412,\n",
       "  0.5649928450584412,\n",
       "  0.5649928450584412,\n",
       "  0.5658536553382874,\n",
       "  0.5652797818183899,\n",
       "  0.563271164894104,\n",
       "  0.5638450384140015,\n",
       "  0.563271164894104,\n",
       "  0.5647059082984924,\n",
       "  0.5649928450584412,\n",
       "  0.5655667185783386,\n",
       "  0.5647059082984924,\n",
       "  0.5649928450584412,\n",
       "  0.5638450384140015,\n",
       "  0.5635581016540527,\n",
       "  0.5647059082984924,\n",
       "  0.5652797818183899,\n",
       "  0.5655667185783386,\n",
       "  0.5638450384140015,\n",
       "  0.5641319751739502,\n",
       "  0.5647059082984924,\n",
       "  0.5647059082984924,\n",
       "  0.5644189119338989,\n",
       "  0.5649928450584412,\n",
       "  0.5644189119338989,\n",
       "  0.563271164894104,\n",
       "  0.5655667185783386,\n",
       "  0.5652797818183899,\n",
       "  0.5641319751739502,\n",
       "  0.5644189119338989,\n",
       "  0.5624103546142578,\n",
       "  0.5649928450584412,\n",
       "  0.5641319751739502,\n",
       "  0.5629842281341553,\n",
       "  0.5647059082984924,\n",
       "  0.5638450384140015,\n",
       "  0.5629842281341553,\n",
       "  0.5652797818183899,\n",
       "  0.563271164894104,\n",
       "  0.5641319751739502,\n",
       "  0.5644189119338989,\n",
       "  0.5624103546142578,\n",
       "  0.5635581016540527,\n",
       "  0.5618364214897156,\n",
       "  0.563271164894104,\n",
       "  0.5635581016540527,\n",
       "  0.5629842281341553,\n",
       "  0.5638450384140015,\n",
       "  0.5638450384140015,\n",
       "  0.5629842281341553,\n",
       "  0.5641319751739502,\n",
       "  0.563271164894104,\n",
       "  0.5635581016540527,\n",
       "  0.5638450384140015,\n",
       "  0.5624103546142578,\n",
       "  0.5635581016540527,\n",
       "  0.5641319751739502,\n",
       "  0.5638450384140015,\n",
       "  0.5644189119338989,\n",
       "  0.563271164894104,\n",
       "  0.563271164894104,\n",
       "  0.5641319751739502,\n",
       "  0.5626972913742065,\n",
       "  0.5644189119338989,\n",
       "  0.563271164894104,\n",
       "  0.5626972913742065,\n",
       "  0.5629842281341553,\n",
       "  0.5641319751739502,\n",
       "  0.5641319751739502,\n",
       "  0.5652797818183899,\n",
       "  0.5644189119338989,\n",
       "  0.5644189119338989,\n",
       "  0.5647059082984924,\n",
       "  0.563271164894104,\n",
       "  0.5635581016540527,\n",
       "  0.5638450384140015,\n",
       "  0.5626972913742065,\n",
       "  0.563271164894104,\n",
       "  0.5635581016540527,\n",
       "  0.5647059082984924,\n",
       "  0.5638450384140015,\n",
       "  0.5635581016540527,\n",
       "  0.5644189119338989,\n",
       "  0.5644189119338989,\n",
       "  0.5638450384140015,\n",
       "  0.5629842281341553,\n",
       "  0.5638450384140015,\n",
       "  0.5644189119338989,\n",
       "  0.5641319751739502,\n",
       "  0.5626972913742065,\n",
       "  0.5644189119338989,\n",
       "  0.563271164894104,\n",
       "  0.563271164894104,\n",
       "  0.5626972913742065,\n",
       "  0.5618364214897156,\n",
       "  0.5626972913742065,\n",
       "  0.5638450384140015,\n",
       "  0.5638450384140015,\n",
       "  0.5629842281341553,\n",
       "  0.5635581016540527,\n",
       "  0.5644189119338989,\n",
       "  0.5641319751739502,\n",
       "  0.5629842281341553,\n",
       "  0.5644189119338989,\n",
       "  0.5649928450584412,\n",
       "  0.5641319751739502,\n",
       "  0.5638450384140015,\n",
       "  0.563271164894104,\n",
       "  0.5624103546142578,\n",
       "  0.5641319751739502,\n",
       "  0.563271164894104,\n",
       "  0.5629842281341553,\n",
       "  0.5635581016540527,\n",
       "  0.5629842281341553,\n",
       "  0.5626972913742065,\n",
       "  0.5649928450584412,\n",
       "  0.5641319751739502,\n",
       "  0.5641319751739502,\n",
       "  0.5635581016540527,\n",
       "  0.5641319751739502,\n",
       "  0.5644189119338989,\n",
       "  0.563271164894104,\n",
       "  0.5638450384140015,\n",
       "  0.5647059082984924,\n",
       "  0.5641319751739502,\n",
       "  0.5638450384140015,\n",
       "  0.5626972913742065,\n",
       "  0.5638450384140015,\n",
       "  0.5641319751739502,\n",
       "  0.5641319751739502,\n",
       "  0.5644189119338989,\n",
       "  0.5641319751739502,\n",
       "  0.5638450384140015,\n",
       "  0.5638450384140015],\n",
       " 'val_factorized_top_k/top_25_categorical_accuracy': [0.5454806089401245,\n",
       "  0.5578192472457886,\n",
       "  0.5658536553382874,\n",
       "  0.6086083054542542,\n",
       "  0.6232424974441528,\n",
       "  0.6261119246482849,\n",
       "  0.6350072026252747,\n",
       "  0.6410329937934875,\n",
       "  0.6450502276420593,\n",
       "  0.6487804651260376,\n",
       "  0.6536585092544556,\n",
       "  0.6553801894187927,\n",
       "  0.6614060401916504,\n",
       "  0.6631276607513428,\n",
       "  0.6651362776756287,\n",
       "  0.6639885306358337,\n",
       "  0.6654232144355774,\n",
       "  0.6662840843200684,\n",
       "  0.6659971475601196,\n",
       "  0.6680057644844055,\n",
       "  0.667718768119812,\n",
       "  0.6703013181686401,\n",
       "  0.6694404482841492,\n",
       "  0.6680057644844055,\n",
       "  0.6682927012443542,\n",
       "  0.6671448945999146,\n",
       "  0.6665710210800171,\n",
       "  0.6674318313598633,\n",
       "  0.668579638004303,\n",
       "  0.667718768119812,\n",
       "  0.6705882549285889,\n",
       "  0.667718768119812,\n",
       "  0.6688665747642517,\n",
       "  0.6703013181686401,\n",
       "  0.6708751916885376,\n",
       "  0.6714490652084351,\n",
       "  0.6700143218040466,\n",
       "  0.6708751916885376,\n",
       "  0.6703013181686401,\n",
       "  0.6703013181686401,\n",
       "  0.6694404482841492,\n",
       "  0.6703013181686401,\n",
       "  0.6688665747642517,\n",
       "  0.668579638004303,\n",
       "  0.667718768119812,\n",
       "  0.6688665747642517,\n",
       "  0.6674318313598633,\n",
       "  0.6668579578399658,\n",
       "  0.6671448945999146,\n",
       "  0.6674318313598633,\n",
       "  0.667718768119812,\n",
       "  0.6674318313598633,\n",
       "  0.6674318313598633,\n",
       "  0.667718768119812,\n",
       "  0.6674318313598633,\n",
       "  0.6665710210800171,\n",
       "  0.6662840843200684,\n",
       "  0.6657102108001709,\n",
       "  0.6674318313598633,\n",
       "  0.6657102108001709,\n",
       "  0.6662840843200684,\n",
       "  0.6668579578399658,\n",
       "  0.6668579578399658,\n",
       "  0.6645624041557312,\n",
       "  0.6654232144355774,\n",
       "  0.6662840843200684,\n",
       "  0.6668579578399658,\n",
       "  0.6668579578399658,\n",
       "  0.6659971475601196,\n",
       "  0.6648493409156799,\n",
       "  0.6642754673957825,\n",
       "  0.6654232144355774,\n",
       "  0.6648493409156799,\n",
       "  0.6648493409156799,\n",
       "  0.6651362776756287,\n",
       "  0.6642754673957825,\n",
       "  0.6651362776756287,\n",
       "  0.663701593875885,\n",
       "  0.6648493409156799,\n",
       "  0.6642754673957825,\n",
       "  0.6642754673957825,\n",
       "  0.6642754673957825,\n",
       "  0.6634146571159363,\n",
       "  0.6645624041557312,\n",
       "  0.6651362776756287,\n",
       "  0.6645624041557312,\n",
       "  0.6642754673957825,\n",
       "  0.6631276607513428,\n",
       "  0.662840723991394,\n",
       "  0.6631276607513428,\n",
       "  0.662840723991394,\n",
       "  0.663701593875885,\n",
       "  0.6639885306358337,\n",
       "  0.663701593875885,\n",
       "  0.6642754673957825,\n",
       "  0.6631276607513428,\n",
       "  0.6634146571159363,\n",
       "  0.6634146571159363,\n",
       "  0.6616929769515991,\n",
       "  0.6634146571159363,\n",
       "  0.6631276607513428,\n",
       "  0.6639885306358337,\n",
       "  0.6625537872314453,\n",
       "  0.6642754673957825,\n",
       "  0.6634146571159363,\n",
       "  0.6654232144355774,\n",
       "  0.6631276607513428,\n",
       "  0.6639885306358337,\n",
       "  0.6619799137115479,\n",
       "  0.6634146571159363,\n",
       "  0.6631276607513428,\n",
       "  0.6634146571159363,\n",
       "  0.6631276607513428,\n",
       "  0.662840723991394,\n",
       "  0.6639885306358337,\n",
       "  0.6639885306358337,\n",
       "  0.6634146571159363,\n",
       "  0.6645624041557312,\n",
       "  0.6631276607513428,\n",
       "  0.663701593875885,\n",
       "  0.6645624041557312,\n",
       "  0.6631276607513428,\n",
       "  0.6631276607513428,\n",
       "  0.6642754673957825,\n",
       "  0.6631276607513428,\n",
       "  0.6634146571159363,\n",
       "  0.6634146571159363,\n",
       "  0.6639885306358337,\n",
       "  0.6634146571159363,\n",
       "  0.6631276607513428,\n",
       "  0.6614060401916504,\n",
       "  0.6625537872314453,\n",
       "  0.662840723991394,\n",
       "  0.662840723991394,\n",
       "  0.6642754673957825,\n",
       "  0.6631276607513428,\n",
       "  0.662840723991394,\n",
       "  0.662840723991394,\n",
       "  0.663701593875885,\n",
       "  0.662840723991394,\n",
       "  0.6648493409156799,\n",
       "  0.663701593875885,\n",
       "  0.6639885306358337,\n",
       "  0.6625537872314453,\n",
       "  0.663701593875885,\n",
       "  0.6634146571159363,\n",
       "  0.6634146571159363,\n",
       "  0.6634146571159363,\n",
       "  0.6631276607513428,\n",
       "  0.6631276607513428,\n",
       "  0.6616929769515991,\n",
       "  0.662840723991394,\n",
       "  0.6622668504714966,\n",
       "  0.6625537872314453,\n",
       "  0.662840723991394,\n",
       "  0.6642754673957825,\n",
       "  0.6642754673957825,\n",
       "  0.6625537872314453,\n",
       "  0.6634146571159363,\n",
       "  0.663701593875885,\n",
       "  0.6634146571159363,\n",
       "  0.662840723991394,\n",
       "  0.662840723991394,\n",
       "  0.6631276607513428,\n",
       "  0.6639885306358337,\n",
       "  0.6634146571159363,\n",
       "  0.663701593875885,\n",
       "  0.6631276607513428,\n",
       "  0.6631276607513428,\n",
       "  0.662840723991394,\n",
       "  0.662840723991394,\n",
       "  0.6631276607513428,\n",
       "  0.6634146571159363,\n",
       "  0.663701593875885,\n",
       "  0.663701593875885,\n",
       "  0.6639885306358337,\n",
       "  0.6639885306358337,\n",
       "  0.662840723991394,\n",
       "  0.662840723991394,\n",
       "  0.6645624041557312,\n",
       "  0.6634146571159363,\n",
       "  0.662840723991394,\n",
       "  0.6631276607513428,\n",
       "  0.662840723991394,\n",
       "  0.6634146571159363,\n",
       "  0.6625537872314453,\n",
       "  0.6631276607513428,\n",
       "  0.6634146571159363,\n",
       "  0.6634146571159363,\n",
       "  0.6642754673957825,\n",
       "  0.6625537872314453,\n",
       "  0.663701593875885,\n",
       "  0.663701593875885,\n",
       "  0.663701593875885,\n",
       "  0.6625537872314453,\n",
       "  0.6634146571159363,\n",
       "  0.662840723991394,\n",
       "  0.6631276607513428,\n",
       "  0.6639885306358337,\n",
       "  0.6625537872314453],\n",
       " 'val_loss': [2643.5830078125,\n",
       "  2543.439453125,\n",
       "  2479.133056640625,\n",
       "  2437.65380859375,\n",
       "  2408.851806640625,\n",
       "  2387.74560546875,\n",
       "  2371.467529296875,\n",
       "  2358.3515625,\n",
       "  2347.305419921875,\n",
       "  2337.634765625,\n",
       "  2328.92822265625,\n",
       "  2320.898681640625,\n",
       "  2313.4306640625,\n",
       "  2306.4228515625,\n",
       "  2299.80908203125,\n",
       "  2293.619873046875,\n",
       "  2287.75537109375,\n",
       "  2282.21240234375,\n",
       "  2276.997802734375,\n",
       "  2272.04443359375,\n",
       "  2267.365966796875,\n",
       "  2262.9541015625,\n",
       "  2258.832763671875,\n",
       "  2254.91259765625,\n",
       "  2251.23193359375,\n",
       "  2247.76171875,\n",
       "  2244.50830078125,\n",
       "  2241.494384765625,\n",
       "  2238.662353515625,\n",
       "  2236.0322265625,\n",
       "  2233.569580078125,\n",
       "  2231.318115234375,\n",
       "  2229.279052734375,\n",
       "  2227.365966796875,\n",
       "  2225.623779296875,\n",
       "  2224.04296875,\n",
       "  2222.5556640625,\n",
       "  2221.2978515625,\n",
       "  2220.1669921875,\n",
       "  2219.168701171875,\n",
       "  2218.266845703125,\n",
       "  2217.525390625,\n",
       "  2216.90283203125,\n",
       "  2216.361083984375,\n",
       "  2215.93994140625,\n",
       "  2215.740966796875,\n",
       "  2215.55029296875,\n",
       "  2215.427490234375,\n",
       "  2215.34814453125,\n",
       "  2215.282958984375,\n",
       "  2215.2490234375,\n",
       "  2215.252197265625,\n",
       "  2215.267822265625,\n",
       "  2215.322509765625,\n",
       "  2215.3759765625,\n",
       "  2215.42919921875,\n",
       "  2215.483154296875,\n",
       "  2215.554443359375,\n",
       "  2215.619873046875,\n",
       "  2215.703857421875,\n",
       "  2215.785400390625,\n",
       "  2215.884033203125,\n",
       "  2216.00390625,\n",
       "  2216.07568359375,\n",
       "  2216.145263671875,\n",
       "  2216.2119140625,\n",
       "  2216.276611328125,\n",
       "  2216.348876953125,\n",
       "  2216.431884765625,\n",
       "  2216.5087890625,\n",
       "  2216.5908203125,\n",
       "  2216.67431640625,\n",
       "  2216.71923828125,\n",
       "  2216.761962890625,\n",
       "  2216.81005859375,\n",
       "  2216.8583984375,\n",
       "  2216.907958984375,\n",
       "  2216.958740234375,\n",
       "  2217.009521484375,\n",
       "  2217.05712890625,\n",
       "  2217.110595703125,\n",
       "  2217.137451171875,\n",
       "  2217.167236328125,\n",
       "  2217.19970703125,\n",
       "  2217.22705078125,\n",
       "  2217.255126953125,\n",
       "  2217.286865234375,\n",
       "  2217.31689453125,\n",
       "  2217.346435546875,\n",
       "  2217.375,\n",
       "  2217.393798828125,\n",
       "  2217.412109375,\n",
       "  2217.431640625,\n",
       "  2217.448974609375,\n",
       "  2217.467529296875,\n",
       "  2217.486572265625,\n",
       "  2217.5029296875,\n",
       "  2217.520263671875,\n",
       "  2217.53857421875,\n",
       "  2217.548583984375,\n",
       "  2217.559814453125,\n",
       "  2217.570068359375,\n",
       "  2217.580322265625,\n",
       "  2217.591064453125,\n",
       "  2217.6015625,\n",
       "  2217.612548828125,\n",
       "  2217.622802734375,\n",
       "  2217.633544921875,\n",
       "  2217.64013671875,\n",
       "  2217.646484375,\n",
       "  2217.65283203125,\n",
       "  2217.6591796875,\n",
       "  2217.66552734375,\n",
       "  2217.671142578125,\n",
       "  2217.677978515625,\n",
       "  2217.68359375,\n",
       "  2217.689453125,\n",
       "  2217.69287109375,\n",
       "  2217.696533203125,\n",
       "  2217.700439453125,\n",
       "  2217.703857421875,\n",
       "  2217.707275390625,\n",
       "  2217.7109375,\n",
       "  2217.7138671875,\n",
       "  2217.7177734375,\n",
       "  2217.72119140625,\n",
       "  2217.722900390625,\n",
       "  2217.72509765625,\n",
       "  2217.72705078125,\n",
       "  2217.7294921875,\n",
       "  2217.731201171875,\n",
       "  2217.7333984375,\n",
       "  2217.7353515625,\n",
       "  2217.73779296875,\n",
       "  2217.739990234375,\n",
       "  2217.740966796875,\n",
       "  2217.7421875,\n",
       "  2217.7431640625,\n",
       "  2217.74462890625,\n",
       "  2217.74560546875,\n",
       "  2217.746826171875,\n",
       "  2217.748291015625,\n",
       "  2217.749267578125,\n",
       "  2217.750244140625,\n",
       "  2217.750732421875,\n",
       "  2217.75146484375,\n",
       "  2217.75244140625,\n",
       "  2217.7529296875,\n",
       "  2217.75341796875,\n",
       "  2217.75439453125,\n",
       "  2217.7548828125,\n",
       "  2217.755615234375,\n",
       "  2217.756591796875,\n",
       "  2217.756591796875,\n",
       "  2217.757080078125,\n",
       "  2217.75732421875,\n",
       "  2217.7578125,\n",
       "  2217.75830078125,\n",
       "  2217.758544921875,\n",
       "  2217.7587890625,\n",
       "  2217.75927734375,\n",
       "  2217.759765625,\n",
       "  2217.760009765625,\n",
       "  2217.76025390625,\n",
       "  2217.76025390625,\n",
       "  2217.7607421875,\n",
       "  2217.7607421875,\n",
       "  2217.76123046875,\n",
       "  2217.76123046875,\n",
       "  2217.76171875,\n",
       "  2217.76171875,\n",
       "  2217.761962890625,\n",
       "  2217.761962890625,\n",
       "  2217.761962890625,\n",
       "  2217.76220703125,\n",
       "  2217.76220703125,\n",
       "  2217.762451171875,\n",
       "  2217.762451171875,\n",
       "  2217.762451171875,\n",
       "  2217.762451171875,\n",
       "  2217.7626953125,\n",
       "  2217.762451171875,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.762939453125,\n",
       "  2217.7626953125,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375],\n",
       " 'val_regularization_loss': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'val_total_loss': [2643.5830078125,\n",
       "  2543.439453125,\n",
       "  2479.133056640625,\n",
       "  2437.65380859375,\n",
       "  2408.851806640625,\n",
       "  2387.74560546875,\n",
       "  2371.467529296875,\n",
       "  2358.3515625,\n",
       "  2347.305419921875,\n",
       "  2337.634765625,\n",
       "  2328.92822265625,\n",
       "  2320.898681640625,\n",
       "  2313.4306640625,\n",
       "  2306.4228515625,\n",
       "  2299.80908203125,\n",
       "  2293.619873046875,\n",
       "  2287.75537109375,\n",
       "  2282.21240234375,\n",
       "  2276.997802734375,\n",
       "  2272.04443359375,\n",
       "  2267.365966796875,\n",
       "  2262.9541015625,\n",
       "  2258.832763671875,\n",
       "  2254.91259765625,\n",
       "  2251.23193359375,\n",
       "  2247.76171875,\n",
       "  2244.50830078125,\n",
       "  2241.494384765625,\n",
       "  2238.662353515625,\n",
       "  2236.0322265625,\n",
       "  2233.569580078125,\n",
       "  2231.318115234375,\n",
       "  2229.279052734375,\n",
       "  2227.365966796875,\n",
       "  2225.623779296875,\n",
       "  2224.04296875,\n",
       "  2222.5556640625,\n",
       "  2221.2978515625,\n",
       "  2220.1669921875,\n",
       "  2219.168701171875,\n",
       "  2218.266845703125,\n",
       "  2217.525390625,\n",
       "  2216.90283203125,\n",
       "  2216.361083984375,\n",
       "  2215.93994140625,\n",
       "  2215.740966796875,\n",
       "  2215.55029296875,\n",
       "  2215.427490234375,\n",
       "  2215.34814453125,\n",
       "  2215.282958984375,\n",
       "  2215.2490234375,\n",
       "  2215.252197265625,\n",
       "  2215.267822265625,\n",
       "  2215.322509765625,\n",
       "  2215.3759765625,\n",
       "  2215.42919921875,\n",
       "  2215.483154296875,\n",
       "  2215.554443359375,\n",
       "  2215.619873046875,\n",
       "  2215.703857421875,\n",
       "  2215.785400390625,\n",
       "  2215.884033203125,\n",
       "  2216.00390625,\n",
       "  2216.07568359375,\n",
       "  2216.145263671875,\n",
       "  2216.2119140625,\n",
       "  2216.276611328125,\n",
       "  2216.348876953125,\n",
       "  2216.431884765625,\n",
       "  2216.5087890625,\n",
       "  2216.5908203125,\n",
       "  2216.67431640625,\n",
       "  2216.71923828125,\n",
       "  2216.761962890625,\n",
       "  2216.81005859375,\n",
       "  2216.8583984375,\n",
       "  2216.907958984375,\n",
       "  2216.958740234375,\n",
       "  2217.009521484375,\n",
       "  2217.05712890625,\n",
       "  2217.110595703125,\n",
       "  2217.137451171875,\n",
       "  2217.167236328125,\n",
       "  2217.19970703125,\n",
       "  2217.22705078125,\n",
       "  2217.255126953125,\n",
       "  2217.286865234375,\n",
       "  2217.31689453125,\n",
       "  2217.346435546875,\n",
       "  2217.375,\n",
       "  2217.393798828125,\n",
       "  2217.412109375,\n",
       "  2217.431640625,\n",
       "  2217.448974609375,\n",
       "  2217.467529296875,\n",
       "  2217.486572265625,\n",
       "  2217.5029296875,\n",
       "  2217.520263671875,\n",
       "  2217.53857421875,\n",
       "  2217.548583984375,\n",
       "  2217.559814453125,\n",
       "  2217.570068359375,\n",
       "  2217.580322265625,\n",
       "  2217.591064453125,\n",
       "  2217.6015625,\n",
       "  2217.612548828125,\n",
       "  2217.622802734375,\n",
       "  2217.633544921875,\n",
       "  2217.64013671875,\n",
       "  2217.646484375,\n",
       "  2217.65283203125,\n",
       "  2217.6591796875,\n",
       "  2217.66552734375,\n",
       "  2217.671142578125,\n",
       "  2217.677978515625,\n",
       "  2217.68359375,\n",
       "  2217.689453125,\n",
       "  2217.69287109375,\n",
       "  2217.696533203125,\n",
       "  2217.700439453125,\n",
       "  2217.703857421875,\n",
       "  2217.707275390625,\n",
       "  2217.7109375,\n",
       "  2217.7138671875,\n",
       "  2217.7177734375,\n",
       "  2217.72119140625,\n",
       "  2217.722900390625,\n",
       "  2217.72509765625,\n",
       "  2217.72705078125,\n",
       "  2217.7294921875,\n",
       "  2217.731201171875,\n",
       "  2217.7333984375,\n",
       "  2217.7353515625,\n",
       "  2217.73779296875,\n",
       "  2217.739990234375,\n",
       "  2217.740966796875,\n",
       "  2217.7421875,\n",
       "  2217.7431640625,\n",
       "  2217.74462890625,\n",
       "  2217.74560546875,\n",
       "  2217.746826171875,\n",
       "  2217.748291015625,\n",
       "  2217.749267578125,\n",
       "  2217.750244140625,\n",
       "  2217.750732421875,\n",
       "  2217.75146484375,\n",
       "  2217.75244140625,\n",
       "  2217.7529296875,\n",
       "  2217.75341796875,\n",
       "  2217.75439453125,\n",
       "  2217.7548828125,\n",
       "  2217.755615234375,\n",
       "  2217.756591796875,\n",
       "  2217.756591796875,\n",
       "  2217.757080078125,\n",
       "  2217.75732421875,\n",
       "  2217.7578125,\n",
       "  2217.75830078125,\n",
       "  2217.758544921875,\n",
       "  2217.7587890625,\n",
       "  2217.75927734375,\n",
       "  2217.759765625,\n",
       "  2217.760009765625,\n",
       "  2217.76025390625,\n",
       "  2217.76025390625,\n",
       "  2217.7607421875,\n",
       "  2217.7607421875,\n",
       "  2217.76123046875,\n",
       "  2217.76123046875,\n",
       "  2217.76171875,\n",
       "  2217.76171875,\n",
       "  2217.761962890625,\n",
       "  2217.761962890625,\n",
       "  2217.761962890625,\n",
       "  2217.76220703125,\n",
       "  2217.76220703125,\n",
       "  2217.762451171875,\n",
       "  2217.762451171875,\n",
       "  2217.762451171875,\n",
       "  2217.762451171875,\n",
       "  2217.7626953125,\n",
       "  2217.762451171875,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.7626953125,\n",
       "  2217.762939453125,\n",
       "  2217.7626953125,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375,\n",
       "  2217.76318359375],\n",
       " 'lr': [0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.006,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.0036,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.00216,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.001296,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.0007776,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00046655998,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00027993598,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.00016796158,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  0.000100776946,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  6.046617e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  3.62797e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  2.176782e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  1.3060692e-05,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  7.8364155e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  4.7018493e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  2.8211095e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.6926657e-06,\n",
       "  1.0155994e-06,\n",
       "  1.0155994e-06]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bb4698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = iter([key for key in data.history.keys() if key.startswith(\"factorized_top\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fe020a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(1,201,1)]\n",
    "for key in keys:\n",
    "    plt.plot(x, data.history[key], \"-b\", label=\"Train\")\n",
    "    plt.plot(x, data.history[\"val_\"+key], \"-r\", label=\"Test\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(key.split(\"/\")[1])\n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6e5af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daed8005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.ITEM_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76522e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b85ca7cd17e46580c5781b40041ecb0327ffab993dd3a95c3861a9f1364646"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
